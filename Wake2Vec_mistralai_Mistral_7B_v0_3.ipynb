{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.10"
      },
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6f7a2d3073db42a69c6c72e6319b04c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7bd7442f6e74d7caefc04111e51f963",
              "IPY_MODEL_9f79bbdecff446f3bf8fe01806967290",
              "IPY_MODEL_d8e640caacdb491fa029a4da23d8368c"
            ],
            "layout": "IPY_MODEL_a2f5b755a3674b36b319387822a88306"
          }
        },
        "e7bd7442f6e74d7caefc04111e51f963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c96890e009149acbc1f2507a2fff27d",
            "placeholder": "​",
            "style": "IPY_MODEL_3ca67e03c87240da887a0e96468f3ae2",
            "value": "tokenizer_config.json: "
          }
        },
        "9f79bbdecff446f3bf8fe01806967290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f623e0431d74e5882fcf3c74e4904eb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62da1cc9711a46ff89e54fbecd4b1ee6",
            "value": 1
          }
        },
        "d8e640caacdb491fa029a4da23d8368c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ed8d621ae6c4393809b318e66158226",
            "placeholder": "​",
            "style": "IPY_MODEL_dab4addcd1fe48898d4da26f2538d007",
            "value": " 137k/? [00:00&lt;00:00, 2.78MB/s]"
          }
        },
        "a2f5b755a3674b36b319387822a88306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c96890e009149acbc1f2507a2fff27d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ca67e03c87240da887a0e96468f3ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f623e0431d74e5882fcf3c74e4904eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "62da1cc9711a46ff89e54fbecd4b1ee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ed8d621ae6c4393809b318e66158226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab4addcd1fe48898d4da26f2538d007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "219d2ee0b6a74da09dedfc2c07d2b16e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14a7483535764de3b30287b467a33b86",
              "IPY_MODEL_907c7ef0029248f2a78b4006d0449d80",
              "IPY_MODEL_07ead01a97b1494ba8f383130008a297"
            ],
            "layout": "IPY_MODEL_1e5b48f132804ed2a20cd7af52685859"
          }
        },
        "14a7483535764de3b30287b467a33b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_518c78b2c4524f84b5a4296d3b92eeb7",
            "placeholder": "​",
            "style": "IPY_MODEL_66fbaa67d5714f4e894b08da15c725a5",
            "value": "tokenizer.model: 100%"
          }
        },
        "907c7ef0029248f2a78b4006d0449d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53f7a43cccc0431eb0511801b6b513d8",
            "max": 587404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20a5357d18da47eab4ec2f2209567d77",
            "value": 587404
          }
        },
        "07ead01a97b1494ba8f383130008a297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_004952e10ef944acac3ca53caff1041d",
            "placeholder": "​",
            "style": "IPY_MODEL_24616af8ce2847d6a0f61b462fe3162e",
            "value": " 587k/587k [00:00&lt;00:00, 684kB/s]"
          }
        },
        "1e5b48f132804ed2a20cd7af52685859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "518c78b2c4524f84b5a4296d3b92eeb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66fbaa67d5714f4e894b08da15c725a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53f7a43cccc0431eb0511801b6b513d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20a5357d18da47eab4ec2f2209567d77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "004952e10ef944acac3ca53caff1041d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24616af8ce2847d6a0f61b462fe3162e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12d543ca3242425795c92109f5f08fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44f5a5fba3854cd38bb138bcfc72aef1",
              "IPY_MODEL_7c7a94e848474c4592ee319ea428ec17",
              "IPY_MODEL_a4aacca7d53f48f8b97995491edbfb8b"
            ],
            "layout": "IPY_MODEL_e1a3c5e008eb407b91547d5c0844efd1"
          }
        },
        "44f5a5fba3854cd38bb138bcfc72aef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67f71e7ab9c8423cbee3c5e45846d4b9",
            "placeholder": "​",
            "style": "IPY_MODEL_489f1a14dd2b495bb190da1a2edf896f",
            "value": "tokenizer.json: "
          }
        },
        "7c7a94e848474c4592ee319ea428ec17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_576ad730ac2b4c7d9f6ded605be7e1a8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a3dab8d380e41808228505c47a3d4e0",
            "value": 1
          }
        },
        "a4aacca7d53f48f8b97995491edbfb8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b07ba6d1383e45d994dc4196994a1f39",
            "placeholder": "​",
            "style": "IPY_MODEL_1da280c3374a498d8ac88cca923009d7",
            "value": " 1.96M/? [00:00&lt;00:00, 12.1MB/s]"
          }
        },
        "e1a3c5e008eb407b91547d5c0844efd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67f71e7ab9c8423cbee3c5e45846d4b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "489f1a14dd2b495bb190da1a2edf896f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "576ad730ac2b4c7d9f6ded605be7e1a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8a3dab8d380e41808228505c47a3d4e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b07ba6d1383e45d994dc4196994a1f39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1da280c3374a498d8ac88cca923009d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a455ee83a19480b8092f91e3242237a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78d402d0043c438db8dc98ecdef766e4",
              "IPY_MODEL_e1b44edfac40408d91ac85e4e42795fd",
              "IPY_MODEL_29097c31b890418a8cd32520cfd64acc"
            ],
            "layout": "IPY_MODEL_e97156bc793a49d795ac8cbfa145ac78"
          }
        },
        "78d402d0043c438db8dc98ecdef766e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66c341ebccaf4461abfa924ff9d5b71d",
            "placeholder": "​",
            "style": "IPY_MODEL_d360959b03fa4a5bbaf13f8762e0f731",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e1b44edfac40408d91ac85e4e42795fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e10a75ed3c74266b1255219b204cda9",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_083037c09792409ab8837b1e8f041890",
            "value": 414
          }
        },
        "29097c31b890418a8cd32520cfd64acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2d3b20a566d437ba2a5f3c7ae8ca429",
            "placeholder": "​",
            "style": "IPY_MODEL_3ff726f485204b5e86e881ff39f7d5f4",
            "value": " 414/414 [00:00&lt;00:00, 12.2kB/s]"
          }
        },
        "e97156bc793a49d795ac8cbfa145ac78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66c341ebccaf4461abfa924ff9d5b71d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d360959b03fa4a5bbaf13f8762e0f731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e10a75ed3c74266b1255219b204cda9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "083037c09792409ab8837b1e8f041890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2d3b20a566d437ba2a5f3c7ae8ca429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ff726f485204b5e86e881ff39f7d5f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahb97/Wake2vec/blob/main/Wake2Vec_mistralai_Mistral_7B_v0_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wake2Vec: Embedding Surgery (4-bit, NC-17) Mistral now, LLaMA soon\n",
        "\n",
        "**Status (2025-11-03):** While LLaMA-2/3 access is pending, this run uses Mistral-7B-v0.3 as an ungated fallback to make use of T4 time. The pipeline, metrics, and artifacts are identical. Once Hugging Face authorises the LLaMA repo, it will switch the base back to LLaMA-2-13B (4-bit) and rerun the exact procedure.\n",
        "\n",
        "**What this notebook does**\n",
        "- Injects a custom Finnegans Wake lexicon into the base model tokenizer.\n",
        "- Trains only the input embedding matrix (output `lm_head` hard-tied) — pure embedding surgery.\n",
        "- Uses aggressive spherical init for new tokens (big initial norm), row-mask grads (only new rows update),\n",
        "  repulsion regularizer (prevents collapse), and optional norm clamp(stability).\n",
        "- Saves compact embedding-only artifacts and geometry receipts:\n",
        "  - **PIP loss** (global geometry shift),\n",
        "  - **Isotropy** (spectral health),\n",
        "  - **Top-k neighbor overlap** (neighborhood reshuffle).\n",
        "\n",
        "**Temporary base**\n",
        "- `MODEL_NAME = \"mistralai/Mistral-7B-v0.3\"` (ungated, T4-friendly).\n",
        "- Same `SEQ_LEN`/accumulation/quantisation settings; identical training logic.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jbq2Ra4vimNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, sys, platform\n",
        "print(\"torch:\", torch.__version__, \"cuda:\", torch.version.cuda, \"py:\", sys.version.split()[0], platform.platform())\n",
        "# Expect torch 2.8.0+cu126 on Colab with 2025.07"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ7KT-TXtvw2",
        "outputId": "c7bc6105-090f-4220-8c97-e88e0a71409d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch: 2.6.0+cu124 cuda: 12.4 py: 3.12.12 Linux-6.6.105+-x86_64-with-glibc2.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === LLaMA-2-13B Embedding-Only (no HF datasets/pandas) ===\n",
        "from huggingface_hub import login\n",
        "from getpass import getpass\n",
        "HF_TOKEN = getpass(\"HF token (hidden): \")\n",
        "login(token=HF_TOKEN, add_to_git_credential=True)\n",
        "\n",
        "import os, math, json, random, torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig,\n",
        "                          DataCollatorForLanguageModeling, TrainingArguments, Trainer, set_seed)\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# ----- CONFIG -----\n",
        "SEED = 42; set_seed(SEED)\n",
        "MODEL_NAME = \"meta-llama/Llama-2-13b-hf\"  # swap to 3.1-8B if OOM\n",
        "WAKE_LEX_PATH = \"/content/wake_lexicon.txt\"      # your file\n",
        "CORPUS_TXT    = \"/content/finnegans_wake.txt\"    # your file\n",
        "RUN_DIR       = \"/content/wake_llama2_embs\"\n",
        "SEQ_LEN = 1024\n",
        "STRIDE  = 1024   # set <SEQ_LEN> if you want overlap (e.g. 1024//2)\n",
        "MAX_STEPS = 1100\n",
        "LOG_STEPS = 20\n",
        "SAVE_STEPS = 100\n",
        "LR = 8e-4\n",
        "GRAD_ACCUM = 8\n",
        "REPULSION_W = 0.05\n",
        "TARGET_NORM = None\n",
        "MAX_ROW_NORM = None\n",
        "REPORT_SAMPLE = 1500\n",
        "\n",
        "os.makedirs(RUN_DIR, exist_ok=True)\n",
        "\n",
        "# ----- 4-bit load -----\n",
        "bnb = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_use_double_quant=True,\n",
        "                         bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.float16)\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True, token=HF_TOKEN)\n",
        "if tok.pad_token is None: tok.pad_token = tok.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME, quantization_config=bnb, torch_dtype=torch.float16, device_map=\"auto\", token=HF_TOKEN\n",
        ")\n",
        "if hasattr(model, \"tie_weights\"): model.tie_weights()\n",
        "model.config.tie_word_embeddings = True\n",
        "\n",
        "# ----- tiny PEFT adapter (policy compliance) -----\n",
        "peft_cfg = LoraConfig(r=1, lora_alpha=1, lora_dropout=0.0,\n",
        "                      target_modules=[\"q_proj\"], bias=\"none\", task_type=\"CAUSAL_LM\")\n",
        "model = get_peft_model(model, peft_cfg)\n",
        "\n",
        "# ----- inject Wake lexicon -----\n",
        "def read_lines(p):\n",
        "    return [x.strip() for x in open(p, encoding=\"utf-8\") if x.strip()] if os.path.exists(p) else []\n",
        "wake = read_lines(WAKE_LEX_PATH)\n",
        "missing = [t for t in wake if tok.convert_tokens_to_ids(t)==tok.unk_token_id]\n",
        "num_added = tok.add_tokens(missing, special_tokens=False)\n",
        "\n",
        "old_vocab = model.get_input_embeddings().weight.shape[0]\n",
        "model.resize_token_embeddings(len(tok))\n",
        "wte = model.get_input_embeddings()\n",
        "if hasattr(model, \"lm_head\"): model.lm_head.weight = wte.weight  # re-tie\n",
        "\n",
        "# ----- spherical kick init for new rows -----\n",
        "with torch.no_grad():\n",
        "    base = wte.weight[:old_vocab]; dim = base.shape[1]\n",
        "    std = base.std().item(); base_radius = std * math.sqrt(dim)\n",
        "    target_radius = TARGET_NORM or (1.5 * base_radius)\n",
        "    if num_added>0:\n",
        "        new = torch.randn((num_added, dim), device=wte.weight.device)\n",
        "        new = new/(new.norm(dim=1, keepdim=True)+1e-8)*target_radius\n",
        "        wte.weight.data[old_vocab:old_vocab+num_added] = new\n",
        "print(f\"[Init] added={num_added} | target_L2≈{target_radius:.3f}\")\n",
        "\n",
        "# ----- freeze all; train only embeddings (new rows masked) -----\n",
        "for n,p in model.named_parameters(): p.requires_grad=False\n",
        "wte.weight.requires_grad=True\n",
        "\n",
        "new_rows = torch.arange(old_vocab, old_vocab+num_added, device=wte.weight.device) if num_added>0 else None\n",
        "base_rows = torch.arange(0, old_vocab, device=wte.weight.device)\n",
        "def mask_grad(grad):\n",
        "    if grad is None or new_rows is None: return grad\n",
        "    grad[base_rows]=0; return grad\n",
        "wte.weight.register_hook(mask_grad)\n",
        "\n",
        "def clamp_rows_(emb, max_norm):\n",
        "    if max_norm is None or new_rows is None: return\n",
        "    rows = emb.weight.data[old_vocab:old_vocab+num_added]\n",
        "    norms = rows.norm(dim=1, keepdim=True).clamp_min(1e-8)\n",
        "    scale = (max_norm/norms).clamp_max(1.0)\n",
        "    emb.weight.data[old_vocab:old_vocab+num_added] = rows*scale\n",
        "\n",
        "# ----- tiny torch Dataset that makes SEQ_LEN blocks -----\n",
        "class BlockDataset(Dataset):\n",
        "    def __init__(self, path, tokenizer, seq_len=1024, stride=1024):\n",
        "        if not os.path.exists(path):\n",
        "            stub = (\"riverrun, past Eve and Adam’s, from swerve of shore to bend of bay, \"\n",
        "                    \"brings us by a commodius vicus of recirculation to Howth Castle and Environs. \")\n",
        "            text = stub * 1000\n",
        "        else:\n",
        "            text = open(path, \"r\", encoding=\"utf-8\").read()\n",
        "        ids = tokenizer(text, add_special_tokens=False)[\"input_ids\"]\n",
        "        blocks = []\n",
        "        for i in range(0, max(1, len(ids)-seq_len), stride):\n",
        "            chunk = ids[i:i+seq_len]\n",
        "            if len(chunk) >= seq_len//2:\n",
        "                blocks.append(chunk[:seq_len])\n",
        "        self.blocks = blocks\n",
        "    def __len__(self): return len(self.blocks)\n",
        "    def __getitem__(self, idx):\n",
        "        ids = torch.tensor(self.blocks[idx], dtype=torch.long)\n",
        "        return {\"input_ids\": ids, \"labels\": ids.clone()}\n",
        "\n",
        "train_ds = BlockDataset(CORPUS_TXT, tok, seq_len=SEQ_LEN, stride=STRIDE)\n",
        "print(f\"[Data] chunks={len(train_ds)} @ seq_len={SEQ_LEN}\")\n",
        "\n",
        "coll = DataCollatorForLanguageModeling(tokenizer=tok, mlm=False)\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "# ----- geometry snapshot (pre) -----\n",
        "@torch.no_grad()\n",
        "def isotropy(M):\n",
        "    u, s, v = torch.pca_lowrank(M - M.mean(0, keepdim=True), q=min(128, M.shape[1]-1))\n",
        "    return float((s.max() / s.min().clamp_min(1e-8)))\n",
        "\n",
        "@torch.no_grad()\n",
        "def pip_loss(A, B):\n",
        "    return float(torch.norm((A@A.T)-(B@B.T), p='fro')/(A.shape[0]**2))\n",
        "\n",
        "@torch.no_grad()\n",
        "def topk_overlap(M1, M2, k=10, sample=1000):\n",
        "    W1 = M1/(M1.norm(dim=1, keepdim=True)+1e-8); W2 = M2/(M2.norm(dim=1, keepdim=True)+1e-8)\n",
        "    vocab = W1.shape[0]; idxs = random.sample(range(vocab), min(sample, vocab))\n",
        "    acc = 0.0\n",
        "    for i in idxs:\n",
        "        c1 = torch.topk(W1 @ W1[i], k+1).indices.tolist(); c1=[j for j in c1 if j!=i][:k]\n",
        "        c2 = torch.topk(W2 @ W2[i], k+1).indices.tolist(); c2=[j for j in c2 if j!=i][:k]\n",
        "        acc += len(set(c1)&set(c2))/k\n",
        "    return float(acc/len(idxs))\n",
        "\n",
        "with torch.no_grad():\n",
        "    pre_full = wte.weight.detach().clone().cpu()\n",
        "    pre_new  = pre_full[old_vocab:old_vocab+num_added].clone() if num_added>0 else torch.empty(0, pre_full.shape[1])\n",
        "\n",
        "# ----- Trainer (embed-only + repulsion + clamp) -----\n",
        "class EmbOnlyTrainer(Trainer):\n",
        "    def create_optimizer(self):\n",
        "        from torch.optim import AdamW\n",
        "        if not hasattr(self, \"optimizer\") or self.optimizer is None:\n",
        "            self.optimizer = AdamW([{\"params\": [wte.weight], \"lr\": LR, \"weight_decay\": 0.0}],\n",
        "                                   betas=(0.9, 0.999), eps=1e-8)\n",
        "        return self.optimizer\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        out = model(**inputs); loss = out.loss\n",
        "        if num_added and num_added>1 and REPULSION_W>0:\n",
        "            E = model.get_input_embeddings().weight[old_vocab:old_vocab+num_added]\n",
        "            E = E - E.mean(0, keepdim=True); E = E/(E.norm(dim=1, keepdim=True)+1e-8)\n",
        "            sims = (E @ E.t()); repul = (sims - torch.eye(E.shape[0], device=E.device)).pow(2).mean()\n",
        "            loss = loss + REPULSION_W*repul\n",
        "        return (loss, out) if return_outputs else loss\n",
        "    def training_step(self, *args, **kwargs):\n",
        "        out = super().training_step(*args, **kwargs)\n",
        "        clamp_rows_(model.get_input_embeddings(), MAX_ROW_NORM)\n",
        "        return out\n",
        "\n",
        "# epoch math (informational)\n",
        "eff_batch = 1 * GRAD_ACCUM\n",
        "steps_per_epoch = math.ceil(len(train_ds) / eff_batch)\n",
        "print(f\"[Epochs] steps/epoch≈{steps_per_epoch} | epochs@{MAX_STEPS}≈{MAX_STEPS/steps_per_epoch:.2f}\")\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=RUN_DIR, per_device_train_batch_size=1, gradient_accumulation_steps=GRAD_ACCUM,\n",
        "    learning_rate=LR, max_steps=MAX_STEPS, warmup_steps=max(20, MAX_STEPS//20),\n",
        "    lr_scheduler_type=\"cosine\", weight_decay=0.0, fp16=True, bf16=False,\n",
        "    logging_steps=LOG_STEPS, save_steps=SAVE_STEPS, save_total_limit=6,\n",
        "    eval_strategy=\"no\", report_to=\"none\", dataloader_pin_memory=False,\n",
        "    gradient_checkpointing=True,\n",
        ")\n",
        "\n",
        "trainer = EmbOnlyTrainer(model=model, args=args, data_collator=coll, train_dataset=train_ds)\n",
        "print(f\"[Run] base={MODEL_NAME} | steps={MAX_STEPS} | seq_len={SEQ_LEN} | accum={GRAD_ACCUM} | LR={LR}\")\n",
        "trainer.train()\n",
        "\n",
        "# ----- save artifacts -----\n",
        "save_dir = os.path.join(RUN_DIR, \"embedding_only\"); os.makedirs(save_dir, exist_ok=True)\n",
        "torch.save(wte.weight.detach().cpu(), os.path.join(save_dir, \"embed_tokens.pt\"))\n",
        "with open(os.path.join(save_dir, \"added_tokens.json\"), \"w\") as f:\n",
        "    json.dump({\"added_tokens\": missing, \"old_vocab\": old_vocab, \"num_added\": num_added}, f, indent=2)\n",
        "tok.save_pretrained(RUN_DIR)\n",
        "\n",
        "# ----- receipts (post) -----\n",
        "with torch.no_grad():\n",
        "    post_full = wte.weight.detach().clone().cpu()\n",
        "    post_new  = post_full[old_vocab:old_vocab+num_added].clone() if num_added>0 else torch.empty(0, pre_full.shape[1])\n",
        "\n",
        "report = {\n",
        "  \"model\": MODEL_NAME, \"added_tokens\": int(num_added), \"old_vocab\": int(old_vocab),\n",
        "  \"pip_loss_full\": pip_loss(pre_full, post_full),\n",
        "  \"topk_overlap_all\": topk_overlap(pre_full, post_full, k=10, sample=min(REPORT_SAMPLE, pre_full.shape[0]-1)),\n",
        "  \"isotropy_pre\": isotropy(pre_full), \"isotropy_post\": isotropy(post_full),\n",
        "  \"pip_loss_new_rows\": (pip_loss(pre_new, post_new) if num_added>1 else None),\n",
        "  \"isotropy_new_rows\": (isotropy(post_new) if num_added>1 else None),\n",
        "}\n",
        "json.dump(report, open(os.path.join(RUN_DIR, \"geometry_report.json\"), \"w\"), indent=2)\n",
        "print(\"\\n=== GEOMETRY REPORT ===\")\n",
        "for k,v in report.items(): print(f\"{k}: {v}\")"
      ],
      "metadata": {
        "id": "C6i7XJDEmwA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tok = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.3\", token=True)\n",
        "print(\"OK:\", tok is not None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "6f7a2d3073db42a69c6c72e6319b04c3",
            "e7bd7442f6e74d7caefc04111e51f963",
            "9f79bbdecff446f3bf8fe01806967290",
            "d8e640caacdb491fa029a4da23d8368c",
            "a2f5b755a3674b36b319387822a88306",
            "7c96890e009149acbc1f2507a2fff27d",
            "3ca67e03c87240da887a0e96468f3ae2",
            "9f623e0431d74e5882fcf3c74e4904eb",
            "62da1cc9711a46ff89e54fbecd4b1ee6",
            "0ed8d621ae6c4393809b318e66158226",
            "dab4addcd1fe48898d4da26f2538d007",
            "219d2ee0b6a74da09dedfc2c07d2b16e",
            "14a7483535764de3b30287b467a33b86",
            "907c7ef0029248f2a78b4006d0449d80",
            "07ead01a97b1494ba8f383130008a297",
            "1e5b48f132804ed2a20cd7af52685859",
            "518c78b2c4524f84b5a4296d3b92eeb7",
            "66fbaa67d5714f4e894b08da15c725a5",
            "53f7a43cccc0431eb0511801b6b513d8",
            "20a5357d18da47eab4ec2f2209567d77",
            "004952e10ef944acac3ca53caff1041d",
            "24616af8ce2847d6a0f61b462fe3162e",
            "12d543ca3242425795c92109f5f08fd7",
            "44f5a5fba3854cd38bb138bcfc72aef1",
            "7c7a94e848474c4592ee319ea428ec17",
            "a4aacca7d53f48f8b97995491edbfb8b",
            "e1a3c5e008eb407b91547d5c0844efd1",
            "67f71e7ab9c8423cbee3c5e45846d4b9",
            "489f1a14dd2b495bb190da1a2edf896f",
            "576ad730ac2b4c7d9f6ded605be7e1a8",
            "8a3dab8d380e41808228505c47a3d4e0",
            "b07ba6d1383e45d994dc4196994a1f39",
            "1da280c3374a498d8ac88cca923009d7",
            "4a455ee83a19480b8092f91e3242237a",
            "78d402d0043c438db8dc98ecdef766e4",
            "e1b44edfac40408d91ac85e4e42795fd",
            "29097c31b890418a8cd32520cfd64acc",
            "e97156bc793a49d795ac8cbfa145ac78",
            "66c341ebccaf4461abfa924ff9d5b71d",
            "d360959b03fa4a5bbaf13f8762e0f731",
            "0e10a75ed3c74266b1255219b204cda9",
            "083037c09792409ab8837b1e8f041890",
            "f2d3b20a566d437ba2a5f3c7ae8ca429",
            "3ff726f485204b5e86e881ff39f7d5f4"
          ]
        },
        "id": "nNFMTtIC75yb",
        "outputId": "d2d48a28-8323-49d1-fac3-be70923b6009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f7a2d3073db42a69c6c72e6319b04c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "219d2ee0b6a74da09dedfc2c07d2b16e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12d543ca3242425795c92109f5f08fd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a455ee83a19480b8092f91e3242237a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wake2Vec: fuck the embeddings\n",
        "# Loads Mistral-7B in 4-bit\n",
        "# minimal PEFT adapter (r=1) to fix \"no pure-quant training\"\n",
        "# Freezes everything; optimizer updates ONLY input embeddings\n",
        "\n",
        "!pip -q install -U transformers==4.45.2 accelerate==0.34.2 datasets==3.0.1 bitsandbytes==0.44.1 peft==0.13.2 --progress-bar off\n",
        "\n",
        "import os, math, json, random, gc, torch, torch.nn as nn\n",
        "from datasets import Dataset\n",
        "from transformers import (AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig,\n",
        "                          DataCollatorForLanguageModeling, TrainingArguments, Trainer, set_seed)\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "# CONFIG\n",
        "SEED = 42\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-v0.3\"           # swap to LLaMA\n",
        "WAKE_LEX_PATH = \"/content/wake_lexicon.txt\"\n",
        "CORPUS_TXT    = \"/content/finnegans_wake.txt\"\n",
        "RUN_DIR = \"/content/wake_llama_embs\"\n",
        "SEQ_LEN = 1024\n",
        "MAX_STEPS = 1100\n",
        "LOG_STEPS = 20\n",
        "SAVE_STEPS = 200\n",
        "LR = 8e-4\n",
        "GRAD_ACCUM = 8\n",
        "REPULSION_W = 0.05\n",
        "TARGET_NORM = None            # e.g., 1.8 * base_radius\n",
        "MAX_ROW_NORM = None           # e.g., 2.0 * base_radius\n",
        "REPORT_SAMPLE = 1500\n",
        "\n",
        "os.makedirs(RUN_DIR, exist_ok=True); set_seed(SEED)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Torch:\", torch.__version__, \"| CUDA:\", torch.version.cuda, \"| GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n",
        "\n",
        "# helpers\n",
        "def read_lines(p, fb=None):\n",
        "    if not os.path.exists(p): return fb or []\n",
        "    return [x.strip() for x in open(p, encoding=\"utf-8\") if x.strip()]\n",
        "\n",
        "def read_corpus(p):\n",
        "    if not os.path.exists(p):\n",
        "        s = (\"riverrun, past Eve and Adam’s, from swerve of shore to bend of bay, \"\n",
        "             \"brings us by a commodius vicus of recirculation to Howth Castle and Environs.\")\n",
        "        return Dataset.from_dict({\"text\":[s]*1000})\n",
        "    txt = open(p, \"r\", encoding=\"utf-8\").read()\n",
        "    paras = [t.strip() for t in txt.split(\"\\n\") if t.strip()]\n",
        "    return Dataset.from_dict({\"text\": paras})\n",
        "\n",
        "def pack_causal(ex, tok, block):\n",
        "    ids = tok(\"\\n\\n\".join(ex[\"text\"]), add_special_tokens=False)[\"input_ids\"]\n",
        "    chunks = [ids[i:i+block] for i in range(0, len(ids)-block, block)]\n",
        "    return {\"input_ids\": chunks, \"labels\": chunks.copy()}\n",
        "\n",
        "def isotropy(M):\n",
        "    u, s, v = torch.pca_lowrank(M - M.mean(0, keepdim=True), q=min(128, M.shape[1]-1))\n",
        "    return float((s.max() / s.min().clamp_min(1e-8)))\n",
        "\n",
        "def pip_loss(A, B):\n",
        "    return float(torch.norm((A@A.T)-(B@B.T), p='fro')/(A.shape[0]**2))\n",
        "\n",
        "def topk_overlap(M1, M2, k=10, sample=1000):\n",
        "    W1 = M1/(M1.norm(dim=1, keepdim=True)+1e-8); W2 = M2/(M2.norm(dim=1, keepdim=True)+1e-8)\n",
        "    vocab = W1.shape[0]; idxs = random.sample(range(vocab), min(sample, vocab))\n",
        "    acc = 0.0\n",
        "    for i in idxs:\n",
        "        c1 = torch.topk(W1 @ W1[i], k+1).indices.tolist(); c1=[j for j in c1 if j!=i][:k]\n",
        "        c2 = torch.topk(W2 @ W2[i], k+1).indices.tolist(); c2=[j for j in c2 if j!=i][:k]\n",
        "        acc += len(set(c1)&set(c2))/k\n",
        "    return float(acc/len(idxs))\n",
        "\n",
        "# load quantized model\n",
        "bnb = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_use_double_quant=True,\n",
        "                         bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.float16)\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "if tok.pad_token is None: tok.pad_token = tok.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, quantization_config=bnb,\n",
        "                                             torch_dtype=torch.float16, device_map=\"auto\")\n",
        "if hasattr(model, \"tie_weights\"): model.tie_weights()\n",
        "model.config.tie_word_embeddings = True\n",
        "\n",
        "# minimal PEFT adapter (fix for \"no pure-quant training\")\n",
        "peft_cfg = LoraConfig(\n",
        "    r=1, lora_alpha=1, lora_dropout=0.0,\n",
        "    target_modules=[\"q_proj\"],   # for Mistral/LLaMA/Qwen; Falcon would be [\"query_key_value\"]\n",
        "    bias=\"none\", task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, peft_cfg)\n",
        "\n",
        "# inject Wake lexicon\n",
        "wake = read_lines(WAKE_LEX_PATH)\n",
        "missing = [t for t in wake if tok.convert_tokens_to_ids(t)==tok.unk_token_id]\n",
        "num_added = tok.add_tokens(missing, special_tokens=False)\n",
        "old_vocab = model.get_input_embeddings().weight.shape[0]\n",
        "model.resize_token_embeddings(len(tok))\n",
        "wte = model.get_input_embeddings()\n",
        "if hasattr(model, \"lm_head\"): model.lm_head.weight = wte.weight\n",
        "\n",
        "# spherical kick init for new rows\n",
        "with torch.no_grad():\n",
        "    base = wte.weight[:old_vocab]; dim = base.shape[1]\n",
        "    std = base.std().item(); base_radius = std * math.sqrt(dim)\n",
        "    target_radius = TARGET_NORM or (1.5 * base_radius)\n",
        "    if num_added>0:\n",
        "        new = torch.randn((num_added, dim), device=wte.weight.device)\n",
        "        new = new/(new.norm(dim=1, keepdim=True)+1e-8)*target_radius\n",
        "        wte.weight.data[old_vocab:old_vocab+num_added] = new\n",
        "print(f\"[Init] new rows: {num_added} | target L2 ≈ {target_radius:.3f}\")\n",
        "\n",
        "# trainables: ONLY embeddings (LoRA params remain frozen)\n",
        "for n,p in model.named_parameters(): p.requires_grad=False\n",
        "wte.weight.requires_grad=True\n",
        "new_rows = torch.arange(old_vocab, old_vocab+num_added, device=wte.weight.device) if num_added>0 else None\n",
        "base_rows = torch.arange(0, old_vocab, device=wte.weight.device)\n",
        "\n",
        "def mask_grad(grad):\n",
        "    if grad is None or new_rows is None: return grad\n",
        "    grad[base_rows]=0; return grad\n",
        "wte.weight.register_hook(mask_grad)\n",
        "\n",
        "def clamp_rows_(emb, max_norm):\n",
        "    if max_norm is None or new_rows is None: return\n",
        "    rows = emb.weight.data[old_vocab:old_vocab+num_added]\n",
        "    norms = rows.norm(dim=1, keepdim=True).clamp_min(1e-8)\n",
        "    scale = (max_norm/norms).clamp_max(1.0)\n",
        "    emb.weight.data[old_vocab:old_vocab+num_added] = rows*scale\n",
        "\n",
        "# data\n",
        "ds = read_corpus(CORPUS_TXT)\n",
        "split = ds.train_test_split(test_size=0.05, seed=SEED)\n",
        "tok_tr = split[\"train\"].map(lambda e: pack_causal(e, tok, SEQ_LEN), batched=True, remove_columns=[\"text\"])\n",
        "tok_ev = split[\"test\"].map(lambda e: pack_causal(e, tok, SEQ_LEN), batched=True, remove_columns=[\"text\"])\n",
        "coll = DataCollatorForLanguageModeling(tokenizer=tok, mlm=False)\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "# receipts\n",
        "with torch.no_grad():\n",
        "    pre_full = wte.weight.detach().clone().cpu()\n",
        "    pre_new  = pre_full[old_vocab:old_vocab+num_added].clone() if num_added>0 else torch.empty(0, pre_full.shape[1])\n",
        "\n",
        "# custom trainer\n",
        "class EmbOnlyTrainer(Trainer):\n",
        "    def create_optimizer(self):\n",
        "        from torch.optim import AdamW\n",
        "        if not hasattr(self, \"optimizer\") or self.optimizer is None:\n",
        "            self.optimizer = AdamW([{\"params\": [wte.weight], \"lr\": LR, \"weight_decay\": 0.0}],\n",
        "                                   betas=(0.9, 0.999), eps=1e-8)\n",
        "        return self.optimizer\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        out = model(**inputs); loss = out.loss\n",
        "        if num_added and num_added>1 and REPULSION_W>0:\n",
        "            E = model.get_input_embeddings().weight[old_vocab:old_vocab+num_added]\n",
        "            E = E - E.mean(0, keepdim=True); E = E/(E.norm(dim=1, keepdim=True)+1e-8)\n",
        "            sims = (E @ E.t()); repul = (sims - torch.eye(E.shape[0], device=E.device)).pow(2).mean()\n",
        "            loss = loss + REPULSION_W*repul\n",
        "        return (loss, out) if return_outputs else loss\n",
        "    def training_step(self, *args, **kwargs):\n",
        "        out = super().training_step(*args, **kwargs)\n",
        "        clamp_rows_(model.get_input_embeddings(), MAX_ROW_NORM)\n",
        "        return out\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=RUN_DIR, per_device_train_batch_size=1, gradient_accumulation_steps=GRAD_ACCUM,\n",
        "    learning_rate=LR, max_steps=MAX_STEPS, warmup_steps=max(20, MAX_STEPS//20),\n",
        "    lr_scheduler_type=\"cosine\", weight_decay=0.0, fp16=True, bf16=False,\n",
        "    logging_steps=LOG_STEPS, save_steps=SAVE_STEPS, save_total_limit=3,\n",
        "    eval_strategy=\"no\", report_to=\"none\", dataloader_pin_memory=False,\n",
        "    gradient_checkpointing=True,\n",
        ")\n",
        "\n",
        "trainer = EmbOnlyTrainer(model=model, args=args, data_collator=coll, train_dataset=tok_tr)\n",
        "print(f\"[Run] emb-only | base={MODEL_NAME} | steps={MAX_STEPS} | seq_len={SEQ_LEN} | accum={GRAD_ACCUM} | LR={LR}\")\n",
        "trainer.train()\n",
        "\n",
        "# save deltas\n",
        "save_dir = os.path.join(RUN_DIR, \"embedding_only\"); os.makedirs(save_dir, exist_ok=True)\n",
        "torch.save(wte.weight.detach().cpu(), os.path.join(save_dir, \"embed_tokens.pt\"))\n",
        "with open(os.path.join(save_dir, \"added_tokens.json\"), \"w\") as f:\n",
        "    json.dump({\"added_tokens\": missing, \"old_vocab\": old_vocab, \"num_added\": num_added}, f, indent=2)\n",
        "tok.save_pretrained(RUN_DIR)\n",
        "\n",
        "# receipts\n",
        "with torch.no_grad():\n",
        "    post_full = wte.weight.detach().clone().cpu()\n",
        "    post_new  = post_full[old_vocab:old_vocab+num_added].clone() if num_added>0 else torch.empty(0, post_full.shape[1])\n",
        "\n",
        "report = {\n",
        "  \"model\": MODEL_NAME, \"added_tokens\": int(num_added), \"old_vocab\": int(old_vocab),\n",
        "  \"pip_loss_full\": pip_loss(pre_full, post_full),\n",
        "  \"topk_overlap_all\": topk_overlap(pre_full, post_full, k=10, sample=min(REPORT_SAMPLE, pre_full.shape[0]-1)),\n",
        "  \"isotropy_pre\": isotropy(pre_full), \"isotropy_post\": isotropy(post_full),\n",
        "  \"pip_loss_new_rows\": (pip_loss(pre_new, post_new) if num_added>1 else None),\n",
        "  \"isotropy_new_rows\": (isotropy(post_new) if num_added>1 else None),\n",
        "}\n",
        "json.dump(report, open(os.path.join(RUN_DIR, \"geometry_report.json\"), \"w\"), indent=2)\n",
        "print(\"\\n=== GEOMETRY REPORT ===\")\n",
        "for k,v in report.items(): print(f\"{k}: {v}\")"
      ],
      "metadata": {
        "id": "cqct0zKAILxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re, json, random, pathlib\n",
        "from collections import defaultdict\n",
        "wake_text = pathlib.Path(\"/content/finnegans_wake.txt\").read_text(encoding=\"utf-8\")\n",
        "lex = [l.strip() for l in pathlib.Path(\"/content/wake_lexicon.txt\").read_text(encoding=\"utf-8\").splitlines() if l.strip()]\n",
        "idx = defaultdict(list)\n",
        "for tok in lex:\n",
        "    for m in re.finditer(re.escape(tok), wake_text, re.IGNORECASE):\n",
        "        i = m.start(); left = max(0, i-256); right = min(len(wake_text), i+256)\n",
        "        idx[tok].append(wake_text[left:right].replace(\"\\n\",\" \"))\n",
        "with open(\"contexts.jsonl\",\"w\",encoding=\"utf-8\") as f:\n",
        "    for tok in lex:\n",
        "        ctxs = idx.get(tok, [])\n",
        "        random.shuffle(ctxs)\n",
        "        for c in ctxs[:100]:  # cap per token\n",
        "            f.write(json.dumps({\"token\":tok, \"text\":c, \"label\":\"pos\", \"source\":\"wake\"})+\"\\n\")"
      ],
      "metadata": {
        "id": "X39bxK-DkZ_J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}