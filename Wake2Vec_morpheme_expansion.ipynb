{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1YxzvmFZN2PQfgwhi2bHbtrfisacZGGgb",
      "authorship_tag": "ABX9TyM+ip7W5wSvJTTXC1A4qS5X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahb97/Wake2vec/blob/main/Wake2Vec_morpheme_expansion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wake2Vec Morpheme Expansion Pipeline\n",
        "\n",
        "This notebook documents a controlled procedure for integrating Joyce-style neologisms into a compact GPT-type language model through morphology-aware token expansion. I curate a small lexicon of prefixes and suffixes and generate synthetic candidates, then extend the tokenizer to admit previously split neologisms as single tokens. New embeddings are initialised by morphemic composition, using the rule \\(E(\\text{word}) = \\alpha\\,E(\\text{prefix}) + (1 - 2\\alpha)\\,E(\\text{root}) + \\alpha\\,E(\\text{suffix}) + \\varepsilon\\), where \\(\\alpha\\) is a fixed weight and \\(\\varepsilon\\) is small Gaussian noise that prevents identical vectors. Training proceeds in two stages: an embedding-only warm-up on a mixture of synthetic lines and Finnegans *Wake* text, followed by a short full-model fine-tune under conservative schedules suitable for a T4 environment.\n",
        "\n",
        " I report top-five neighbor overlap for the newly introduced tokens before and after training, track shifts in embedding norms, provide a t-SNE projection of the new tokens against pre-training neighbor centroids, and save JSON snapshots of neighborhoods at each stage. These diagnostics are intended to show coherent integration of the new forms into the embedding space rather than collapse or runaway drift, and to make the procedure straightforward to reproduce on modest hardware.\n",
        "\n",
        "**Config**\n",
        "\n",
        "Base model: `TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T`. Composition weight \\(\\alpha = 0.25\\). Maximum sequence length set to 1024 to respect T4 memory limits. Batching uses `per_device_train_batch_size = 1` with `gradient_accumulation_steps = 8`, attention implementation set to `eager`, and `use_cache = False`. Phase 1 trains input embeddings and the tied output head only; Phase 2 unfreezes all parameters with a warm-up ratio of 0.10 and light weight decay. All runs write plots and machine-readable artifacts to `runs/<RUN_ID>/` and generate a brief HTML report.\n",
        "\n",
        "---\n",
        "\n",
        "## Run controls\n",
        "- **BASE_MODEL:** `TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T`\n",
        "- **α (composition weight):** `0.25` (can tune)\n",
        "- **Max seq length:** `1024` (T4-safe; raise only if VRAM allows)\n",
        "- **Batching:** `per_device_train_batch_size=1`, `gradient_accumulation_steps=8`\n",
        "- **Attn impl:** `eager` (avoid SDPA spikes on T4)\n",
        "- **Two phases:**\n",
        "  - **Phase 1:** embeddings + lm_head only, Adafactor/8-bit Adam, 1 epoch\n",
        "  - **Phase 2:** full model, short run, warmup 0.10\n",
        "\n",
        "## Inputs\n",
        "- `data/FW_TEXT.txt` — Finnegans Wake plain text (slice for demo)\n",
        "- `data/morpheme_data.json` or `data/morphemes.csv`  \n",
        "  Structure maps:\n",
        "  - `prefixes`: `{ prefix → [example words…] }`\n",
        "  - `suffixes`: `{ suffix → [example words…] }`\n",
        "\n",
        "## Outputs (per run)\n",
        "- `runs/<RUN_ID>/metrics/`\n",
        "  - `pre_morpheme_snapshot.json`\n",
        "  - `morpheme_comparison_p1.json` *(midpoint, after Phase 1)*\n",
        "  - `morpheme_comparison.json` *(final, after Phase 2)*\n",
        "  - `summary_stats_p1.json`, `summary_stats.json`\n",
        "- `runs/<RUN_ID>/plots/`\n",
        "  - `hist_overlap_top5(_p1).png`, `hist_norm_change(_p1).png`\n",
        "  - `scatter_norm_vs_overlap.png`, `tsne_newtokens_vs_precentroids.png`\n",
        "- `reports/Wake2Vec_Report.html`\n",
        "\n",
        "## Quickstart\n",
        "1. **Reset & install** deps (Colab-friendly).  \n",
        "2. **Load data** (prefers JSON).  \n",
        "3. **Generate** synthetic forms (prefix + root + suffix).  \n",
        "4. **Expand tokenizer** (add new tokens); compose embeddings with α-rule; tie head.  \n",
        "5. **Phase 1**: train embeddings only. Saves midpoint snapshot.\n",
        "6. **Phase 2**: unfreeze and short fine-tune.  \n",
        "7. **Diagnostics**: compute overlap@5, norm deltas, t-SNE; write HTML report.  \n",
        "\n",
        "\n",
        "## Diagnostics (what “good” looks like)\n",
        "- **Top-5 neighbor overlap (pre→post):** ~3–4/5 indicates coherent integration (not collapse).\n",
        "- **Norm shift (Δ‖E‖):** small positive mean (slight energy increase from training).\n",
        "- **Qualitative neighbors:** morpheme-aligned (e.g., `presounder` ≈ `resound`, `ensounder`, …).\n",
        "- **Tokenization:** most synthetic forms now **single IDs**.\n",
        "\n",
        "## Repro & env\n",
        "- `RUN_ID = \"t4_<unix>\"` auto-stamped; seeds fixed at 42.\n",
        "- Tested on Colab T4 with: `transformers 4.57.1`, `datasets 2.21.0`, `pyarrow 22.0.0`.\n",
        "- T4 guardrails: `MAX_LEN=1024`, `gradient_checkpointing=True`, attention=`eager`, batch=1 + accum=8.\n",
        "\n",
        "## Troubleshooting (T4)\n",
        "- **CUDA OOM** → lower `MAX_LEN` to 768/512; keep batch=1; accum=8–16; ensure `use_cache=False`; `PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True`.\n",
        "- **Version noise** → uninstall RAPIDS/TF; pin `transformers 4.57.1`, `datasets 2.21.0`, `pyarrow 22.0.0`.\n",
        "\n",
        "---\n",
        "\n",
        " *Wake2Vec tests morphology-aware token expansion to integrate Joyce-style neologisms into a small language model without destabilising the embedding space. We curate a prefix/suffix lexicon, generate synthetic forms, initialise new vectors by morpheme composition, and train in two phases. Evaluation reports neighbor-overlap@5, embedding-norm shifts, and qualitative neighborhoods, with JSON snapshots for reproducibility.*\n"
      ],
      "metadata": {
        "id": "Ovb6LuW8cVUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q uninstall -y cudf-cu12 pylibcudf-cu12 cuml-cu12 dask-cudf-cu12 cupy-cuda12x tensorflow opencv-python-headless opencv-contrib-python opencv-python >/dev/null\n",
        "\n",
        "!pip -q install --no-cache-dir --upgrade-strategy eager \\\n",
        "  \"transformers==4.57.1\" \"accelerate>=0.33\" \"tokenizers>=0.15\" \"safetensors\" \\\n",
        "  \"datasets==2.21.0\" \"evaluate>=0.4.0\" \"pyarrow==22.0.0\" \\\n",
        "  \"huggingface-hub>=0.34,<1.0\" \"bitsandbytes>=0.43\" \\\n",
        "  \"umap-learn\" \"faiss-cpu\" \"wordfreq\" \"Unidecode\" \"matplotlib\" \"scikit-learn\"\n",
        "\n",
        "import transformers, datasets, pyarrow\n",
        "print(\"Transformers:\", transformers.__version__)\n",
        "print(\"datasets:\", datasets.__version__)\n",
        "print(\"pyarrow:\", pyarrow.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shcc5QFPT7iJ",
        "outputId": "230a11a3-dfbd-472d-d5ca-045f4f7d82c3",
        "collapsed": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping cudf-cu12 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping pylibcudf-cu12 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping cuml-cu12 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping dask-cudf-cu12 as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping cupy-cuda12x as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-python-headless as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mTransformers: 4.57.1\n",
            "datasets: 2.21.0\n",
            "pyarrow: 22.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports, seeds, run IDs, paths"
      ],
      "metadata": {
        "id": "LJd_oDr2evlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, time, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "RUN_ID = f\"t4_{int(time.time())}\"\n",
        "ROOT = Path(\"/content\")\n",
        "RUN_DIR = ROOT / \"runs\" / RUN_ID\n",
        "PLOTS_DIR = RUN_DIR / \"plots\"\n",
        "METRICS_DIR = RUN_DIR / \"metrics\"\n",
        "REPORTS_DIR = ROOT / \"reports\"\n",
        "for p in (PLOTS_DIR, METRICS_DIR, REPORTS_DIR): p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "META = {\n",
        "    \"run_id\": RUN_ID, \"seed\": SEED, \"alpha\": 0.25,\n",
        "    \"phase1\": {\"lr\": 5e-4, \"epochs\": 1, \"ptd_bs\": 8, \"grad_accum\": 2},\n",
        "    \"phase2\": {\"lr\": 2e-5, \"epochs\": 2, \"warmup_ratio\": 0.10, \"ptd_bs\": 8, \"grad_accum\": 2, \"weight_decay\": 0.01}\n",
        "}\n",
        "(METRICS_DIR/\"meta.json\").write_text(json.dumps(META, indent=2))\n",
        "print(\"RUN_ID:\", RUN_ID)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7Vjjx2oVFmX",
        "outputId": "7ebd0c33-480f-4350-a8fb-0cb2294cd7fc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUN_ID: t4_1761966609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data"
      ],
      "metadata": {
        "id": "txo87v9YgG-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import json, csv\n",
        "\n",
        "DATA_DIR = ROOT/\"data\"; DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "FW_PATH   = DATA_DIR/\"/content/FW_TEXT.txt\"\n",
        "JSON_PATH = DATA_DIR/\"/content/morpheme_data.json\"\n",
        "CSV_PATH  = DATA_DIR/\"/content/morphemes.csv\"\n",
        "\n",
        "def load_morpheme_csv(path):\n",
        "    d = {\"prefixes\": {}, \"suffixes\": {}}\n",
        "    with open(path, newline=\"\", encoding=\"utf-8\") as f:\n",
        "        rdr = csv.reader(f); header = next(rdr, None)\n",
        "        for row in rdr:\n",
        "            if not row: continue\n",
        "            typ, morpheme, *examples = [x.strip() for x in row]\n",
        "            if typ not in (\"prefix\",\"suffix\"): continue\n",
        "            key = \"prefixes\" if typ==\"prefix\" else \"suffixes\"\n",
        "            ex = [w for w in dict.fromkeys(examples) if w]\n",
        "            if ex: d[key][morpheme] = ex\n",
        "    return d\n",
        "\n",
        "if JSON_PATH.exists():\n",
        "    MORPHEME_DATA = json.load(open(JSON_PATH, \"r\", encoding=\"utf-8\"))\n",
        "elif CSV_PATH.exists():\n",
        "    MORPHEME_DATA = load_morpheme_csv(CSV_PATH)\n",
        "else:\n",
        "    raise FileNotFoundError(\"Put morpheme_data.json or morphemes.csv in /content/data\")\n",
        "\n",
        "prefixes = MORPHEME_DATA.get(\"prefixes\", {})\n",
        "suffixes = MORPHEME_DATA.get(\"suffixes\", {})\n",
        "\n",
        "if not FW_PATH.exists():\n",
        "    FW_PATH.write_text(\"Placeholder FW text.\\n\"*5000, encoding=\"utf-8\")\n",
        "FW_TEXT = FW_PATH.read_text(encoding=\"utf-8\")\n",
        "\n",
        "print(f\"Prefixes: {len(prefixes)} | Suffixes: {len(suffixes)} | FW chars: {len(FW_TEXT):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTFDpC9dVLzU",
        "outputId": "23b80304-e8a9-4d26-b93e-6b67b7c42f3e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prefixes: 15 | Suffixes: 15 | FW chars: 1,364,712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Synthetic generator"
      ],
      "metadata": {
        "id": "pzykhrzCKmy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def synthetic_words(n=1200, roots=(\"river thunder word sound dance queen storm tree night sun rain book\".split())):\n",
        "    out=set()\n",
        "    pfx_pool=[p for p,ex in prefixes.items() for _ in range(max(1,len(ex)//2+1))]\n",
        "    sfx_pool=[s for s,ex in suffixes.items() for _ in range(max(1,len(ex)//2+1))]\n",
        "    for _ in range(max(2*n, 2000)):\n",
        "        if not pfx_pool or not sfx_pool: break\n",
        "        p=random.choice(pfx_pool); s=random.choice(sfx_pool); r=random.choice(roots)\n",
        "        if len(p)+len(r)+len(s)>3: out.add(f\"{p}{r}{s}\")\n",
        "        if len(out)>=n: break\n",
        "    return sorted(out)\n",
        "\n",
        "SYN_WORDS = synthetic_words()\n",
        "SYN_LINES = [f\"The {w} rolled down the river at night.\" for w in random.sample(SYN_WORDS, min(400,len(SYN_WORDS)))]\n",
        "print(\"Synthetic words:\", len(SYN_WORDS), \"| synthetic lines:\", len(SYN_LINES))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4I0lXj5Vd2F",
        "outputId": "4f7729ea-50ac-4215-fe2d-51ac3648e83b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic words: 1200 | synthetic lines: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "base model, expand tokenizer, compose embeddings, tie head\n"
      ],
      "metadata": {
        "id": "Qq5P2pjnKv2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "BASE_MODEL = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
        "tok = AutoTokenizer.from_pretrained(BASE_MODEL, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, dtype=\"float32\", device_map=\"auto\")\n",
        "\n",
        "pre_token_splits = {w: tok.encode(w, add_special_tokens=False) for w in SYN_WORDS}\n",
        "new_tokens = [w for w, ids in pre_token_splits.items() if len(ids) > 1]\n",
        "added = tok.add_tokens(new_tokens, special_tokens=False)\n",
        "model.resize_token_embeddings(len(tok), mean_resizing=False)\n",
        "print(f\"Added tokens: {added} | Vocab size: {len(tok)}\")\n",
        "\n",
        "import torch\n",
        "def avg_vec(terms, emb, tok):\n",
        "    vecs=[]\n",
        "    for t in terms:\n",
        "        ids = tok.encode(t, add_special_tokens=False)\n",
        "        if len(ids)==1: vecs.append(emb.weight.data[ids[0]])\n",
        "    return torch.stack(vecs,0).mean(0) if vecs else None\n",
        "\n",
        "with torch.no_grad():\n",
        "    emb = model.get_input_embeddings()\n",
        "    alpha = META[\"alpha\"]; std = emb.weight.data.std().item()\n",
        "    for w in new_tokens:\n",
        "        p = next((p for p in prefixes if w.startswith(p)), None)\n",
        "        s = next((s for s in suffixes if w.endswith(s)), None)\n",
        "        root = w[len(p):len(w)-len(s)] if (p and s and len(w)>len(p)+len(s)) else w\n",
        "        vp = avg_vec(prefixes.get(p, []), emb, tok)\n",
        "        vs = avg_vec(suffixes.get(s, []), emb, tok)\n",
        "        vr_ids = tok.encode(root, add_special_tokens=False)\n",
        "        vr = emb.weight.data[vr_ids[0]] if len(vr_ids)==1 else torch.randn(emb.embedding_dim, device=emb.weight.device)*(std*0.5)\n",
        "        comp = alpha*(vp if vp is not None else vr) + (1-2*alpha)*vr + alpha*(vs if vs is not None else vr)\n",
        "        comp = comp + torch.randn_like(comp)*(std*0.01)\n",
        "        emb.weight.data[tok.convert_tokens_to_ids(w)] = comp\n",
        "    model.lm_head.weight = emb.weight\n",
        "\n",
        "print(\"Composed embeddings + tied head.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5_uilzdVkRl",
        "outputId": "69e34de1-a21e-42f1-f6a6-1e4632508f8d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added tokens: 1200 | Vocab size: 33200\n",
            "Composed embeddings + tied head.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token\n",
        "model.config.pad_token_id = tok.pad_token_id"
      ],
      "metadata": {
        "id": "Wun4Cf35Wj34"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "blocks + PRE snapshot"
      ],
      "metadata": {
        "id": "0yvf0QyoLGdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import json\n",
        "\n",
        "MAX_LEN=1024; STRIDE=512\n",
        "def make_blocks(text, max_len=MAX_LEN, stride=STRIDE):\n",
        "    ids = tok.encode(text, add_special_tokens=False)\n",
        "    return [{\"input_ids\": ids[i:i+max_len]} for i in range(0, max(0,len(ids)-max_len), stride) if len(ids[i:i+max_len])==max_len]\n",
        "\n",
        "train_text = \"\\n\".join(SYN_LINES) + \"\\n\" + FW_TEXT[:600_000]\n",
        "valid_text = FW_TEXT[600_000:630_000]\n",
        "train_ds = Dataset.from_list(make_blocks(train_text))\n",
        "valid_ds = Dataset.from_list(make_blocks(valid_text))\n",
        "dc = DataCollatorForLanguageModeling(tok, mlm=False)\n",
        "\n",
        "print(\"Train blocks:\", len(train_ds), \"| Valid blocks:\", len(valid_ds))\n",
        "\n",
        "with torch.no_grad():\n",
        "    W_pre = model.get_input_embeddings().weight.detach().clone().to(\"cpu\").numpy()\n",
        "    new_ids = [tok.convert_tokens_to_ids(t) for t in new_tokens]\n",
        "    sim_pre = cosine_similarity(W_pre[new_ids], W_pre)\n",
        "    top5_pre = np.argsort(-sim_pre, axis=1)[:,1:6]\n",
        "\n",
        "json.dump({\"new_tokens\": new_tokens, \"top5_pre\": top5_pre[:50].tolist()}, open(METRICS_DIR/\"pre_morpheme_snapshot.json\",\"w\"), indent=2)\n",
        "print(\"Saved pre snapshot.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXeYQJtIVsob",
        "outputId": "71952791-3209-4335-e1a0-d56ea2093543"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train blocks: 372 | Valid blocks: 16\n",
            "Saved pre snapshot.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P1 — embeddings-only warm-up"
      ],
      "metadata": {
        "id": "irYAXRooLSNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, torch, gc\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "gc.collect(); torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "kntqzcokXxhU"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# P1 Embedding-only warm-up\n",
        "import gc, torch\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "gc.collect(); torch.cuda.empty_cache()\n",
        "\n",
        "# Freeze everything except embeddings and lm_head\n",
        "def freeze_all_but_embeddings(m):\n",
        "    for p in m.parameters():\n",
        "        p.requires_grad = False\n",
        "    for p in m.get_input_embeddings().parameters():\n",
        "        p.requires_grad = True\n",
        "    for p in m.lm_head.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "freeze_all_but_embeddings(model)\n",
        "\n",
        "# Trainer args — tiny batch, big accum, checkpointing\n",
        "model.config.use_cache = False\n",
        "args1 = TrainingArguments(\n",
        "    output_dir=str(RUN_DIR/\"phase1\"),\n",
        "    per_device_train_batch_size=1,     # tiny batch\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=META[\"phase1\"][\"lr\"],\n",
        "    num_train_epochs=META[\"phase1\"][\"epochs\"],\n",
        "    eval_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=400,\n",
        "    eval_steps=400,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=False,                        # fp16 fragile on T4\n",
        "    load_best_model_at_end=False,\n",
        "    report_to=\"none\",\n",
        "    optim=\"adamw_bnb_8bit\",            # use 8-bit Adam if bitsandbytes is present\n",
        ")\n",
        "\n",
        "trainer1 = Trainer(\n",
        "    model=model,\n",
        "    args=args1,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=valid_ds,\n",
        "    data_collator=dc,\n",
        ")\n",
        "\n",
        "trainer1.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "-hpbA0aRZvRg",
        "outputId": "209ec861-3dec-4a10-c81d-3a5412e04241"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [47/47 17:45, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=47, training_loss=6.399282252534907, metrics={'train_runtime': 1083.9698, 'train_samples_per_second': 0.343, 'train_steps_per_second': 0.043, 'total_flos': 2214661416026112.0, 'train_loss': 6.399282252534907, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MID SNAPSHOT\n",
        "import json, torch, numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "MID_DIR = METRICS_DIR  # reuse same folder\n",
        "\n",
        "with torch.no_grad():\n",
        "    W_mid = model.get_input_embeddings().weight.detach().clone().to(\"cpu\").numpy()\n",
        "    sim_mid = cosine_similarity(W_mid[new_ids], W_mid)\n",
        "    top5_mid = np.argsort(-sim_mid, axis=1)[:,1:6]\n",
        "\n",
        "def overlap_at5(a,b): return len(set(a.tolist()) & set(b.tolist()))\n",
        "\n",
        "overlaps_p1 = np.array([overlap_at5(top5_pre[i], top5_mid[i]) for i in range(len(new_ids))])\n",
        "norms_pre   = np.linalg.norm(W_pre[new_ids], axis=1)\n",
        "norms_mid   = np.linalg.norm(W_mid[new_ids], axis=1)\n",
        "norm_deltas_p1 = norms_mid - norms_pre\n",
        "\n",
        "summary_p1 = {\n",
        "    \"phase\": \"phase1\",\n",
        "    \"compared_tokens\": int(len(new_ids)),\n",
        "    \"mean_top5_overlap\": float(np.mean(overlaps_p1)) if len(overlaps_p1) else None,\n",
        "    \"mean_norm_delta\": float(np.mean(norm_deltas_p1)) if len(norm_deltas_p1) else None,\n",
        "}\n",
        "\n",
        "# save JSONs\n",
        "(Path(MID_DIR)/\"morpheme_comparison_p1.json\").write_text(\n",
        "    json.dumps({\n",
        "        \"top5_pre\": top5_pre.tolist(),\n",
        "        \"top5_mid\": top5_mid.tolist(),\n",
        "        \"overlap@5\": overlaps_p1.tolist(),\n",
        "        \"norm_deltas\": norm_deltas_p1.tolist(),\n",
        "    }, indent=2)\n",
        ")\n",
        "(Path(MID_DIR)/\"summary_stats_p1.json\").write_text(json.dumps(summary_p1, indent=2))\n",
        "print(\"Phase-1 summary:\", summary_p1)\n",
        "\n",
        "# quick plots\n",
        "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "plt.figure(); plt.hist(overlaps_p1, bins=[-0.5,0.5,1.5,2.5,3.5,4.5,5.5])\n",
        "plt.title(\"Top-5 overlap (PRE → MID)\"); plt.xlabel(\"Overlap\"); plt.ylabel(\"Freq\")\n",
        "plt.tight_layout(); plt.savefig(PLOTS_DIR/\"hist_overlap_top5_p1.png\", dpi=180); plt.close()\n",
        "\n",
        "plt.figure(); plt.hist(norm_deltas_p1, bins=30)\n",
        "plt.title(\"Embedding norm change (MID − PRE)\"); plt.xlabel(\"Δ norm\"); plt.ylabel(\"Freq\")\n",
        "plt.tight_layout(); plt.savefig(PLOTS_DIR/\"hist_norm_change_p1.png\", dpi=180); plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XOKrmuXbAtC",
        "outputId": "b7159370-248c-4f04-9bc3-ce2997eaa056"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase-1 summary: {'phase': 'phase1', 'compared_tokens': 1200, 'mean_top5_overlap': 3.1283333333333334, 'mean_norm_delta': 0.07451333105564117}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P2 full-model fine-tune"
      ],
      "metadata": {
        "id": "goWc5R-gbHtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# capture init for new ids\n",
        "with torch.no_grad():\n",
        "    E_init = model.get_input_embeddings().weight.data.clone()\n",
        "\n",
        "# custom loss wrapper\n",
        "LAMBDA = 1e-4\n",
        "def add_anchor_loss(outputs, inputs):\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    emb = model.get_input_embeddings().weight\n",
        "    ids = torch.unique(input_ids)\n",
        "    ids = ids[ids >= 0]\n",
        "    return LAMBDA * (emb[ids] - E_init[ids]).pow(2).mean()"
      ],
      "metadata": {
        "id": "xyW3DEk_fU6a"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 768\n",
        "STRIDE  = 384\n",
        "\n",
        "def make_blocks(text, max_len=MAX_LEN, stride=STRIDE):\n",
        "    ids = tok.encode(text, add_special_tokens=False)\n",
        "    return [{\"input_ids\": ids[i:i+max_len]} for i in range(0, max(0,len(ids)-max_len), stride) if len(ids[i:i+max_len])==max_len]\n",
        "\n",
        "train_text = \"\\n\".join(SYN_LINES) + \"\\n\" + FW_TEXT[:600_000]\n",
        "valid_text = FW_TEXT[600_000:630_000]\n",
        "train_ds = Dataset.from_list(make_blocks(train_text))\n",
        "valid_ds = Dataset.from_list(make_blocks(valid_text))\n",
        "\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token\n",
        "model.config.pad_token_id = tok.pad_token_id\n",
        "dc = DataCollatorForLanguageModeling(tok, mlm=False)\n",
        "\n",
        "len(train_ds), len(valid_ds)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnSrNxbsgvGu",
        "outputId": "ca3275ab-63bc-4dd2-b911-08576423edb4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(497, 22)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}