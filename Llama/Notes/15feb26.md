## 2026-02-15 — Llama-3.2-1B P1 embedding-only, resuming from step 200

Switched to running the Llama today because my other google account won't give me any free GPU access today (henceforth "gaslight GPU"). Running P1 embedding-only on Llama-3.2-1B, picking up from step 200.

Only change today: save frequency 100 → 50 steps. This thing is slow enough that losing 100 steps to a Colab disconnect is genuinely painful.

VRAM: 6.2 / 15.0 GB. System RAM: 7.9 / 12.7 GB.

| step | training loss | validation loss |
| --- | --- | --- |
