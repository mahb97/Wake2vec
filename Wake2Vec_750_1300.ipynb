{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.10"
      },
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahb97/Wake2vec/blob/main/Wake2Vec_750_1300.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wake2Vec: Lexicon-Augmented Embedding Training (Steps 750-1300)\n",
        "\n",
        "Continuation training for embedding-only fine-tuning of TinyLlama-1.1B with Finnegans Wake lexicon injection.\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook implements a continuation phase of embedding-only fine-tuning for a large language model augmented with approximately 44,000 Wake-specific tokens. The training methodology isolates new token embeddings through gradient masking while keeping pre-trained model parameters frozen, enabling lexical integration into the existing semantic space without catastrophic forgetting.\n",
        "\n",
        "## Training Configuration\n",
        "\n",
        "Phase: Continuation from checkpoint 750 to step 1300\n",
        "\n",
        "Model: TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\n",
        "\n",
        "Training strategy: Embedding-only optimization with gradient masking on base vocabulary\n",
        "\n",
        "Data: Finnegans Wake corpus with held-out validation set\n",
        "\n",
        "Optimization: Adafactor (learning rate 5e-4, no warmup)\n",
        "\n",
        "Hardware: Single T4 GPU (15GB VRAM) via Google Colab\n",
        "\n",
        "## Notebook Structure\n",
        "\n",
        "This notebook is organized into six sequential cells for reproducible execution:\n",
        "\n",
        "1. Path configuration and environment setup\n",
        "2. Dependency pinning and compatibility patches\n",
        "3. Model and tokenizer loading with gradient masking\n",
        "4. Dataset loading and sequence truncation\n",
        "5. Training callback definitions (monitoring, backups, snapshots)\n",
        "6. Training execution and resumption logic\n",
        "\n",
        "## Monitoring and Backup Utilities\n",
        "\n",
        "The notebook provides automated systems for long-running training stability:\n",
        "\n",
        "- Loss and evaluation metric tracking via structured JSON logs\n",
        "- Checkpoint inventory and validation (weights, optimizer state, trainer state)\n",
        "- Sentry mirror system for automated checkpoint backups to Google Drive\n",
        "- Embedding snapshot capture at 50-step intervals\n",
        "- Training throughput diagnostics (steps per second reporting)\n",
        "- Heartbeat metadata for remote monitoring\n",
        "\n",
        "## Implementation Details\n",
        "\n",
        "The training resumes from checkpoint-750 and proceeds with the following hyperparameters:\n",
        "\n",
        "- Batch size: 1 (effective batch size 16 via gradient accumulation)\n",
        "- Gradient accumulation steps: 16\n",
        "- Learning rate: 5e-4 (no warmup)\n",
        "- Sequence length: 384 tokens (runtime truncation)\n",
        "- Save frequency: 75 steps\n",
        "- Evaluation frequency: 200 steps\n",
        "- Checkpoint retention: 3 most recent (memory optimization)\n",
        "- Gradient clipping: maximum norm 1.0\n",
        "- Gradient checkpointing: enabled for memory efficiency\n",
        "\n",
        "All training callbacks (evaluation triggers, sentry mirroring, embedding snapshots, throughput monitoring) are integrated into the Hugging Face Trainer workflow for automated execution during training. The notebook includes compatibility patches for transformers 4.57.1 and accelerate 1.2.1 to ensure stable execution on Colab environments."
      ],
      "metadata": {
        "id": "CIBlQSpl0iaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Archive ⬇"
      ],
      "metadata": {
        "id": "j4OK4KgOdZnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Path config\n",
        "DRIVE = Path(\"/content/drive/MyDrive/wake2vec\")\n",
        "RUN_ID = \"t4_1762376560\"\n",
        "DATASETS = Path(\"/content/datasets\")\n",
        "LOCAL_RUN = Path(\"/content/runs\") / RUN_ID\n",
        "SENTRY = DRIVE / \"sentry_backups\" / RUN_ID\n",
        "RESUME_FROM = DRIVE / \"runs\" / RUN_ID / \"checkpoint-750-rebuilt\"\n",
        "\n",
        "# directories\n",
        "LOCAL_RUN.mkdir(parents=True, exist_ok=True)\n",
        "SENTRY.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Training config\n",
        "FINAL_TARGET = 1300\n",
        "LAST_STEP = 750\n",
        "TARGET = min(FINAL_TARGET, LAST_STEP + 550)\n",
        "\n",
        "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
        "\n",
        "print(\"[PATH CONFIGURATION]\")\n",
        "print(f\"  RUN_ID: {RUN_ID}\")\n",
        "print(f\"  RESUME_FROM: {RESUME_FROM}\")\n",
        "print(f\"  LOCAL_RUN: {LOCAL_RUN}\")\n",
        "print(f\"  SENTRY: {SENTRY}\")\n",
        "print(f\"  DATASETS: {DATASETS}\")\n",
        "print(f\"  TARGET: {LAST_STEP} → {TARGET}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "273hKq1e3yk1",
        "outputId": "e9663700-6dfb-46a4-dcb5-ccf7078877ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[PATH CONFIGURATION]\n",
            "  RUN_ID: t4_1762376560\n",
            "  RESUME_FROM: /content/drive/MyDrive/wake2vec/runs/t4_1762376560/checkpoint-750-rebuilt\n",
            "  LOCAL_RUN: /content/runs/t4_1762376560\n",
            "  SENTRY: /content/drive/MyDrive/wake2vec/sentry_backups/t4_1762376560\n",
            "  DATASETS: /content/datasets\n",
            "  TARGET: 750 → 1300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependency Pin & Compat Patches\n",
        "import sys\n",
        "import subprocess\n",
        "import importlib\n",
        "\n",
        "def pin(pkg, ver):\n",
        "    \"\"\"Pin package to specific version\"\"\"\n",
        "    try:\n",
        "        m = importlib.import_module(pkg)\n",
        "        assert m.__version__ == ver\n",
        "        print(f\"[OK] {pkg} {m.__version__}\")\n",
        "    except Exception:\n",
        "        print(f\"[PIN] {pkg}=={ver}\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", f\"{pkg}=={ver}\", \"-q\"])\n",
        "        m = importlib.import_module(pkg)\n",
        "        print(f\"[OK] {pkg} {m.__version__}\")\n",
        "\n",
        "pin(\"transformers\", \"4.57.1\")\n",
        "pin(\"accelerate\", \"1.2.1\")\n",
        "pin(\"datasets\", \"2.21.0\")\n",
        "\n",
        "# unwrap_model compatibility patch\n",
        "import accelerate\n",
        "if not hasattr(accelerate.Accelerator, \"_w2v_patched\"):\n",
        "    _orig = accelerate.Accelerator.unwrap_model\n",
        "    def _shim(self, model, *args, **kw):\n",
        "        kw.pop(\"keep_torch_compile\", None)\n",
        "        return _orig(self, model, *args, **kw)\n",
        "    accelerate.Accelerator.unwrap_model = _shim\n",
        "    accelerate.Accelerator._w2v_patched = True\n",
        "    print(\"[PATCH] unwrap_model compatibility shim active\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8KoalXX38Yv",
        "outputId": "568198a5-07d0-4990-997f-6515f6da752a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] transformers 4.57.1\n",
            "[OK] accelerate 1.2.1\n",
            "[OK] datasets 2.21.0\n",
            "[PATCH] unwrap_model compatibility shim active\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc, torch, os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True,max_split_size_mb=64\"\n",
        "\n",
        "for k in [\"trainer\",\"model\",\"tok\",\"optimizer\",\"scheduler\",\"dc\",\"train_ds\",\"valid_ds\"]:\n",
        "    if k in globals():\n",
        "        try: del globals()[k]\n",
        "        except: pass\n",
        "gc.collect(); torch.cuda.empty_cache()\n",
        "try: torch.cuda.ipc_collect()\n",
        "except: pass"
      ],
      "metadata": {
        "id": "fv8bq5WsDSbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model and Tok\n",
        "import torch\n",
        "import gc\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Clear GPU\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Load tok\n",
        "tok = AutoTokenizer.from_pretrained(str(RESUME_FROM), use_fast=True)\n",
        "if tok.pad_token_id is None:\n",
        "    tok.pad_token = tok.eos_token or \"</s>\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    str(RESUME_FROM),\n",
        "    torch_dtype=torch.float32,\n",
        "    device_map=\"auto\",\n",
        "    low_cpu_mem_usage=True,\n",
        ")\n",
        "\n",
        "# Config model\n",
        "model.config.use_cache = False\n",
        "model.config.attn_implementation = \"eager\"\n",
        "\n",
        "# freeze all except embeddings\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "emb = model.get_input_embeddings()\n",
        "emb.weight.requires_grad = True\n",
        "\n",
        "# Tie head\n",
        "with torch.no_grad():\n",
        "    model.get_output_embeddings().weight = emb.weight\n",
        "\n",
        "model.train()\n",
        "\n",
        "# Verification\n",
        "print(\"[MODEL LOADED]\")\n",
        "print(f\"  Tied weights: {'OK' if emb.weight.data_ptr() == model.get_output_embeddings().weight.data_ptr() else 'NO'}\")\n",
        "print(f\"  Embedding trainable: {emb.weight.requires_grad}\")\n",
        "print(f\"  Pad token ID: {tok.pad_token_id}\")\n",
        "\n",
        "import collections\n",
        "devs = collections.Counter(p.device.type for p in model.parameters())\n",
        "print(f\"  Device distribution: {dict(devs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv267cQA4Ja-",
        "outputId": "bfcb3fdd-604a-4b40-f547-917d2d3a48a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at /content/drive/MyDrive/wake2vec/runs/t4_1762376560/checkpoint-750-rebuilt and are newly initialized: ['lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MODEL LOADED]\n",
            "  Tied weights: OK\n",
            "  Embedding trainable: True\n",
            "  Pad token ID: 2\n",
            "  Device distribution: {'cuda': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "import json\n",
        "import time\n",
        "import shutil\n",
        "from transformers import TrainerCallback\n",
        "from transformers.trainer_callback import TrainerState\n",
        "\n",
        "class EvalEveryNSteps(TrainerCallback):\n",
        "    \"\"\"Trigger evaluation at fixed step intervals\"\"\"\n",
        "    def __init__(self, n=200):\n",
        "        self.n = n\n",
        "\n",
        "    def on_step_end(self, args, state, control, **kw):\n",
        "        s = int(state.global_step or 0)\n",
        "        if s and s % self.n == 0:\n",
        "            control.should_log = True\n",
        "            control.should_evaluate = True\n",
        "\n",
        "class SentryMirror(TrainerCallback):\n",
        "    \"\"\"Mirror checkpoints to backup directory on Drive\"\"\"\n",
        "    def on_save(self, args, state, control, **kw):\n",
        "        try:\n",
        "            out = Path(args.output_dir)\n",
        "            cks = [p for p in out.glob(\"checkpoint-*\") if p.is_dir()]\n",
        "            if not cks:\n",
        "                return\n",
        "\n",
        "            def step_of(p):\n",
        "                try:\n",
        "                    return int(p.name.split(\"-\")[-1])\n",
        "                except:\n",
        "                    return -1\n",
        "\n",
        "            ck = max(cks, key=step_of)\n",
        "            has_weights = (ck/\"model.safetensors\").exists() or (ck/\"pytorch_model.bin\").exists()\n",
        "\n",
        "            if not has_weights:\n",
        "                return\n",
        "\n",
        "            dst = SENTRY / ck.name\n",
        "            if not dst.exists():\n",
        "                shutil.copytree(ck, dst)\n",
        "                print(f\"[SENTRY] mirrored {ck.name}\")\n",
        "\n",
        "            # Mirror metrics\n",
        "            msrc = out / \"metrics\"\n",
        "            if msrc.exists():\n",
        "                (SENTRY/\"metrics\").mkdir(parents=True, exist_ok=True)\n",
        "                for f in msrc.glob(\"*.json\"):\n",
        "                    shutil.copy2(f, SENTRY/\"metrics\"/f.name)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[SENTRY] mirror failed: {e}\")\n",
        "\n",
        "class EmbeddingSnap(TrainerCallback):\n",
        "    \"\"\"Save embedding snapshots at regular intervals\"\"\"\n",
        "    def __init__(self, every=50):\n",
        "        self.every = every\n",
        "        (DRIVE/\"emb_snaps\"/RUN_ID).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def on_step_end(self, args, state, control, **kw):\n",
        "        s = int(state.global_step or 0)\n",
        "        if s and s % self.every == 0:\n",
        "            try:\n",
        "                E = model.get_input_embeddings().weight.detach().cpu()\n",
        "                out_path = (DRIVE/\"emb_snaps\"/RUN_ID) / f\"emb_step{s:04d}.pt\"\n",
        "                torch.save(E, out_path)\n",
        "\n",
        "                # Write heartbeat metadata\n",
        "                heartbeat = {\n",
        "                    \"run_id\": RUN_ID,\n",
        "                    \"step\": s,\n",
        "                    \"rows\": int(E.size(0)),\n",
        "                    \"dim\": int(E.size(1)),\n",
        "                    \"ts\": time.time()\n",
        "                }\n",
        "                (out_path.parent/\"heartbeat.json\").write_text(\n",
        "                    json.dumps(heartbeat, indent=2))\n",
        "\n",
        "                print(f\"[SNAP] embeddings saved to {out_path.name}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"[SNAP] failed: {e}\")\n",
        "\n",
        "class StepTimer(TrainerCallback):\n",
        "    \"\"\"Monitor training throughput in steps per second\"\"\"\n",
        "    def __init__(self, every=10):\n",
        "        self.prev = None\n",
        "        self.t = None\n",
        "        self.every = every\n",
        "\n",
        "    def on_step_end(self, args, state, control, **kw):\n",
        "        s = int(state.global_step or 0)\n",
        "        now = time.time()\n",
        "\n",
        "        if self.prev is not None and s > self.prev and s % self.every == 0:\n",
        "            dt = now - self.t\n",
        "            print(f\"[{s:4d}] ~{dt/self.every:.2f}s/step (last {self.every})\")\n",
        "\n",
        "        self.prev, self.t = s, now\n",
        "\n",
        "print(\"[CALLBACKS CONFIGURED]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VpyEAhM5BFk",
        "outputId": "5e71e312-e0ad-44ed-b4eb-5896adcd0e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CALLBACKS CONFIGURED]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pin and patch FIRST\n",
        "import sys, subprocess, importlib\n",
        "\n",
        "def pin(pkg, ver):\n",
        "    try:\n",
        "        m = importlib.import_module(pkg)\n",
        "        assert m.__version__ == ver\n",
        "        print(f\"[OK] {pkg} {m.__version__}\")\n",
        "    except Exception:\n",
        "        print(f\"[PIN] {pkg}=={ver}\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", f\"{pkg}=={ver}\", \"-q\"])\n",
        "        m = importlib.import_module(pkg)\n",
        "        print(f\"[OK] {pkg} {m.__version__}\")\n",
        "\n",
        "pin(\"transformers\", \"4.57.1\")\n",
        "pin(\"accelerate\", \"1.2.1\")\n",
        "pin(\"datasets\", \"2.21.0\")\n",
        "\n",
        "import accelerate\n",
        "if not hasattr(accelerate.Accelerator, \"_w2v_patched\"):\n",
        "    _orig = accelerate.Accelerator.unwrap_model\n",
        "    def _shim(self, model, *args, **kw):\n",
        "        kw.pop(\"keep_torch_compile\", None)\n",
        "        return _orig(self, model, *args, **kw)\n",
        "    accelerate.Accelerator.unwrap_model = _shim\n",
        "    accelerate.Accelerator._w2v_patched = True\n",
        "    print(\"[PATCH] active\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvIgdVTFGVCc",
        "outputId": "e4dcdd70-4329-4308-d386-7adf768c1a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] transformers 4.57.1\n",
            "[OK] accelerate 1.2.1\n",
            "[OK] datasets 2.21.0\n",
            "[PATCH] active\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATASETS\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\", force_remount=False)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "DRIVE = Path(\"/content/drive/MyDrive/wake2vec\")\n",
        "DATASETS = Path(\"/content/datasets\"); DATASETS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def ensure_dir(src: Path, dst: Path):\n",
        "    assert src.exists(), f\"Missing dataset at {src}\"\n",
        "    if not dst.exists():\n",
        "        print(f\"[DATA] copying {src} → {dst}\")\n",
        "        shutil.copytree(src, dst)\n",
        "    else:\n",
        "        print(f\"[DATA] already local:\", dst)\n",
        "\n",
        "# try to copy\n",
        "src_train = DRIVE/\"datasets\"/\"train_ds\"\n",
        "src_valid = DRIVE/\"datasets\"/\"valid_ds\"\n",
        "dst_train = DATASETS/\"train_ds\"\n",
        "dst_valid = DATASETS/\"valid_ds\"\n",
        "ensure_dir(src_train, dst_train)\n",
        "ensure_dir(src_valid, dst_valid)\n",
        "\n",
        "# load with a Drive fallback\n",
        "try:\n",
        "    train_ds_path = str(dst_train if dst_train.exists() else src_train)\n",
        "    valid_ds_path = str(dst_valid if dst_valid.exists() else src_valid)\n",
        "    print(\"[DATA] train_ds:\", train_ds_path)\n",
        "    print(\"[DATA] valid_ds:\", valid_ds_path)\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Dataset path resolution failed: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF7tooxRCCe6",
        "outputId": "6af61578-2e17-49c8-d167-e1f843759f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[DATA] already local: /content/datasets/train_ds\n",
            "[DATA] already local: /content/datasets/valid_ds\n",
            "[DATA] train_ds: /content/datasets/train_ds\n",
            "[DATA] valid_ds: /content/datasets/valid_ds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FORCE CLEAN GPU\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "for name in list(globals().keys()):\n",
        "    if 'model' in name.lower() or 'trainer' in name.lower():\n",
        "        try:\n",
        "            del globals()[name]\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()\n",
        "\n",
        "print(\"[MEMORY] GPU cleaned\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAVXmnAcIH6s",
        "outputId": "3d0a994b-30ba-426c-d330-d39df1231b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MEMORY] GPU cleaned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "for name in list(globals().keys()):\n",
        "    if 'model' in name.lower() or 'trainer' in name.lower():\n",
        "        try:\n",
        "            del globals()[name]\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "print(\"[MEMORY] Cleaned\")"
      ],
      "metadata": {
        "id": "TDOSd5ARw7cZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8333c1bb-9d1f-423d-fbe1-de232fea7d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MEMORY] Cleaned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for p1 eval"
      ],
      "metadata": {
        "id": "jRvQ2ZhVQ389"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TRAIN output_dir:\", trainer.args.output_dir)\n",
        "print(\"RUN_ID:\", pathlib.Path(trainer.args.output_dir).name)\n",
        "print(\"global_step:\", trainer.state.global_step)"
      ],
      "metadata": {
        "id": "4Q8WwTrs-zCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "from transformers import TrainingArguments\n",
        "'evaluation_strategy' in inspect.signature(TrainingArguments.__init__).parameters"
      ],
      "metadata": {
        "id": "eC9-VVNQ2KC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainerCallback\n",
        "\n",
        "class EvalEveryNSteps(TrainerCallback):\n",
        "    def __init__(self, n=200): self.n=n\n",
        "    def on_step_end(self, args, state, control, **kw):\n",
        "        if state.global_step and (state.global_step % self.n == 0):\n",
        "            control.should_save = True         # ensure state gets flushed\n",
        "            control.should_log = True\n",
        "            control.should_evaluate = True"
      ],
      "metadata": {
        "id": "yX9eVZvc2SCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# P1 finalise overlap@5, norm stats, and a loss plot\n",
        "import json, numpy as np, pathlib, matplotlib.pyplot as plt\n",
        "\n",
        "DRIVE_ROOT = pathlib.Path(\"/content/drive/MyDrive/wake2vec\")\n",
        "RUNS = sorted((DRIVE_ROOT/\"runs\").glob(\"t4_*\"), key=lambda p: p.stat().st_mtime)\n",
        "RUN_DIR = pathlib.Path(\"/content/runs\")/RUNS[-1].name\n",
        "METRICS_DIR = RUN_DIR/\"metrics\"\n",
        "PLOTS_DIR = RUN_DIR/\"plots\"; PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Load current embeddings\n",
        "from transformers import AutoModelForCausalLM\n",
        "BASE_CKPT = RUN_DIR/\"checkpoint-final\"\n",
        "model = AutoModelForCausalLM.from_pretrained(str(BASE_CKPT), torch_dtype=\"float32\", device_map=None)\n",
        "E_post = model.get_input_embeddings().weight.detach().cpu().numpy()\n",
        "\n",
        "# Optional composed init + ids\n",
        "E_COMP = DRIVE_ROOT/\"E_comp.npy\"\n",
        "NEW_IDS = DRIVE_ROOT/\"new_ids.npy\"\n",
        "has_comp = E_COMP.exists() and NEW_IDS.exists()\n",
        "\n",
        "def topk_overlap(a, b, k=5):\n",
        "    import numpy as np\n",
        "    from numpy.linalg import norm\n",
        "    a = a / (norm(a, axis=1, keepdims=True)+1e-9)\n",
        "    b = b / (norm(b, axis=1, keepdims=True)+1e-9)\n",
        "    sims = a @ b.T\n",
        "    top_a = np.argsort(-sims, axis=1)[:, :k]\n",
        "    top_b = np.argsort(-sims, axis=1)[:, :k]\n",
        "    inter = np.array([len(set(top_a[i]) & set(top_b[i])) for i in range(a.shape[0])])\n",
        "    return inter.mean()\n",
        "\n",
        "report = {}\n",
        "\n",
        "if has_comp:\n",
        "    E_comp = np.load(E_COMP)\n",
        "    new_ids = np.load(NEW_IDS)\n",
        "    E_post_new = E_post[new_ids]\n",
        "    overlap5 = topk_overlap(E_comp, E_post_new, k=5)\n",
        "    # Norm drift\n",
        "    from numpy.linalg import norm\n",
        "    dn = (norm(E_post_new, axis=1) - norm(E_comp, axis=1)).mean()\n",
        "    report.update({\"overlap_at_5\": float(overlap5), \"mean_delta_norm\": float(dn), \"n_new\": int(len(new_ids))})\n",
        "else:\n",
        "    # Fallback\n",
        "    from numpy.linalg import norm\n",
        "    norms = norm(E_post, axis=1)\n",
        "    report.update({\"post_mean_norm\": float(norms.mean()), \"post_std_norm\": float(norms.std()), \"n_vocab\": int(E_post.shape[0])})\n",
        "\n",
        "# JSON\n",
        "(METRICS_DIR/\"p1_summary.json\").write_text(json.dumps(report, indent=2))\n",
        "print(\"[P1 SUMMARY]\", json.dumps(report, indent=2))\n",
        "\n",
        "# Loss plot\n",
        "import json, glob\n",
        "state_files = [RUN_DIR/\"trainer_state.json\", BASE_CKPT/\"trainer_state.json\"]\n",
        "state_files = [p for p in state_files if p.exists()]\n",
        "logs = []\n",
        "for sf in state_files:\n",
        "    s = json.loads(sf.read_text())\n",
        "    logs.extend([d for d in s.get(\"log_history\", []) if \"loss\" in d])\n",
        "\n",
        "if logs:\n",
        "    steps = [d[\"step\"] for d in logs]\n",
        "    losses = [float(d[\"loss\"]) for d in logs]\n",
        "    ema = []\n",
        "    alpha = 0.1\n",
        "    for i,x in enumerate(losses):\n",
        "        ema.append(x if i==0 else alpha*x + (1-alpha)*ema[-1])\n",
        "    plt.figure(figsize=(7,4.5))\n",
        "    plt.plot(steps, losses, label=\"loss\")\n",
        "    plt.plot(steps, ema, label=\"EMA(0.1)\")\n",
        "    plt.title(f\"P1 Loss — {RUN_DIR.name}\")\n",
        "    plt.xlabel(\"step\"); plt.ylabel(\"loss\"); plt.grid(True, linewidth=0.3); plt.legend()\n",
        "    outp = PLOTS_DIR/\"p1_loss_curve.png\"\n",
        "    plt.savefig(outp, dpi=140, bbox_inches=\"tight\")\n",
        "    print(\"[PLOT]\", outp)\n",
        "else:\n",
        "    print(\"[WARN] No trainer_state logs found; skip loss plot.\")"
      ],
      "metadata": {
        "id": "5AMneAlxqpmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Config and Execution\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# Training args\n",
        "args = TrainingArguments(\n",
        "    output_dir=str(LOCAL_RUN),\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=16,\n",
        "    max_steps=TARGET,\n",
        "    learning_rate=5e-4,\n",
        "    warmup_ratio=0.0,\n",
        "    optim=\"adafactor\",\n",
        "    logging_steps=25,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=75,\n",
        "    save_total_limit=3,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=False,\n",
        "    bf16=False,\n",
        "    dataloader_num_workers=0,\n",
        "    dataloader_pin_memory=False,\n",
        "    dataloader_persistent_workers=False,\n",
        "    report_to=[\"none\"],\n",
        "    max_grad_norm=1.0,\n",
        ")\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=valid_ds,\n",
        "    data_collator=dc_trunc,\n",
        "    callbacks=[\n",
        "        EvalEveryNSteps(200),\n",
        "        SentryMirror(),\n",
        "        EmbeddingSnap(50),\n",
        "        StepTimer(10)\n",
        "    ],\n",
        ")\n",
        "\n",
        "# resume state\n",
        "ts = RESUME_FROM / \"trainer_state.json\"\n",
        "if not ts.exists():\n",
        "    state_dict = {\n",
        "        \"global_step\": LAST_STEP,\n",
        "        \"max_steps\": TARGET,\n",
        "        \"log_history\": []\n",
        "    }\n",
        "    ts.write_text(json.dumps(state_dict, indent=2))\n",
        "    print(f\"[RESUME] wrote trainer_state.json at step {LAST_STEP}\")\n",
        "\n",
        "# training\n",
        "print(f\"[GO] Resuming from step {LAST_STEP} with MAX_LEN={MAX_LEN}\")\n",
        "print(f\"     Target: {TARGET} | Gradient checkpointing: ON\")\n",
        "\n",
        "t0 = time.time()\n",
        "trainer.train(resume_from_checkpoint=str(RESUME_FROM))\n",
        "elapsed = time.time() - t0\n",
        "\n",
        "print(f\"[COMPLETE] Training finished in {elapsed:.1f}s ({elapsed/60:.1f}min)\")"
      ],
      "metadata": {
        "id": "etUEGZNd7Qvl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}