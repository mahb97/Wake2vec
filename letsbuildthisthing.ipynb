{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Rc8jGvcht9NbRuPgmkPg6WJeSdPWIz-P",
      "authorship_tag": "ABX9TyONZdnPlcVFF4csYz9MZ6L0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0bb24b6826f74b36bc006ed702b1b2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c86e6d00afb4240958f8a350d2f9345",
              "IPY_MODEL_8e842c8014d94ebfab9ef2b11e803175",
              "IPY_MODEL_2e938c8d0f0d468ebe1f33d3cc8c3d49"
            ],
            "layout": "IPY_MODEL_030bf06809964a86aafeb5a067c818ca"
          }
        },
        "8c86e6d00afb4240958f8a350d2f9345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd325af3ad0a4f7abaefd7cb9861f35a",
            "placeholder": "​",
            "style": "IPY_MODEL_9af2320fa4284dae840c05b3c632a38f",
            "value": "tokenizer_config.json: "
          }
        },
        "8e842c8014d94ebfab9ef2b11e803175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc0ea95baf0c4698a942b41b8021026b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4fb1cd74afe4eeaa7622cb7ece836a6",
            "value": 1
          }
        },
        "2e938c8d0f0d468ebe1f33d3cc8c3d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1b45270224741f2a18b270d73dab87a",
            "placeholder": "​",
            "style": "IPY_MODEL_489e9447d4594c7c8fc376f6f5d762ea",
            "value": " 1.29k/? [00:00&lt;00:00, 60.6kB/s]"
          }
        },
        "030bf06809964a86aafeb5a067c818ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd325af3ad0a4f7abaefd7cb9861f35a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9af2320fa4284dae840c05b3c632a38f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc0ea95baf0c4698a942b41b8021026b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a4fb1cd74afe4eeaa7622cb7ece836a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1b45270224741f2a18b270d73dab87a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "489e9447d4594c7c8fc376f6f5d762ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "809617d38ef84337903a8f5c5135eaf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce1d8834e83940a4851bb1546dd29b09",
              "IPY_MODEL_1dc25cdb15904320be597fdca2471ccc",
              "IPY_MODEL_15f770d3fe7e404da9bc4dff6afd0688"
            ],
            "layout": "IPY_MODEL_c1d3f8a71f014d5ba512653fd83d7ffd"
          }
        },
        "ce1d8834e83940a4851bb1546dd29b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_826448d8cbe548df9e45afbba358e709",
            "placeholder": "​",
            "style": "IPY_MODEL_537eb4a7bf08455ba51f9512ab801024",
            "value": "tokenizer.model: 100%"
          }
        },
        "1dc25cdb15904320be597fdca2471ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59e612ecad0b4507a6f110f9fc08fdcd",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cc7f83ec02046bfb7cd0d08dc1fbfd2",
            "value": 499723
          }
        },
        "15f770d3fe7e404da9bc4dff6afd0688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5596e4bf864149b89fb5c7f4f47275b3",
            "placeholder": "​",
            "style": "IPY_MODEL_400851f83b354613954a48def65548e2",
            "value": " 500k/500k [00:00&lt;00:00, 1.21MB/s]"
          }
        },
        "c1d3f8a71f014d5ba512653fd83d7ffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "826448d8cbe548df9e45afbba358e709": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "537eb4a7bf08455ba51f9512ab801024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59e612ecad0b4507a6f110f9fc08fdcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cc7f83ec02046bfb7cd0d08dc1fbfd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5596e4bf864149b89fb5c7f4f47275b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "400851f83b354613954a48def65548e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "161e147ccc8947b98bfecb4ada4d24db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_555c4a23d6f246b086f6c67cb89d2781",
              "IPY_MODEL_c598b481d0284b6f9fd69c91fa3c9e04",
              "IPY_MODEL_90ac5f803cd74f52b11d43eafe3c00ef"
            ],
            "layout": "IPY_MODEL_aa80b06153c14686ad63bc0e07d252d1"
          }
        },
        "555c4a23d6f246b086f6c67cb89d2781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b32837b274844c7996fee2633a4881e6",
            "placeholder": "​",
            "style": "IPY_MODEL_ec22777d2cfe4dbdbcc9930215746441",
            "value": "tokenizer.json: "
          }
        },
        "c598b481d0284b6f9fd69c91fa3c9e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eef2434f43b45249f26aa8e1e7a3765",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf04a568ef104fbdaad261e05c018d20",
            "value": 1
          }
        },
        "90ac5f803cd74f52b11d43eafe3c00ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df370d80adbc413aba8887d6f538e7f0",
            "placeholder": "​",
            "style": "IPY_MODEL_c67683fcf95645688699d4757dfe6a2d",
            "value": " 1.84M/? [00:00&lt;00:00, 11.6MB/s]"
          }
        },
        "aa80b06153c14686ad63bc0e07d252d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b32837b274844c7996fee2633a4881e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec22777d2cfe4dbdbcc9930215746441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eef2434f43b45249f26aa8e1e7a3765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "cf04a568ef104fbdaad261e05c018d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df370d80adbc413aba8887d6f538e7f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c67683fcf95645688699d4757dfe6a2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b99857eee93490db5de7ada6b9ccb2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a69c030f6cb4cc1a1b01c356faf438b",
              "IPY_MODEL_3d4bae708a27462994de889571a8a308",
              "IPY_MODEL_a4e8407302774887b15b77aadaa9d99c"
            ],
            "layout": "IPY_MODEL_20691a4817e54a778232961f1c295558"
          }
        },
        "6a69c030f6cb4cc1a1b01c356faf438b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aad6709d972547da84aa758e28b869d4",
            "placeholder": "​",
            "style": "IPY_MODEL_12b884b754cc442fa9ba1f0abf5cd8f7",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "3d4bae708a27462994de889571a8a308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28e54b24c2e2413b8623b9d54cc2d5f2",
            "max": 551,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a36fd92746904cfe894123e8dd01a23c",
            "value": 551
          }
        },
        "a4e8407302774887b15b77aadaa9d99c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7de61d565a3a4d84b1d0aed4841ad7ca",
            "placeholder": "​",
            "style": "IPY_MODEL_a050e3bbb56d46fe922c44d6a9ce4c6b",
            "value": " 551/551 [00:00&lt;00:00, 15.0kB/s]"
          }
        },
        "20691a4817e54a778232961f1c295558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aad6709d972547da84aa758e28b869d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12b884b754cc442fa9ba1f0abf5cd8f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28e54b24c2e2413b8623b9d54cc2d5f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a36fd92746904cfe894123e8dd01a23c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7de61d565a3a4d84b1d0aed4841ad7ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a050e3bbb56d46fe922c44d6a9ce4c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b769d88bc9c4df2979c38270e8f5c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0777df12a2014a0c899ba694f62abfc4",
              "IPY_MODEL_7338c81df8db4dd4ad4505ad34011aa7",
              "IPY_MODEL_37f4c44e845546898d901b7b9eb49c32"
            ],
            "layout": "IPY_MODEL_0dc787313e5b47ef9521bc82dac1a0e6"
          }
        },
        "0777df12a2014a0c899ba694f62abfc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8a933b4cae24db199f4bdb32b85d6ab",
            "placeholder": "​",
            "style": "IPY_MODEL_bad8728a627a44ab88acbd73f9f862e3",
            "value": "config.json: 100%"
          }
        },
        "7338c81df8db4dd4ad4505ad34011aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23dda180301543e2b15c826e00a78a85",
            "max": 608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_093d54f181c54e849065c0a05ae2f718",
            "value": 608
          }
        },
        "37f4c44e845546898d901b7b9eb49c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a5c0063fb8947ac99eda906109dd78c",
            "placeholder": "​",
            "style": "IPY_MODEL_d72cb3130aa94e6295e36c0a3e645b5d",
            "value": " 608/608 [00:00&lt;00:00, 13.5kB/s]"
          }
        },
        "0dc787313e5b47ef9521bc82dac1a0e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a933b4cae24db199f4bdb32b85d6ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bad8728a627a44ab88acbd73f9f862e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23dda180301543e2b15c826e00a78a85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "093d54f181c54e849065c0a05ae2f718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a5c0063fb8947ac99eda906109dd78c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d72cb3130aa94e6295e36c0a3e645b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6f7789e2eb646ec9f609a2e2d9fc20f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d381fcdf0cac4eab9a31911a043c7768",
              "IPY_MODEL_77d23fcb7d3d4acdb93b5c7a8a9607e2",
              "IPY_MODEL_547a71d243674b13948cb2ff7bb02e45"
            ],
            "layout": "IPY_MODEL_adf7d62c8b2d4f6d91d66a747dd33aca"
          }
        },
        "d381fcdf0cac4eab9a31911a043c7768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38c2580658964e30be96fcc7ff3f0c3e",
            "placeholder": "​",
            "style": "IPY_MODEL_61b83bd9cd0f4f5395feac2c109e4f05",
            "value": "model.safetensors: 100%"
          }
        },
        "77d23fcb7d3d4acdb93b5c7a8a9607e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed308d19a9f04bf697f3d035f6107a0f",
            "max": 2200119864,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a8e6e548ee748439931587e8ee70af9",
            "value": 2200119864
          }
        },
        "547a71d243674b13948cb2ff7bb02e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac33ced032324b75b0099792637a6ee8",
            "placeholder": "​",
            "style": "IPY_MODEL_a0acd2f5df3644738eccbf83cae6b7f6",
            "value": " 2.20G/2.20G [00:37&lt;00:00, 75.8MB/s]"
          }
        },
        "adf7d62c8b2d4f6d91d66a747dd33aca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38c2580658964e30be96fcc7ff3f0c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61b83bd9cd0f4f5395feac2c109e4f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed308d19a9f04bf697f3d035f6107a0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a8e6e548ee748439931587e8ee70af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac33ced032324b75b0099792637a6ee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0acd2f5df3644738eccbf83cae6b7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5d92e57e6fb431da3ad835686a4dc58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cfbe43598664048a728c1cd60231ada",
              "IPY_MODEL_f7a51019394f4c1e9ba0ceb892974f5f",
              "IPY_MODEL_e47e20bc11974e89a35dba652d4f0e72"
            ],
            "layout": "IPY_MODEL_6c183771da394d99be8eb1458e719aa9"
          }
        },
        "4cfbe43598664048a728c1cd60231ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72b97cfc379943afa9dcaac2922ce882",
            "placeholder": "​",
            "style": "IPY_MODEL_d3235fdf032b4533bdc85c7b5234b3b9",
            "value": "generation_config.json: 100%"
          }
        },
        "f7a51019394f4c1e9ba0ceb892974f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf3d4d307ee744a1b39d9fe78c42b230",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ae8b9f605cd4827b787fd57bdcb4cf6",
            "value": 124
          }
        },
        "e47e20bc11974e89a35dba652d4f0e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d54001d569a6485989f3fb360dc94715",
            "placeholder": "​",
            "style": "IPY_MODEL_0c626591ad094c48b5c6fff028528d98",
            "value": " 124/124 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "6c183771da394d99be8eb1458e719aa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72b97cfc379943afa9dcaac2922ce882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3235fdf032b4533bdc85c7b5234b3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf3d4d307ee744a1b39d9fe78c42b230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ae8b9f605cd4827b787fd57bdcb4cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d54001d569a6485989f3fb360dc94715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c626591ad094c48b5c6fff028528d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b686730b396949a28aad6110263559c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a163a44b8826432597278c1cc68185ae",
              "IPY_MODEL_3fbbaa00398a4e39b39c9a2368ae422e",
              "IPY_MODEL_b289608e9e2d405b86fbd9a73acc32ce"
            ],
            "layout": "IPY_MODEL_9c10c539bb9449928a603ede6ad4a428"
          }
        },
        "a163a44b8826432597278c1cc68185ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da0f1f2c86024ec886fc80aad34f41f7",
            "placeholder": "​",
            "style": "IPY_MODEL_75ba90567c294f18b9c3ff6576e9f121",
            "value": "Map: 100%"
          }
        },
        "3fbbaa00398a4e39b39c9a2368ae422e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c0678203c4948439d059ba3949e5cf8",
            "max": 1566,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb967529b8874e169f0b3dfdce0c635f",
            "value": 1566
          }
        },
        "b289608e9e2d405b86fbd9a73acc32ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee1bc443b3fe408390d63256bdbb762a",
            "placeholder": "​",
            "style": "IPY_MODEL_59e3f0621e1340448dc933807995f30d",
            "value": " 1566/1566 [00:00&lt;00:00, 3128.89 examples/s]"
          }
        },
        "9c10c539bb9449928a603ede6ad4a428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da0f1f2c86024ec886fc80aad34f41f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75ba90567c294f18b9c3ff6576e9f121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c0678203c4948439d059ba3949e5cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb967529b8874e169f0b3dfdce0c635f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee1bc443b3fe408390d63256bdbb762a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59e3f0621e1340448dc933807995f30d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc07412a224541079d561990f536bc0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea162751756c4689a0958ccc72df1637",
              "IPY_MODEL_2326dcd7288d407db2c21de6fcaa2b7d",
              "IPY_MODEL_8b7a5f0866c4457cb483ec2c6230174b"
            ],
            "layout": "IPY_MODEL_6d73ab2b20ec492fbc75da318401aa28"
          }
        },
        "ea162751756c4689a0958ccc72df1637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15039c9136b6475fbc35f8769e6cfaf9",
            "placeholder": "​",
            "style": "IPY_MODEL_8e6b4114f56a4b3f90ac9fd9679df122",
            "value": "Map: 100%"
          }
        },
        "2326dcd7288d407db2c21de6fcaa2b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b8aafcf122a4d11912c714d49f30981",
            "max": 174,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_579cfacd7cd747169f51dfabe7ba07aa",
            "value": 174
          }
        },
        "8b7a5f0866c4457cb483ec2c6230174b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d308ae2892bd4d6c82679e6ce11e031f",
            "placeholder": "​",
            "style": "IPY_MODEL_bd8b892cc67146e9a839413b35b76f76",
            "value": " 174/174 [00:00&lt;00:00, 2979.53 examples/s]"
          }
        },
        "6d73ab2b20ec492fbc75da318401aa28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15039c9136b6475fbc35f8769e6cfaf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e6b4114f56a4b3f90ac9fd9679df122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b8aafcf122a4d11912c714d49f30981": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "579cfacd7cd747169f51dfabe7ba07aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d308ae2892bd4d6c82679e6ce11e031f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd8b892cc67146e9a839413b35b76f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "907d3bf403b7455d88d880dd1adb1c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_521de04f0fa44053854b121e4b839b31",
              "IPY_MODEL_a707dd0731ed47a5b1d791420dc1b5d5",
              "IPY_MODEL_ecffa6d714b740768952fdb91f63c472"
            ],
            "layout": "IPY_MODEL_9cc6b73171cd4f549a3191294e38d03d"
          }
        },
        "521de04f0fa44053854b121e4b839b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fbfe320ff204fe8b9e3e300de40b389",
            "placeholder": "​",
            "style": "IPY_MODEL_dfa605cef56e4a19b2baaa9670ec1008",
            "value": "Map: 100%"
          }
        },
        "a707dd0731ed47a5b1d791420dc1b5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d391082208144816b8cae3abf9692a7b",
            "max": 1596,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_220b90768ace4cb69dd8aa2807ea48de",
            "value": 1596
          }
        },
        "ecffa6d714b740768952fdb91f63c472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d76f8e6524542e49d3984f45cc92c1e",
            "placeholder": "​",
            "style": "IPY_MODEL_8f60c708c456488fadea4cfdd95e0a3d",
            "value": " 1596/1596 [00:00&lt;00:00, 5695.61 examples/s]"
          }
        },
        "9cc6b73171cd4f549a3191294e38d03d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fbfe320ff204fe8b9e3e300de40b389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfa605cef56e4a19b2baaa9670ec1008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d391082208144816b8cae3abf9692a7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "220b90768ace4cb69dd8aa2807ea48de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d76f8e6524542e49d3984f45cc92c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f60c708c456488fadea4cfdd95e0a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a562adb41b57411b80081bdb9b5394eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7171cc3197df480b86274d56fb6895c1",
              "IPY_MODEL_b74d679715474382a40b12bf62af3abc",
              "IPY_MODEL_cdde0dd37d0a4b82922916a2ba99bcca"
            ],
            "layout": "IPY_MODEL_7514c16d82a64ab0b1028e9fd2ba7da1"
          }
        },
        "7171cc3197df480b86274d56fb6895c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24feb4c470be499680297ab8bd654e5d",
            "placeholder": "​",
            "style": "IPY_MODEL_1ea40b9ee21f4800a2e7bead0cebeecf",
            "value": "Map: 100%"
          }
        },
        "b74d679715474382a40b12bf62af3abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd9b05cba25d4fd089f9a0196810a43f",
            "max": 178,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be0517c163df4ec2914701cc1adf714d",
            "value": 178
          }
        },
        "cdde0dd37d0a4b82922916a2ba99bcca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45c5eb51bc08453ab76978b0cd5db8a2",
            "placeholder": "​",
            "style": "IPY_MODEL_cc3f6acf777e49ada7aba311af1b9af2",
            "value": " 178/178 [00:00&lt;00:00, 3347.15 examples/s]"
          }
        },
        "7514c16d82a64ab0b1028e9fd2ba7da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24feb4c470be499680297ab8bd654e5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ea40b9ee21f4800a2e7bead0cebeecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd9b05cba25d4fd089f9a0196810a43f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be0517c163df4ec2914701cc1adf714d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45c5eb51bc08453ab76978b0cd5db8a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc3f6acf777e49ada7aba311af1b9af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahb97/Wake2vec/blob/main/letsbuildthisthing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "did some digging and guess what i found, absolute gold, so here comes everybody"
      ],
      "metadata": {
        "id": "twvOaI8RUnBW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MORPHEME-AWARE WAKE2VEC**\n",
        "\n",
        "**Teaching TinyLlama Joyce's Generative Grammar**\n",
        "\n",
        "Based on hand-compiled morphological analysis of Finnegans Wake\n",
        "\n",
        "This notebook teaches compositional word formation via embedding arithmetic"
      ],
      "metadata": {
        "id": "lthZp2xlU6BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install python-docx\n",
        "\n",
        "from pathlib import Path\n",
        "import re, json, csv\n",
        "from collections import defaultdict\n",
        "from docx import Document\n",
        "\n",
        "DOCX = Path(\"/content/morphemesraw.docx\")\n",
        "OUT_CSV = Path(\"/content/affixes.csv\")\n",
        "OUT_JSON = Path(\"/content/affixes.json\")\n",
        "\n",
        "if not DOCX.exists():\n",
        "    raise FileNotFoundError(f\"Upload your DOCX to {DOCX}\")\n",
        "\n",
        "# Normalisation helpers\n",
        "def norm_token(s: str) -> str:\n",
        "    s = (s or \"\").strip()\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    # strip stray punctuation boundaries\n",
        "    s = re.sub(r\"^[^A-Za-z'-]+|[^A-Za-z'-]+$\", \"\", s)\n",
        "    return s\n",
        "\n",
        "def is_header(line: str):\n",
        "    \"\"\"Return ('prefix','re-') or ('suffix','-ness') if line looks like a header.\"\"\"\n",
        "    l = line.strip().lower()\n",
        "    # e.g. \"prefix ad-\" | \"Prefix acro-\" | \"suffix -ness\" | \"Suffix a-1 and a-2\"\n",
        "    m1 = re.match(r'^(prefix)\\s+([a-z]+)\\-+(\\d+)?', l)\n",
        "    m2 = re.match(r'^(suffix)\\s+\\-+([a-z]+)(\\d+)?', l)\n",
        "    if m1:\n",
        "        return \"prefix\", f\"{m1.group(2)}-\"\n",
        "    if m2:\n",
        "        return \"suffix\", f\"-{m2.group(2)}\"\n",
        "    # also handle \"prefix all-\" with punctuation noise\n",
        "    m3 = re.match(r'^(prefix)\\s+([a-z\\-]+)', l)\n",
        "    if m3 and m3.group(2).endswith('-') and re.match(r'^[a-z\\-]+-$', m3.group(2)):\n",
        "        return \"prefix\", m3.group(2)\n",
        "    m4 = re.match(r'^(suffix)\\s+(\\-[a-z\\-]+)', l)\n",
        "    if m4:\n",
        "        return \"suffix\", m4.group(2)\n",
        "    return None\n",
        "\n",
        "doc = Document(str(DOCX))\n",
        "lines = []\n",
        "for para in doc.paragraphs:\n",
        "    txt = para.text\n",
        "    if txt is None:\n",
        "        continue\n",
        "    t = norm_token(txt)\n",
        "    if not t:\n",
        "        continue\n",
        "    lines.append(t)\n",
        "\n",
        "# Sweep through lines, collect examples under the last seen header until a new header\n",
        "current = None  # (kind, morpheme)\n",
        "buckets = defaultdict(list)  # (kind,morpheme) -> [examples]\n",
        "\n",
        "for raw in lines:\n",
        "    hdr = is_header(raw)\n",
        "    if hdr:\n",
        "        current = hdr  # set active bucket\n",
        "        continue\n",
        "    if not current:\n",
        "        # Not under a header — skip noisy list blocks\n",
        "        continue\n",
        "    # explode lines that still contain counts or commas/spaces into tokens\n",
        "    # keep A–Z strings (incl. hyphens, apostrophes), drop stray numbers\n",
        "    tokens = re.findall(r\"[A-Za-z][A-Za-z'’\\-]*\", raw)\n",
        "    for tok in tokens:\n",
        "        w = norm_token(tok)\n",
        "        if not w:\n",
        "            continue\n",
        "        # avoid mistakenly re-adding the morpheme itself as an example\n",
        "        _, morpheme = current\n",
        "        if w.lower() == morpheme.strip('-').lower():\n",
        "            continue\n",
        "        key = current\n",
        "        buckets[key].append(w)\n",
        "\n",
        "# Deduplicate and lightly cap examples per morpheme (keeps order of first occurrence)\n",
        "MAX_EXAMPLES = 150\n",
        "clean = defaultdict(list)\n",
        "seen_pair = set()\n",
        "for (kind, morph), words in buckets.items():\n",
        "    seen = set()\n",
        "    out = []\n",
        "    for w in words:\n",
        "        wl = w.lower()\n",
        "        if wl in seen:\n",
        "            continue\n",
        "        seen.add(wl)\n",
        "        out.append(w)\n",
        "        if len(out) >= MAX_EXAMPLES:\n",
        "            break\n",
        "    clean[(kind, morph)] = out\n",
        "\n",
        "# Write CSV\n",
        "with OUT_CSV.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"kind\",\"morpheme\",\"example\"])\n",
        "    rows = 0\n",
        "    for (kind, morph), lst in clean.items():\n",
        "        for ex in lst:\n",
        "            writer.writerow([kind, morph, ex])\n",
        "            rows += 1\n",
        "\n",
        "# Also write JSON in the simple shape your training uses\n",
        "prefixes = {}\n",
        "suffixes = {}\n",
        "for (kind, morph), lst in clean.items():\n",
        "    if kind == \"prefix\":\n",
        "        prefixes[morph] = lst\n",
        "    else:\n",
        "        suffixes[morph] = lst\n",
        "\n",
        "affixes_json = {\"prefixes\": prefixes, \"suffixes\": suffixes}\n",
        "with OUT_JSON.open(\"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(affixes_json, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"[done] wrote {OUT_CSV} and {OUT_JSON}\")\n",
        "print(f\"  prefixes={len(prefixes)} | suffixes={len(suffixes)}\")\n",
        "# quick peek\n",
        "for k, v in list(prefixes.items())[:5]:\n",
        "    print(\"  prefix\", k, \"egs:\", v[:6])\n",
        "for k, v in list(suffixes.items())[:5]:\n",
        "    print(\"  suffix\", k, \"egs:\", v[:6])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfyPll61h5by",
        "outputId": "bb7b3261-7b8c-4509-9d4d-8b0158620828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m245.8/253.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h[done] wrote /content/affixes.csv and /content/affixes.json\n",
            "  prefixes=184 | suffixes=200\n",
            "  prefix ab- egs: ['ove', 'Abaft', 'Abcd', 'Abe', 'Abecedeed', 'Abject']\n",
            "  prefix abs- egs: ['Absolute']\n",
            "  prefix acro- egs: ['Acropoll']\n",
            "  prefix ad- egs: ['Added', 'Addedto', 'Addicted', 'addition', 'Adiaptotously', 'Admiracion']\n",
            "  prefix all- egs: ['allbust', 'alliance', 'allinall', 'allmarken', 'allmysty', 'alloaf']\n",
            "  suffix -a egs: ['Ada', 'Africa', 'Allsea', 'America', 'Anna', 'Aquila']\n",
            "  suffix -ata egs: ['Cryptoconchoidsiphonostomata', 'Spezzata']\n",
            "  suffix -able egs: ['alloilable', 'im-pugnable', 'Impermeable', 'inevitable', 'Parable', 'peacable']\n",
            "  suffix -ible egs: ['Inaccessible', 'Incredible', 'Inexhaustible', 'Invisible', 'pensible', 'plusible']\n",
            "  suffix -uble egs: ['Double', 'Trouble']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "os.environ[\"PYTHONHASHSEED\"] = \"1337\"\n",
        "\n",
        "import torch\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = False\n",
        "torch.backends.cudnn.allow_tf32 = False\n",
        "torch.use_deterministic_algorithms(True)\n",
        "\n",
        "import random, json, math, re\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "SEED = 1337\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "print(\"Morpheme chaos mode activated\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpvYNSFoU5k7",
        "outputId": "82f601a8-b6f6-4daf-8b9d-b463da030ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Morpheme chaos mode activated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "config"
      ],
      "metadata": {
        "id": "CTO4KqfqWTfT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj0xrjyMUi7Z",
        "outputId": "9d0e528a-41cb-44f5-8ec4-2658ffb5d800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run ID: morpheme_wake_20251030_0017\n",
            "Teaching TinyLlama Joyce's morphological grammar...\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "CORPUS_PATH = \"/content/fw.txt\"\n",
        "MORPHEME_DATA_PATH = \"/content/affixes_terms.txt\"\n",
        "\n",
        "# Training params\n",
        "BATCH_SIZE = 2\n",
        "BLOCK_SIZE = 256\n",
        "EPOCHS = 2\n",
        "LR = 2e-5\n",
        "WARMUP_RATIO = 0.05\n",
        "WEIGHT_DECAY = 0.01\n",
        "GRAD_ACCUM = 4\n",
        "SAVE_STEPS = 200\n",
        "\n",
        "# Morpheme chaos params\n",
        "SYNTHETIC_PER_MORPHEME = 10  # Generate N examples per morpheme combo\n",
        "COMPOSITION_ALPHA = 0.33     # Weight for prefix:root:suffix (0.33:0.34:0.33)\n",
        "MORPHEME_NOISE = 0.05        # Add chaos to composed embeddings\n",
        "\n",
        "# Output\n",
        "RUN_ID = datetime.now().strftime(\"morpheme_wake_%Y%m%d_%H%M\")\n",
        "OUTDIR = Path(f\"./runs/{RUN_ID}\")\n",
        "(OUTDIR / \"results\").mkdir(parents=True, exist_ok=True)\n",
        "(OUTDIR / \"checkpoints\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Run ID: {RUN_ID}\")\n",
        "print(f\"Teaching TinyLlama Joyce's morphological grammar...\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_corpus(path):\n",
        "    p = Path(path)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"Corpus not found: {p}\")\n",
        "    text = p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "    print(f\"✓ Loaded corpus: {len(text)} chars\")\n",
        "    return text\n",
        "\n",
        "FW_TEXT = load_corpus(CORPUS_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxULlIp5Xl6s",
        "outputId": "1e8a7dc3-6635-4bc1-c4de-4f0392cf0916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Loaded corpus: 1364712 chars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "parse morpheme data"
      ],
      "metadata": {
        "id": "ynxUJIYnXyVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_morpheme_document(text):\n",
        "    \"\"\"\n",
        "    Parse your hand-compiled morpheme analysis into structured data.\n",
        "    Returns: {prefixes: {}, suffixes: {}, examples: {}}\n",
        "    \"\"\"\n",
        "    data = {\n",
        "        'prefixes': defaultdict(list),\n",
        "        'suffixes': defaultdict(list),\n",
        "        'infixes': defaultdict(list),\n",
        "        'prefix_counts': Counter(),\n",
        "        'suffix_counts': Counter(),\n",
        "    }\n",
        "\n",
        "    lines = text.split('\\n')\n",
        "    current_type = None\n",
        "    current_morph = None\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        # Detect section headers\n",
        "        if line.startswith('Prefix') or line.startswith('prefix'):\n",
        "            current_type = 'prefix'\n",
        "            # Extract morpheme: \"Prefix ab- 13\" -> \"ab-\"\n",
        "            parts = line.split()\n",
        "            if len(parts) >= 2:\n",
        "                current_morph = parts[1].lower()\n",
        "                count = int(parts[2]) if len(parts) > 2 and parts[2].isdigit() else 1\n",
        "                data['prefix_counts'][current_morph] = count\n",
        "\n",
        "        elif line.startswith('Suffix') or line.startswith('suffix'):\n",
        "            current_type = 'suffix'\n",
        "            parts = line.split()\n",
        "            if len(parts) >= 2:\n",
        "                current_morph = parts[1].lower()\n",
        "                count = int(parts[2]) if len(parts) > 2 and parts[2].isdigit() else 1\n",
        "                data['suffix_counts'][current_morph] = count\n",
        "\n",
        "        elif line.startswith('Infix') or line.startswith('infix'):\n",
        "            current_type = 'infix'\n",
        "            parts = line.split()\n",
        "            if len(parts) >= 2:\n",
        "                current_morph = parts[1].lower()\n",
        "\n",
        "        # Collect examples (lines that aren't headers)\n",
        "        elif current_type and current_morph:\n",
        "            # Skip lines with numbers only or special headers\n",
        "            if line[0].isupper() and current_type in ['prefix', 'suffix']:\n",
        "                continue\n",
        "\n",
        "            # Clean example words\n",
        "            word = line.split()[0] if line.split() else line\n",
        "            word = word.strip('.,;:()[]{}\\\"\\'')\n",
        "\n",
        "            if word and len(word) > 1:\n",
        "                if current_type == 'prefix':\n",
        "                    data['prefixes'][current_morph].append(word)\n",
        "                elif current_type == 'suffix':\n",
        "                    data['suffixes'][current_morph].append(word)\n",
        "                elif current_type == 'infix':\n",
        "                    data['infixes'][current_morph].append(word)\n",
        "\n",
        "    # Convert defaultdicts to regular dicts\n",
        "    data['prefixes'] = dict(data['prefixes'])\n",
        "    data['suffixes'] = dict(data['suffixes'])\n",
        "    data['infixes'] = dict(data['infixes'])\n",
        "\n",
        "    return data\n",
        "\n",
        "# Load and parse your morpheme data\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PARSING HAND-COMPILED MORPHEME DATA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "morpheme_doc = Path(MORPHEME_DATA_PATH)\n",
        "if morpheme_doc.exists():\n",
        "    morpheme_text = morpheme_doc.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "    MORPHEME_DATA = parse_morpheme_document(morpheme_text)\n",
        "else:\n",
        "    # Fallback: extract from the text you pasted inline\n",
        "    print(\"⚠ Morpheme data file not found, using inline extraction...\")\n",
        "    # You can paste your dataset here as a string if needed\n",
        "    MORPHEME_DATA = {\n",
        "        'prefixes': {\n",
        "            'ab-': ['above', 'abaft', 'abject', 'abler'],\n",
        "            'anti-': ['anticipation', 'antipathies'],\n",
        "            'circum-': ['circumvallator'],\n",
        "            'hyper-': ['hyperchemical'],\n",
        "            'sub-': ['subject', 'substrate', 'subordinating'],\n",
        "        },\n",
        "        'suffixes': {\n",
        "            '-ation': ['acclammitation', 'anticipation', 'paupulation'],\n",
        "            '-ous': ['delicious', 'precious', 'gracious'],\n",
        "            '-ness': ['darkness', 'sweetness', 'softness'],\n",
        "            '-ing': ['going', 'coming', 'being'],\n",
        "        },\n",
        "        'prefix_counts': Counter({'ab-': 13, 'anti-': 2, 'circum-': 1, 'hyper-': 1, 'sub-': 7}),\n",
        "        'suffix_counts': Counter({'-ation': 38, '-ous': 49, '-ness': 28, '-ing': 257}),\n",
        "    }\n",
        "\n",
        "print(f\"Parsed {len(MORPHEME_DATA['prefixes'])} prefixes\")\n",
        "print(f\"Parsed {len(MORPHEME_DATA['suffixes'])} suffixes\")\n",
        "print(f\"\\nTop prefixes by frequency:\")\n",
        "for morph, count in MORPHEME_DATA['prefix_counts'].most_common(10):\n",
        "    print(f\"  {morph}: {count}\")\n",
        "print(f\"\\nTop suffixes by frequency:\")\n",
        "for morph, count in MORPHEME_DATA['suffix_counts'].most_common(10):\n",
        "    print(f\"  {morph}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5rPEZ76Xqt0",
        "outputId": "62f06c9c-8c81-46f9-8e70-3e5d7b0da7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PARSING HAND-COMPILED MORPHEME DATA\n",
            "============================================================\n",
            "✓ Parsed 0 prefixes\n",
            "✓ Parsed 1 suffixes\n",
            "\n",
            "Top prefixes by frequency:\n",
            "\n",
            "Top suffixes by frequency:\n",
            "  –‘s: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Build MORPHEME_DATA from a flat term list (affixes_terms.txt) ====\n",
        "import re\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "AFFIX_TXT = Path(\"/content/affixes_terms.txt\")  # one term per line\n",
        "EXAMPLES_PER_MORPHEME = 120                     # cap examples per morpheme\n",
        "\n",
        "if not AFFIX_TXT.exists():\n",
        "    raise FileNotFoundError(f\"Missing {AFFIX_TXT}. Upload your affixes_terms.txt first.\")\n",
        "\n",
        "# --- Curated affix lists (extend as you like) ---\n",
        "PREFIXES = [\n",
        "    \"anti-\",\"ante-\",\"arch-\",\"auto-\",\"bi-\",\"bio-\",\"co-\",\"con-\",\"contra-\",\"counter-\",\n",
        "    \"crypto-\",\"de-\",\"dis-\",\"down-\",\"en-\",\"em-\",\"ex-\",\"extra-\",\"fore-\",\"geo-\",\"hetero-\",\n",
        "    \"homo-\",\"hyper-\",\"hypo-\",\"il-\",\"im-\",\"in-\",\"inter-\",\"intra-\",\"ir-\",\"macro-\",\n",
        "    \"mega-\",\"meta-\",\"micro-\",\"mid-\",\"mis-\",\"mono-\",\"multi-\",\"neo-\",\"non-\",\"omni-\",\n",
        "    \"over-\",\"pan-\",\"para-\",\"peri-\",\"poly-\",\"post-\",\"pre-\",\"pro-\",\"proto-\",\"pseudo-\",\n",
        "    \"re-\",\"semi-\",\"sub-\",\"super-\",\"supra-\",\"sur-\",\"tele-\",\"trans-\",\"tri-\",\"ultra-\",\n",
        "    \"un-\",\"under-\",\"uni-\",\"up-\",\"vice-\",\n",
        "    # Joycean-friendly add-ons\n",
        "    \"quasi-\",\"infra-\",\"intro-\",\"out-\",\"sous-\",\"uber-\"\n",
        "]\n",
        "PREFIXES.sort(key=len, reverse=True)\n",
        "\n",
        "SUFFIXES = [\n",
        "    \"-ability\",\"-ibility\",\"-ation\",\"-ition\",\"-ication\",\"-ization\",\n",
        "    \"-ment\",\"-ness\",\"-less\",\"-ful\",\"-able\",\"-ible\",\"-ish\",\"-ism\",\"-ist\",\"-ity\",\"-ety\",\n",
        "    \"-ive\",\"-ative\",\"-tive\",\"-al\",\"-ial\",\"-ual\",\"-ary\",\"-ory\",\"-ature\",\n",
        "    \"-ous\",\"-eous\",\"-ious\",\"-esque\",\"-ific\",\"-logue\",\"-logy\",\"-ology\",\"-ography\",\n",
        "    \"-ship\",\"-hood\",\"-ward\",\"-wards\",\"-wise\",\"-y\",\"-ly\",\"-er\",\"-or\",\"-eer\",\"-eur\",\n",
        "    \"-ette\",\"-let\",\"-ling\",\"-kin\",\"-ance\",\"-ence\",\"-ancy\",\"-ency\",\"-ure\",\n",
        "    \"-ium\",\"-um\",\"-arium\",\"-orium\",\"-dom\",\n",
        "    # (Optional) inflectional:\n",
        "    \"-ing\",\"-ed\",\"-en\",\"-s\",\"-es\",\n",
        "    # Joycean-friendly\n",
        "    \"-scape\",\"-some\",\"-smith\",\"-most\",\"-worthy\",\"-gate\",\"-tron\",\"-plex\",\"-polis\"\n",
        "]\n",
        "SUFFIXES.sort(key=len, reverse=True)\n",
        "\n",
        "# --- helpers ---\n",
        "def _clean_line(s: str) -> str:\n",
        "    s = (s or \"\").strip()\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    # keep letters, hyphens, apostrophes; strip outer junk\n",
        "    s = re.sub(r\"^[^A-Za-z'’-]+|[^A-Za-z'’-]+$\", \"\", s)\n",
        "    s = s.replace(\"’\", \"'\")\n",
        "    return s\n",
        "\n",
        "def _longest_prefix(word: str):\n",
        "    wl = word.lower()\n",
        "    for p in PREFIXES:\n",
        "        core = p[:-1]  # drop trailing '-'\n",
        "        if wl.startswith(core) and len(wl) > len(core)+0:  # allow short roots\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "def _longest_suffix(word: str):\n",
        "    wl = word.lower()\n",
        "    for s in SUFFIXES:\n",
        "        core = s[1:]  # drop leading '-'\n",
        "        if wl.endswith(core) and len(wl) > len(core)+0:\n",
        "            return s\n",
        "    return None\n",
        "\n",
        "# --- load terms ---\n",
        "terms = []\n",
        "with AFFIX_TXT.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "    for line in f:\n",
        "        t = _clean_line(line)\n",
        "        if not t or not re.search(r\"[A-Za-z]\", t):\n",
        "            continue\n",
        "        # skip accidental section headers like \"Prefix\", \"Suffix\" if present\n",
        "        if re.match(r\"(?i)^(prefix|suffix|infix)\\b\", t):\n",
        "            continue\n",
        "        terms.append(t)\n",
        "\n",
        "# --- build morpheme -> examples maps ---\n",
        "prefix_map = defaultdict(list)\n",
        "suffix_map = defaultdict(list)\n",
        "\n",
        "for w in terms:\n",
        "    p = _longest_prefix(w)\n",
        "    s = _longest_suffix(w)\n",
        "    if p:\n",
        "        prefix_map[p].append(w)\n",
        "    if s:\n",
        "        suffix_map[s].append(w)\n",
        "\n",
        "# --- dedupe & cap examples ---\n",
        "def _dedupe_cap(d):\n",
        "    out = {}\n",
        "    for k, lst in d.items():\n",
        "        seen = set()\n",
        "        keep = []\n",
        "        for w in lst:\n",
        "            wl = w.lower()\n",
        "            if wl in seen:\n",
        "                continue\n",
        "            seen.add(wl)\n",
        "            keep.append(w)\n",
        "            if len(keep) >= EXAMPLES_PER_MORPHEME:\n",
        "                break\n",
        "        out[k] = keep\n",
        "    return out\n",
        "\n",
        "prefix_map = _dedupe_cap(prefix_map)\n",
        "suffix_map = _dedupe_cap(suffix_map)\n",
        "\n",
        "# --- final structure for your functions ---\n",
        "MORPHEME_DATA = {\n",
        "    \"prefixes\": dict(prefix_map),\n",
        "    \"suffixes\": dict(suffix_map),\n",
        "}\n",
        "\n",
        "# --- preview ---\n",
        "def _peek(d, n=5):\n",
        "    return {k: d[k][:min(len(d[k]), 3)] for k in list(d.keys())[:n]}\n",
        "\n",
        "print(f\"[MORPHEME_DATA] prefixes={len(MORPHEME_DATA['prefixes'])} | suffixes={len(MORPHEME_DATA['suffixes'])}\")\n",
        "print(\"  sample prefixes:\", _peek(MORPHEME_DATA[\"prefixes\"]))\n",
        "print(\"  sample suffixes:\", _peek(MORPHEME_DATA[\"suffixes\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pY1r0ddjfKK",
        "outputId": "ce44a77d-9784-4add-80e9-02ae992b2667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MORPHEME_DATA] prefixes=57 | suffixes=63\n",
            "  sample prefixes: {'anti-': ['anti-cipation', 'Anticipation', 'antipathies'], 'auto-': ['Autotone', 'autotune'], 'co-': ['Cocoa', 'columna', 'Coal'], 'con-': ['Conna', 'Constellatria', 'conceal'], 'crypto-': ['Cryptoconchoidsiphonostomata']}\n",
            "  sample suffixes: {'-s': ['Aas', 'accacians', 'Accidents'], '-y': ['Abby', 'Accuracy', 'aisy'], '-ed': ['abecedeed', 'accorded', 'Achamed'], '-er': ['abler', 'Acquiester', 'admirer'], '-al': ['Accidental', 'Apersonal', 'Appeal']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " LOAD MODEL & TOKENIZER"
      ],
      "metadata": {
        "id": "-2Vr8nAKYDqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, set_seed\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(DEVICE)\n",
        "\n",
        "print(f\"\\nModel: {MODEL_NAME}\")\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(f\"Initial vocab: {len(tok)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431,
          "referenced_widgets": [
            "0bb24b6826f74b36bc006ed702b1b2d0",
            "8c86e6d00afb4240958f8a350d2f9345",
            "8e842c8014d94ebfab9ef2b11e803175",
            "2e938c8d0f0d468ebe1f33d3cc8c3d49",
            "030bf06809964a86aafeb5a067c818ca",
            "dd325af3ad0a4f7abaefd7cb9861f35a",
            "9af2320fa4284dae840c05b3c632a38f",
            "bc0ea95baf0c4698a942b41b8021026b",
            "a4fb1cd74afe4eeaa7622cb7ece836a6",
            "f1b45270224741f2a18b270d73dab87a",
            "489e9447d4594c7c8fc376f6f5d762ea",
            "809617d38ef84337903a8f5c5135eaf4",
            "ce1d8834e83940a4851bb1546dd29b09",
            "1dc25cdb15904320be597fdca2471ccc",
            "15f770d3fe7e404da9bc4dff6afd0688",
            "c1d3f8a71f014d5ba512653fd83d7ffd",
            "826448d8cbe548df9e45afbba358e709",
            "537eb4a7bf08455ba51f9512ab801024",
            "59e612ecad0b4507a6f110f9fc08fdcd",
            "4cc7f83ec02046bfb7cd0d08dc1fbfd2",
            "5596e4bf864149b89fb5c7f4f47275b3",
            "400851f83b354613954a48def65548e2",
            "161e147ccc8947b98bfecb4ada4d24db",
            "555c4a23d6f246b086f6c67cb89d2781",
            "c598b481d0284b6f9fd69c91fa3c9e04",
            "90ac5f803cd74f52b11d43eafe3c00ef",
            "aa80b06153c14686ad63bc0e07d252d1",
            "b32837b274844c7996fee2633a4881e6",
            "ec22777d2cfe4dbdbcc9930215746441",
            "4eef2434f43b45249f26aa8e1e7a3765",
            "cf04a568ef104fbdaad261e05c018d20",
            "df370d80adbc413aba8887d6f538e7f0",
            "c67683fcf95645688699d4757dfe6a2d",
            "2b99857eee93490db5de7ada6b9ccb2e",
            "6a69c030f6cb4cc1a1b01c356faf438b",
            "3d4bae708a27462994de889571a8a308",
            "a4e8407302774887b15b77aadaa9d99c",
            "20691a4817e54a778232961f1c295558",
            "aad6709d972547da84aa758e28b869d4",
            "12b884b754cc442fa9ba1f0abf5cd8f7",
            "28e54b24c2e2413b8623b9d54cc2d5f2",
            "a36fd92746904cfe894123e8dd01a23c",
            "7de61d565a3a4d84b1d0aed4841ad7ca",
            "a050e3bbb56d46fe922c44d6a9ce4c6b",
            "6b769d88bc9c4df2979c38270e8f5c20",
            "0777df12a2014a0c899ba694f62abfc4",
            "7338c81df8db4dd4ad4505ad34011aa7",
            "37f4c44e845546898d901b7b9eb49c32",
            "0dc787313e5b47ef9521bc82dac1a0e6",
            "e8a933b4cae24db199f4bdb32b85d6ab",
            "bad8728a627a44ab88acbd73f9f862e3",
            "23dda180301543e2b15c826e00a78a85",
            "093d54f181c54e849065c0a05ae2f718",
            "0a5c0063fb8947ac99eda906109dd78c",
            "d72cb3130aa94e6295e36c0a3e645b5d",
            "c6f7789e2eb646ec9f609a2e2d9fc20f",
            "d381fcdf0cac4eab9a31911a043c7768",
            "77d23fcb7d3d4acdb93b5c7a8a9607e2",
            "547a71d243674b13948cb2ff7bb02e45",
            "adf7d62c8b2d4f6d91d66a747dd33aca",
            "38c2580658964e30be96fcc7ff3f0c3e",
            "61b83bd9cd0f4f5395feac2c109e4f05",
            "ed308d19a9f04bf697f3d035f6107a0f",
            "4a8e6e548ee748439931587e8ee70af9",
            "ac33ced032324b75b0099792637a6ee8",
            "a0acd2f5df3644738eccbf83cae6b7f6",
            "a5d92e57e6fb431da3ad835686a4dc58",
            "4cfbe43598664048a728c1cd60231ada",
            "f7a51019394f4c1e9ba0ceb892974f5f",
            "e47e20bc11974e89a35dba652d4f0e72",
            "6c183771da394d99be8eb1458e719aa9",
            "72b97cfc379943afa9dcaac2922ce882",
            "d3235fdf032b4533bdc85c7b5234b3b9",
            "bf3d4d307ee744a1b39d9fe78c42b230",
            "7ae8b9f605cd4827b787fd57bdcb4cf6",
            "d54001d569a6485989f3fb360dc94715",
            "0c626591ad094c48b5c6fff028528d98"
          ]
        },
        "id": "SKlnV6e-YErr",
        "outputId": "ec1a9e68-d4f8-4db4-813f-6c59a629a9f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bb24b6826f74b36bc006ed702b1b2d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "809617d38ef84337903a8f5c5135eaf4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "161e147ccc8947b98bfecb4ada4d24db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b99857eee93490db5de7ada6b9ccb2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b769d88bc9c4df2979c38270e8f5c20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6f7789e2eb646ec9f609a2e2d9fc20f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5d92e57e6fb431da3ad835686a4dc58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
            "Device: cuda\n",
            "Initial vocab: 32000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "def _clean_line(s: str) -> str:\n",
        "    s = (s or \"\").strip()\n",
        "    s = re.sub(r\"\\b\\d+\\b$\", \"\", s).strip()                 # drop trailing counts\n",
        "    s = re.sub(r\"\\((sic|decap)\\)\", \"\", s, flags=re.I).strip()\n",
        "    return s\n",
        "\n",
        "def _normalise_affix(kind: str, aff: str) -> str:\n",
        "    aff = (aff or \"\").replace(\"–\",\"-\").strip()\n",
        "    if not aff: return \"\"\n",
        "    if kind == \"prefix\":\n",
        "        return aff if aff.endswith(\"-\") else (aff + \"-\")\n",
        "    if kind == \"suffix\":\n",
        "        return aff if aff.startswith(\"-\") else (\"-\" + aff)\n",
        "    return aff\n",
        "\n",
        "prefix_map = MORPHEME_DATA.get(\"prefixes\", {})\n",
        "suffix_map = MORPHEME_DATA.get(\"suffixes\", {})\n",
        "\n",
        "def _dedupe_cap(d, limit):\n",
        "    out = {}\n",
        "    for k, lst in d.items():\n",
        "        seen = set()\n",
        "        uniq = []\n",
        "        for w in lst:\n",
        "            wl = w.lower()\n",
        "            if wl not in seen:\n",
        "                seen.add(wl)\n",
        "                uniq.append(w)\n",
        "            if len(uniq) >= limit:\n",
        "                break\n",
        "        out[k] = uniq\n",
        "    return out\n",
        "\n",
        "def _peek(d, n=5):\n",
        "    # Ensure we only sample from keys that actually have examples\n",
        "    valid_keys = [k for k in d.keys() if d[k]]\n",
        "    sample_keys = random.sample(valid_keys, min(n, len(valid_keys))) if valid_keys else []\n",
        "    return {k: d[k][:min(len(d[k]),3)] for k in sample_keys}\n",
        "\n",
        "\n",
        "print(f\"[MORPHEME_DATA] prefixes={len(MORPHEME_DATA.get('prefixes', {}))} | suffixes={len(MORPHEME_DATA.get('suffixes', {}))}\")\n",
        "print(\"  sample prefixes:\", _peek(MORPHEME_DATA.get(\"prefixes\", {})))\n",
        "print(\"  sample suffixes:\", _peek(MORPHEME_DATA.get(\"suffixes\", {})))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-RJHYHFb5ue",
        "outputId": "335ff813-1ba9-4a31-ab08-0b47e06d84c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MORPHEME_DATA] prefixes=57 | suffixes=63\n",
            "  sample prefixes: {'out-': ['Outnullused', 'Outer', 'Outing'], 'semi-': ['semination', 'semicolonials'], 'fore-': ['Forest', 'Forecast', 'Foretellers'], 'homo-': ['homo-gallant', 'homoheatherous', 'Homoid'], 'mega-': ['Megacene', 'Megalopolis']}\n",
            "  sample suffixes: {'-ication': ['Fornication', 'Gratification', 'Intoxication'], '-ness': ['deleteriousness of decorousness', 'badness', 'Breadchestviousness'], '-ance': ['acquointance', 'advance', 'Alliance'], '-ette': ['liffeyette', 'pepette', 'pette'], '-hood': ['childhood']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# sensible defaults (honour existing globals if defined elsewhere)\n",
        "COMPOSITION_ALPHA = float(globals().get(\"COMPOSITION_ALPHA\", 0.2))\n",
        "MORPHEME_NOISE    = float(globals().get(\"MORPHEME_NOISE\", 0.03))\n",
        "DEVICE            = next(model.parameters()).device\n",
        "\n",
        "def _tok_ids(text, tokenizer):\n",
        "    return tokenizer(text, add_special_tokens=False)[\"input_ids\"]\n",
        "\n",
        "def _vec_mean(ids, emb_matrix):\n",
        "    if not ids:\n",
        "        return None\n",
        "    vecs = emb_matrix[torch.as_tensor(ids, device=emb_matrix.device)]\n",
        "    return vecs.mean(dim=0)\n",
        "\n",
        "def _single_token_id(text, tokenizer):\n",
        "    ids = _tok_ids(text, tokenizer)\n",
        "    return ids[0] if len(ids) == 1 else None\n",
        "\n",
        "def _kind_of(morpheme: str):\n",
        "    # prefixes end with '-', suffixes start with '-'\n",
        "    if morpheme.endswith('-'): return \"prefix\"\n",
        "    if morpheme.startswith('-'): return \"suffix\"\n",
        "    return None\n",
        "\n",
        "def _nearest_morpheme_backoff(morpheme, emb_matrix, tokenizer, k=8):\n",
        "    \"\"\"\n",
        "    Try to find another morpheme of the same kind with examples,\n",
        "    take the average embedding across a few of its examples.\n",
        "    \"\"\"\n",
        "    kind = _kind_of(morpheme)\n",
        "    if kind is None:\n",
        "        return None\n",
        "\n",
        "    pool = MORPHEME_DATA[\"prefixes\"] if kind == \"prefix\" else MORPHEME_DATA[\"suffixes\"]\n",
        "    if not pool:\n",
        "        return None\n",
        "\n",
        "    # crude lexical proximity: same first letters (after stripping hyphen)\n",
        "    stem = morpheme.strip('-').lower()\n",
        "    candidates = []\n",
        "    for m, exs in pool.items():\n",
        "        if not exs:\n",
        "            continue\n",
        "        score = 0\n",
        "        mstem = m.strip('-').lower()\n",
        "        # shared prefix length heuristic\n",
        "        for a, b in zip(stem, mstem):\n",
        "            if a == b: score += 1\n",
        "            else: break\n",
        "        candidates.append((score, m, exs))\n",
        "\n",
        "    if not candidates:\n",
        "        return None\n",
        "    candidates.sort(key=lambda x: x[0], reverse=True)\n",
        "    # take a few top candidates’ example words\n",
        "    ex_words = []\n",
        "    for _, _, exs in candidates[:k]:\n",
        "        ex_words.extend(exs[:5])\n",
        "    if not ex_words:\n",
        "        return None\n",
        "\n",
        "    emb_list = []\n",
        "    for w in ex_words:\n",
        "        ids = _tok_ids(w.lower(), tokenizer)\n",
        "        v = _vec_mean(ids, emb_matrix)\n",
        "        if v is not None:\n",
        "            emb_list.append(v)\n",
        "    if emb_list:\n",
        "        return torch.stack(emb_list).mean(dim=0)\n",
        "    return None\n",
        "\n",
        "def find_morpheme_embedding(morpheme, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Strategy:\n",
        "    1) If morpheme is a single tokenizer piece, return that vector.\n",
        "    2) Else average embeddings of example words containing it (token-averaged).\n",
        "    3) Else average embeddings of morpheme's own subtokens.\n",
        "    4) Else back off to a similar morpheme's examples.\n",
        "    5) Else random normal scaled to emb std.\n",
        "    \"\"\"\n",
        "    emb_matrix = model.get_input_embeddings().weight.data\n",
        "\n",
        "    # --- 1) single-token morpheme (e.g., some BPEs may have \"re\" + \"-\" separate; we require length == 1)\n",
        "    stid = _single_token_id(morpheme, tokenizer)\n",
        "    if stid is not None:\n",
        "        return emb_matrix[stid].clone()\n",
        "\n",
        "    # --- 2) average example words for this morpheme (from MORPHEME_DATA)\n",
        "    examples = []\n",
        "    if morpheme in MORPHEME_DATA.get('prefixes', {}):\n",
        "        examples = MORPHEME_DATA['prefixes'][morpheme][:32]\n",
        "    elif morpheme in MORPHEME_DATA.get('suffixes', {}):\n",
        "        examples = MORPHEME_DATA['suffixes'][morpheme][:32]\n",
        "\n",
        "    if examples:\n",
        "        emb_list = []\n",
        "        for w in examples:\n",
        "            ids = _tok_ids(w.lower(), tokenizer)\n",
        "            v = _vec_mean(ids, emb_matrix)\n",
        "            if v is not None:\n",
        "                emb_list.append(v)\n",
        "        if emb_list:\n",
        "            return torch.stack(emb_list).mean(dim=0)\n",
        "\n",
        "    # --- 3) average the morpheme’s own subtokens (strip the hyphen so BPE sees letters)\n",
        "    morph_text = morpheme.strip('-').lower()\n",
        "    ids = _tok_ids(morph_text, tokenizer)\n",
        "    v = _vec_mean(ids, emb_matrix)\n",
        "    if v is not None:\n",
        "        return v\n",
        "\n",
        "    # --- 4) neighbor backoff from same kind\n",
        "    v = _nearest_morpheme_backoff(morpheme, emb_matrix, tokenizer)\n",
        "    if v is not None:\n",
        "        return v\n",
        "\n",
        "    # --- 5) final fallback: random normal scaled to overall emb std\n",
        "    return torch.randn(emb_matrix.shape[1], device=emb_matrix.device) * emb_matrix.std()\n",
        "\n",
        "def compose_morpheme_embedding(prefix, root, suffix, model, tokenizer):\n",
        "    \"\"\"\n",
        "    E(word) = α * E(prefix) + β * E(root) + γ * E(suffix),  where β = 1 - 2α\n",
        "    If a component is missing, its vector is a zero vector.\n",
        "    Root uses token-mean; if missing, small random normal.\n",
        "    \"\"\"\n",
        "    emb_matrix = model.get_input_embeddings().weight.data\n",
        "    dim = emb_matrix.shape[1]\n",
        "    alpha = COMPOSITION_ALPHA\n",
        "    beta  = 1.0 - 2.0 * alpha\n",
        "    gamma = alpha\n",
        "\n",
        "    # prefix / suffix vecs (zero if None/empty)\n",
        "    if prefix:\n",
        "        prefix_vec = find_morpheme_embedding(prefix, model, tokenizer)\n",
        "    else:\n",
        "        prefix_vec = torch.zeros(dim, device=emb_matrix.device)\n",
        "\n",
        "    if suffix:\n",
        "        suffix_vec = find_morpheme_embedding(suffix, model, tokenizer)\n",
        "    else:\n",
        "        suffix_vec = torch.zeros(dim, device=emb_matrix.device)\n",
        "\n",
        "    # root vec: average token pieces (more robust than single-id lookup)\n",
        "    root_ids = _tok_ids((root or \"\").lower(), tokenizer)\n",
        "    if root_ids:\n",
        "        root_vec = _vec_mean(root_ids, emb_matrix)\n",
        "    else:\n",
        "        root_vec = None\n",
        "    if root_vec is None:\n",
        "        root_vec = torch.randn(dim, device=emb_matrix.device) * 0.02\n",
        "\n",
        "    composed = alpha * prefix_vec + beta * root_vec + gamma * suffix_vec\n",
        "\n",
        "    # small noise for diversity/stability\n",
        "    if MORPHEME_NOISE > 0:\n",
        "        std = composed.detach().std().clamp(min=1e-6)\n",
        "        composed = composed + torch.randn_like(composed) * (MORPHEME_NOISE * std)\n",
        "\n",
        "    return composed\n"
      ],
      "metadata": {
        "id": "f96z2chslj7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "gen synthetic wake words via morpheme combination"
      ],
      "metadata": {
        "id": "Y7uM8lLfYWSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "# --- ensure counts exist from MORPHEME_DATA['prefixes'/'suffixes'] ---\n",
        "def _ensure_morpheme_counts():\n",
        "    px = {m: len(exs) for m, exs in MORPHEME_DATA.get(\"prefixes\", {}).items()}\n",
        "    sx = {m: len(exs) for m, exs in MORPHEME_DATA.get(\"suffixes\", {}).items()}\n",
        "    # fallback if empty\n",
        "    if not px:\n",
        "        px = {\"re-\": 1, \"un-\": 1, \"in-\": 1}\n",
        "    if not sx:\n",
        "        sx = {\"-ness\": 1, \"-al\": 1, \"-ity\": 1}\n",
        "    MORPHEME_DATA[\"prefix_counts\"] = px\n",
        "    MORPHEME_DATA[\"suffix_counts\"] = sx\n",
        "\n",
        "_ensure_morpheme_counts()\n",
        "\n",
        "def generate_morpheme_words(n_samples=1000, p_prefix=0.7, p_suffix=0.8, roots=None, dedupe=True):\n",
        "    \"\"\"\n",
        "    Generate synthetic 'Wake-ish' words by composing prefix + root + suffix.\n",
        "    Frequencies are proportional to #examples recorded for each morpheme.\n",
        "    \"\"\"\n",
        "    generated = []\n",
        "\n",
        "    prefixes = list(MORPHEME_DATA[\"prefix_counts\"].keys())\n",
        "    suffixes = list(MORPHEME_DATA[\"suffix_counts\"].keys())\n",
        "    pw = [max(1, MORPHEME_DATA[\"prefix_counts\"][p]) for p in prefixes]\n",
        "    sw = [max(1, MORPHEME_DATA[\"suffix_counts\"][s]) for s in suffixes]\n",
        "\n",
        "    if not roots:\n",
        "        roots = [\n",
        "            'dream','river','thunder','word','night','day','wake','sleep',\n",
        "            'fire','water','time','man','woman','king','queen','stone',\n",
        "            'tree','moon','sun','star','wind','rain','storm','cloud',\n",
        "            'book','letter','voice','sound','song','dance','walk','run'\n",
        "        ]\n",
        "\n",
        "    seen = set()\n",
        "    for _ in range(n_samples):\n",
        "        use_p = (random.random() < p_prefix) and len(prefixes) > 0\n",
        "        use_s = (random.random() < p_suffix) and len(suffixes) > 0\n",
        "\n",
        "        prefix = random.choices(prefixes, weights=pw, k=1)[0] if use_p else None\n",
        "        suffix = random.choices(suffixes, weights=sw, k=1)[0] if use_s else None\n",
        "        root   = random.choice(roots)\n",
        "\n",
        "        # build word string without hyphen artifacts\n",
        "        def strip_hy(s, is_prefix):\n",
        "            if not s: return \"\"\n",
        "            return s[:-1] if is_prefix else s[1:]  # drop trailing '-' for prefix; leading '-' for suffix\n",
        "\n",
        "        word = f\"{strip_hy(prefix, True)}{root}{strip_hy(suffix, False)}\"\n",
        "\n",
        "        if dedupe:\n",
        "            if word in seen:\n",
        "                continue\n",
        "            seen.add(word)\n",
        "\n",
        "        generated.append({\n",
        "            \"word\": word,\n",
        "            \"prefix\": prefix,\n",
        "            \"root\": root,\n",
        "            \"suffix\": suffix\n",
        "        })\n",
        "\n",
        "    return generated\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GENERATING SYNTHETIC WAKE WORDS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "synthetic_words = generate_morpheme_words(n_samples=500)\n",
        "print(f\"✓ Generated {len(synthetic_words)} morphological neologisms\")\n",
        "\n",
        "print(\"\\nExamples:\")\n",
        "for w in synthetic_words[:20]:\n",
        "    print(f\"  {w['word']:20s} ({w['prefix'] or 'Ø'} + {w['root']} + {w['suffix'] or 'Ø'})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpeQqfEnmbNJ",
        "outputId": "8f439cc0-0b79-4f58-8183-6df71daa6cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "GENERATING SYNTHETIC WAKE WORDS\n",
            "============================================================\n",
            "✓ Generated 471 morphological neologisms\n",
            "\n",
            "Examples:\n",
            "  inlettersmith        (in- + letter + -smith)\n",
            "  cloudor              (Ø + cloud + -or)\n",
            "  innight              (in- + night + Ø)\n",
            "  misstares            (mis- + star + -es)\n",
            "  imdance              (im- + dance + Ø)\n",
            "  emdanceling          (em- + dance + -ling)\n",
            "  unthunder            (un- + thunder + Ø)\n",
            "  misword              (mis- + word + Ø)\n",
            "  consonger            (con- + song + -er)\n",
            "  wind                 (Ø + wind + Ø)\n",
            "  enqueen              (en- + queen + Ø)\n",
            "  unkingor             (un- + king + -or)\n",
            "  reworded             (re- + word + -ed)\n",
            "  riverly              (Ø + river + -ly)\n",
            "  stormity             (Ø + storm + -ity)\n",
            "  treeor               (Ø + tree + -or)\n",
            "  codayed              (co- + day + -ed)\n",
            "  overword             (over- + word + Ø)\n",
            "  imthunderary         (im- + thunder + -ary)\n",
            "  constormance         (con- + storm + -ance)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "token injection"
      ],
      "metadata": {
        "id": "LynN1U3AcYk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math, random, torch\n",
        "from datasets import Dataset\n",
        "\n",
        "# 1) Make tiny Joyce-ish sentences so the new tokens appear in context\n",
        "def lines_from_synth(synth, per_word=3):\n",
        "    patt = [\n",
        "        \"He said {w} and smiled at the rivery din.\",\n",
        "        \"They hummed {w} through the nightlong thunder.\",\n",
        "        \"A {w} fell between letter and time.\",\n",
        "        \"Write it as {w}, he urged, once and again.\",\n",
        "        \"Under cloud and over stone, {w} kept talking.\"\n",
        "    ]\n",
        "    out = []\n",
        "    for item in synth:\n",
        "        w = item[\"word\"]\n",
        "        for _ in range(per_word):\n",
        "            out.append(random.choice(patt).format(w=w))\n",
        "    return out\n",
        "\n",
        "aug_lines = lines_from_synth(synthetic_words, per_word=3)\n",
        "print(f\"[augment] {len(aug_lines)} synthetic lines from {len(synthetic_words)} words\")\n",
        "\n",
        "# 2) Add only words that aren't already single tokens; init embeddings by morpheme composition\n",
        "def is_single_token(tokenizer, s):\n",
        "    return len(tokenizer(s, add_special_tokens=False)[\"input_ids\"]) == 1\n",
        "\n",
        "to_add = [x for x in synthetic_words if not is_single_token(tok, x[\"word\"])]\n",
        "new_tokens = [x[\"word\"] for x in to_add]\n",
        "\n",
        "n_before = len(tok)\n",
        "added = tok.add_tokens(new_tokens, special_tokens=False)\n",
        "model.resize_token_embeddings(len(tok))\n",
        "print(f\"[tokenizer] added {added} new tokens (from {len(new_tokens)} candidates)\")\n",
        "\n",
        "# compose vectors for the *added* words and write them into the embedding matrix (tied to lm_head)\n",
        "with torch.no_grad():\n",
        "    emb = model.get_input_embeddings().weight\n",
        "    # map word -> new id (only for those actually added)\n",
        "    vocab = tok.get_vocab()\n",
        "    inv = {t:i for t,i in vocab.items()}  # token -> id\n",
        "    wrote = 0\n",
        "    for item in to_add:\n",
        "        w = item[\"word\"]\n",
        "        tid = inv.get(w, None)\n",
        "        if tid is None:\n",
        "            continue  # not actually added (maybe was already in vocab as 1-piece)\n",
        "        p, r, s = item.get(\"prefix\"), item.get(\"root\"), item.get(\"suffix\")\n",
        "        vec = compose_morpheme_embedding(p, r, s, model, tok)\n",
        "        emb[tid].copy_(vec)\n",
        "        wrote += 1\n",
        "\n",
        "    # ensure lm_head is tied (GPT-2 style)\n",
        "    if hasattr(model, \"lm_head\") and model.lm_head.weight.data_ptr() != emb.data_ptr():\n",
        "        model.lm_head.weight = torch.nn.Parameter(emb)\n",
        "\n",
        "print(f\"[init] wrote composed embeddings for {wrote} new tokens\")\n",
        "\n",
        "# 3) Build combined training text (FW + synthetic)\n",
        "if 'FW_TEXT' not in globals() or not FW_TEXT:\n",
        "    raise RuntimeError(\"FW_TEXT is not loaded. Set FW_TEXT to your Finnegans Wake text string first.\")\n",
        "\n",
        "COMBINED_TEXT = FW_TEXT + \"\\n\" + \"\\n\".join(aug_lines)\n",
        "\n",
        "# Convert to block dataset for causal LM\n",
        "def make_blocks_from_text(text, tokenizer, block_size=256):\n",
        "    ids = tokenizer(text, add_special_tokens=False, return_attention_mask=False)[\"input_ids\"]\n",
        "    n = len(ids) // block_size\n",
        "    if n == 0:\n",
        "        raise ValueError(f\"Text too short: {len(ids)} ids for block_size={block_size}\")\n",
        "    ids = ids[: n * block_size]\n",
        "    arr = torch.tensor(ids, dtype=torch.int32).view(n, block_size).tolist()\n",
        "    return Dataset.from_dict({\"input_ids\": arr})\n",
        "\n",
        "BLOCK_SIZE = int(globals().get(\"BLOCK_SIZE\", 256))\n",
        "ds = make_blocks_from_text(COMBINED_TEXT, tok, BLOCK_SIZE)\n",
        "\n",
        "def _add_labels(b): return {\"labels\": b[\"input_ids\"]}\n",
        "N = len(ds)\n",
        "cut = int(0.9 * N) if N > 10 else N\n",
        "train = ds.select(range(cut)).map(_add_labels, batched=True)\n",
        "valid = ds.select(range(cut, N)).map(_add_labels, batched=True)\n",
        "print(f\"[dataset] blocks total={N} | train={len(train)} | valid={len(valid)}\")\n",
        "\n",
        "# quick peek: confirm a few new tokens are single-piece now\n",
        "probe = [w for w in new_tokens[:10]]\n",
        "lens = {w: len(tok(w, add_special_tokens=False)[\"input_ids\"]) for w in probe}\n",
        "print(\"[probe] tokenization lengths (expect 1):\", lens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "b686730b396949a28aad6110263559c2",
            "a163a44b8826432597278c1cc68185ae",
            "3fbbaa00398a4e39b39c9a2368ae422e",
            "b289608e9e2d405b86fbd9a73acc32ce",
            "9c10c539bb9449928a603ede6ad4a428",
            "da0f1f2c86024ec886fc80aad34f41f7",
            "75ba90567c294f18b9c3ff6576e9f121",
            "7c0678203c4948439d059ba3949e5cf8",
            "eb967529b8874e169f0b3dfdce0c635f",
            "ee1bc443b3fe408390d63256bdbb762a",
            "59e3f0621e1340448dc933807995f30d",
            "cc07412a224541079d561990f536bc0b",
            "ea162751756c4689a0958ccc72df1637",
            "2326dcd7288d407db2c21de6fcaa2b7d",
            "8b7a5f0866c4457cb483ec2c6230174b",
            "6d73ab2b20ec492fbc75da318401aa28",
            "15039c9136b6475fbc35f8769e6cfaf9",
            "8e6b4114f56a4b3f90ac9fd9679df122",
            "8b8aafcf122a4d11912c714d49f30981",
            "579cfacd7cd747169f51dfabe7ba07aa",
            "d308ae2892bd4d6c82679e6ce11e031f",
            "bd8b892cc67146e9a839413b35b76f76"
          ]
        },
        "id": "KMeQ25LcnDZ0",
        "outputId": "039147c9-477d-4c24-b9cd-a90a5ce3c4d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[augment] 1413 synthetic lines from 471 words\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new lm_head weights will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tokenizer] added 447 new tokens (from 447 candidates)\n",
            "[init] wrote composed embeddings for 447 new tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (445614 > 2048). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1566 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b686730b396949a28aad6110263559c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/174 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc07412a224541079d561990f536bc0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[dataset] blocks total=1740 | train=1566 | valid=174\n",
            "[probe] tokenization lengths (expect 1): {'inlettersmith': 1, 'cloudor': 1, 'innight': 1, 'misstares': 1, 'imdance': 1, 'emdanceling': 1, 'unthunder': 1, 'misword': 1, 'consonger': 1, 'enqueen': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn OFF mean-resizing if your HF version supports it (keeps own init in control)\n",
        "import inspect\n",
        "\n",
        "def resize_tok_emb_no_mean(model, new_size):\n",
        "    fn = model.resize_token_embeddings\n",
        "    sig = inspect.signature(fn)\n",
        "    if \"mean_resizing\" in sig.parameters:\n",
        "        return fn(new_size, mean_resizing=False)\n",
        "    return fn(new_size)\n",
        "\n",
        "# Example usage after tokenizer.add_tokens(...)\n",
        "n_before = len(tok)\n",
        "added = tok.add_tokens(new_tokens, special_tokens=False)\n",
        "resize_tok_emb_no_mean(model, len(tok))\n",
        "\n",
        "# (Re)tie lm_head to embeddings (GPT-2 family)\n",
        "with torch.no_grad():\n",
        "    emb = model.get_input_embeddings().weight\n",
        "    if hasattr(model, \"lm_head\") and model.lm_head.weight.data_ptr() != emb.data_ptr():\n",
        "        model.lm_head.weight = torch.nn.Parameter(emb)\n"
      ],
      "metadata": {
        "id": "Jq5OaMADnnhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SYNTHETIC TRAINING DATA GENERATION"
      ],
      "metadata": {
        "id": "R_mcGbOecgsZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pre training snap"
      ],
      "metadata": {
        "id": "IaZZKgESoVZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === PRE-TRAINING SNAPSHOT ===\n",
        "from pathlib import Path\n",
        "import json, torch, hashlib\n",
        "from datetime import datetime\n",
        "\n",
        "SNAP_DIR = Path(OUTDIR) / f\"pretrain_snapshot_{datetime.now().strftime('%Y%m%d_%H%M')}\"\n",
        "SNAP_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) Save tokenizer (captures the 447 new tokens you've added)\n",
        "tok.save_pretrained(SNAP_DIR)\n",
        "\n",
        "# 2) Save model weights (before any new training)\n",
        "model.save_pretrained(SNAP_DIR)\n",
        "\n",
        "# 3) Save vocab + new_tokens + quick embedding stats\n",
        "vocab = tok.get_vocab()\n",
        "inv_vocab = {i:t for t,i in vocab.items()}\n",
        "emb = model.get_input_embeddings().weight.detach().float().cpu()\n",
        "\n",
        "stats = {\n",
        "    \"vocab_size\": len(vocab),\n",
        "    \"embedding_dim\": emb.shape[1],\n",
        "    \"embedding_mean\": float(emb.mean()),\n",
        "    \"embedding_std\":  float(emb.std()),\n",
        "}\n",
        "\n",
        "# store an md5 hash over the embedding tensor for later diff checks\n",
        "md5 = hashlib.md5(emb.numpy().tobytes()).hexdigest()\n",
        "stats[\"embedding_md5\"] = md5\n",
        "\n",
        "# if you kept `new_tokens` from earlier cell, persist them; else store empty list\n",
        "try:\n",
        "    new_tokens  # noqa\n",
        "except NameError:\n",
        "    new_tokens = []\n",
        "\n",
        "(Path(SNAP_DIR / \"embedding_stats.json\")).write_text(json.dumps(stats, indent=2))\n",
        "(Path(SNAP_DIR / \"new_tokens.json\")).write_text(json.dumps(new_tokens, indent=2))\n",
        "\n",
        "print(\"[snapshot] saved to:\", SNAP_DIR)\n",
        "print(stats)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDKt5CycoXIB",
        "outputId": "4c54a507-f9ca-48d6-d6e0-3a1903cefaee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[snapshot] saved to: runs/morpheme_wake_20251030_0017/pretrain_snapshot_20251030_0100\n",
            "{'vocab_size': 32445, 'embedding_dim': 2048, 'embedding_mean': -3.6155972793494584e-07, 'embedding_std': 0.014816503040492535, 'embedding_md5': '31866c7862ffb554e4e362cbad659e69'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_morpheme_sentences(word_data, per_word=5):\n",
        "    \"\"\"\n",
        "    Generate training sentences that showcase morphological patterns.\n",
        "    \"\"\"\n",
        "    patterns = [\n",
        "        \"The {word} of {root} echoes through the Wake.\",\n",
        "        \"By {word} and by {root}, the river flows.\",\n",
        "        \"In the {word} of night, {root} speaks.\",\n",
        "        \"From {root} to {word}, the tale unwinds.\",\n",
        "        \"He spoke of {word} as if {root} remembered.\",\n",
        "        \"{word} upon {word}, the {root} multiplies.\",\n",
        "        \"Through {word} and beyond {root}, voices drift.\",\n",
        "        \"The {word} contains the {root} contains the word.\",\n",
        "        \"Call it {word}, call it {root}-become-language.\",\n",
        "        \"Riverrun past {word} and {root} from swerve of shore.\",\n",
        "    ]\n",
        "\n",
        "    sentences = []\n",
        "    for item in word_data:\n",
        "        for _ in range(per_word):\n",
        "            pattern = random.choice(patterns)\n",
        "            sentence = pattern.format(word=item['word'], root=item['root'])\n",
        "            sentences.append(sentence)\n",
        "\n",
        "    return sentences\n",
        "\n",
        "synthetic_sentences = generate_morpheme_sentences(synthetic_words[:200], per_word=SYNTHETIC_PER_MORPHEME)\n",
        "random.shuffle(synthetic_sentences)\n",
        "\n",
        "print(f\"\\n✓ Generated {len(synthetic_sentences)} training sentences\")\n",
        "print(\"\\nSample sentences:\")\n",
        "for s in synthetic_sentences[:5]:\n",
        "    print(f\"  {s}\")\n",
        "\n",
        "# Combine with original Wake text\n",
        "COMBINED_TEXT = FW_TEXT + \"\\n\" + \"\\n\".join(synthetic_sentences)\n",
        "print(f\"\\n✓ Combined corpus: {len(COMBINED_TEXT)} chars\")\n",
        "\n",
        "# Save generated words for analysis\n",
        "with open(OUTDIR / \"results\" / \"generated_morpheme_words.json\", \"w\") as f:\n",
        "    json.dump(synthetic_words, f, indent=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6blAat0XcjiK",
        "outputId": "6f3e7c07-bc0b-438f-a016-6d76847e4a41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Generated 2000 training sentences\n",
            "\n",
            "Sample sentences:\n",
            "  From letter to inlettersmith, the tale unwinds.\n",
            "  From king to unkingor, the tale unwinds.\n",
            "  The emsoundist of sound echoes through the Wake.\n",
            "  In the redayal of night, day speaks.\n",
            "  semiqueens upon semiqueens, the queen multiplies.\n",
            "\n",
            "✓ Combined corpus: 1457308 chars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# knobs\n",
        "N_SYN_WORDS   = 800       # number of neologisms to sample\n",
        "P_PREFIX      = 0.72      # prob of using a prefix\n",
        "P_SUFFIX      = 0.82      # prob of using a suffix\n",
        "PER_WORD_LINES= 3         # how many sentences per new word\n",
        "\n",
        "# 1) generate synthetic words (uses MORPHEME_DATA, created earlier)\n",
        "synthetic_words = generate_morpheme_words(\n",
        "    n_samples=N_SYN_WORDS,\n",
        "    p_prefix=P_PREFIX,\n",
        "    p_suffix=P_SUFFIX,\n",
        "    dedupe=True\n",
        ")\n",
        "\n",
        "print(f\"[synthetic] words={len(synthetic_words)} (p_prefix={P_PREFIX}, p_suffix={P_SUFFIX})\")\n",
        "print(\"  e.g.:\", \", \".join([w[\"word\"] for w in synthetic_words[:10]]))\n",
        "\n",
        "# 2) convert to short Joyce-ish sentences\n",
        "def lines_from_synth(synth, per_word=PER_WORD_LINES):\n",
        "    patt = [\n",
        "        \"He said {w} and smiled at the rivery din.\",\n",
        "        \"They hummed {w} through the nightlong thunder.\",\n",
        "        \"A {w} fell between letter and time.\",\n",
        "        \"Write it as {w}, he urged, once and again.\",\n",
        "        \"Under cloud and over stone, {w} kept talking.\"\n",
        "    ]\n",
        "    out = []\n",
        "    for item in synth:\n",
        "        w = item[\"word\"]\n",
        "        for _ in range(per_word):\n",
        "            out.append(random.choice(patt).format(w=w))\n",
        "    return out\n",
        "\n",
        "aug_lines = lines_from_synth(synthetic_words, per_word=PER_WORD_LINES)\n",
        "print(f\"[synthetic] lines={len(aug_lines)} (≈ {PER_WORD_LINES} per word)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNg8ooBMsPeD",
        "outputId": "493424a7-fb99-4131-8a36-2a821c351345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[synthetic] words=734 (p_prefix=0.72, p_suffix=0.82)\n",
            "  e.g.: conmanes, presounder, soundity, codayor, outdanceist, maned, corunous, coraines, consongen, destarment\n",
            "[synthetic] lines=2202 (≈ 3 per word)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data set prep"
      ],
      "metadata": {
        "id": "S-3-8Jx7cpAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === DATASET PREP: add tokens, init vectors, build block dataset ===\n",
        "import inspect, torch\n",
        "from datasets import Dataset\n",
        "\n",
        "BLOCK_SIZE  = int(globals().get(\"BLOCK_SIZE\", 256))\n",
        "SAVE_STEPS  = int(globals().get(\"SAVE_STEPS\", 200))\n",
        "\n",
        "def resize_tok_emb_no_mean(model, new_size):\n",
        "    fn = model.resize_token_embeddings\n",
        "    sig = inspect.signature(fn)\n",
        "    if \"mean_resizing\" in sig.parameters:\n",
        "        return fn(new_size, mean_resizing=False)\n",
        "    return fn(new_size)\n",
        "\n",
        "def is_single_token(tokenizer, s):\n",
        "    return len(tokenizer(s, add_special_tokens=False)[\"input_ids\"]) == 1\n",
        "\n",
        "# 1) determine which synthetic words need to be added\n",
        "to_add = [x for x in synthetic_words if not is_single_token(tok, x[\"word\"])]\n",
        "new_tokens = [x[\"word\"] for x in to_add]\n",
        "added = tok.add_tokens(new_tokens, special_tokens=False)\n",
        "resize_tok_emb_no_mean(model, len(tok))\n",
        "print(f\"[tokenizer] candidates={len(new_tokens)} | actually_added={added}\")\n",
        "\n",
        "# 2) write composed embeddings only for actually-added tokens\n",
        "with torch.no_grad():\n",
        "    emb = model.get_input_embeddings().weight\n",
        "    vocab = tok.get_vocab()\n",
        "    wrote = 0\n",
        "    for item in to_add:\n",
        "        tid = vocab.get(item[\"word\"])\n",
        "        if tid is None:\n",
        "            continue\n",
        "        vec = compose_morpheme_embedding(item.get(\"prefix\"), item.get(\"root\"), item.get(\"suffix\"), model, tok)\n",
        "        emb[tid].copy_(vec)\n",
        "        wrote += 1\n",
        "    if hasattr(model, \"lm_head\") and model.lm_head.weight.data_ptr() != emb.data_ptr():\n",
        "        model.lm_head.weight = torch.nn.Parameter(emb)\n",
        "print(f\"[init] morpheme-composed vectors written for {wrote} tokens\")\n",
        "\n",
        "# 3) build combined text from FW + synthetic lines\n",
        "assert 'FW_TEXT' in globals() and FW_TEXT, \"FW_TEXT missing; load your Finnegans Wake text string.\"\n",
        "COMBINED_TEXT = FW_TEXT + \"\\n\" + \"\\n\".join(aug_lines)\n",
        "\n",
        "# avoid any full-sequence forwards later:\n",
        "def make_blocks_from_text(text, tokenizer, block_size=BLOCK_SIZE):\n",
        "    ids = tokenizer(text, add_special_tokens=False, return_attention_mask=False)[\"input_ids\"]\n",
        "    n = len(ids) // block_size\n",
        "    if n == 0:\n",
        "        raise ValueError(f\"Text too short: {len(ids)} ids for block_size={block_size}\")\n",
        "    ids = ids[: n * block_size]\n",
        "    import numpy as np\n",
        "    arr = np.array(ids, dtype=np.int32).reshape(n, block_size)\n",
        "    return Dataset.from_dict({\"input_ids\": arr.tolist()})\n",
        "\n",
        "ds = make_blocks_from_text(COMBINED_TEXT, tok, BLOCK_SIZE)\n",
        "\n",
        "def _add_labels(b): return {\"labels\": b[\"input_ids\"]}\n",
        "N = len(ds)\n",
        "cut = int(0.9 * N) if N > 10 else N\n",
        "train = ds.select(range(cut)).map(_add_labels, batched=True)\n",
        "valid = ds.select(range(cut, N)).map(_add_labels, batched=True)\n",
        "\n",
        "print(f\"[dataset] blocks total={N} | train={len(train)} | valid={len(valid)} | block_size={BLOCK_SIZE}\")\n",
        "\n",
        "# quick probe: new tokens are single-piece now\n",
        "probe = new_tokens[:10]\n",
        "lens = {w: len(tok(w, add_special_tokens=False)[\"input_ids\"]) for w in probe}\n",
        "print(\"[probe] tokenization lengths (expect 1):\", lens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "907d3bf403b7455d88d880dd1adb1c62",
            "521de04f0fa44053854b121e4b839b31",
            "a707dd0731ed47a5b1d791420dc1b5d5",
            "ecffa6d714b740768952fdb91f63c472",
            "9cc6b73171cd4f549a3191294e38d03d",
            "0fbfe320ff204fe8b9e3e300de40b389",
            "dfa605cef56e4a19b2baaa9670ec1008",
            "d391082208144816b8cae3abf9692a7b",
            "220b90768ace4cb69dd8aa2807ea48de",
            "5d76f8e6524542e49d3984f45cc92c1e",
            "8f60c708c456488fadea4cfdd95e0a3d",
            "a562adb41b57411b80081bdb9b5394eb",
            "7171cc3197df480b86274d56fb6895c1",
            "b74d679715474382a40b12bf62af3abc",
            "cdde0dd37d0a4b82922916a2ba99bcca",
            "7514c16d82a64ab0b1028e9fd2ba7da1",
            "24feb4c470be499680297ab8bd654e5d",
            "1ea40b9ee21f4800a2e7bead0cebeecf",
            "cd9b05cba25d4fd089f9a0196810a43f",
            "be0517c163df4ec2914701cc1adf714d",
            "45c5eb51bc08453ab76978b0cd5db8a2",
            "cc3f6acf777e49ada7aba311af1b9af2"
          ]
        },
        "id": "2f7NNdiqsdUW",
        "outputId": "4b629a20-9b28-41f5-d8c3-d81f4a23430e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tokenizer] candidates=654 | actually_added=654\n",
            "[init] morpheme-composed vectors written for 654 tokens\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1596 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "907d3bf403b7455d88d880dd1adb1c62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/178 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a562adb41b57411b80081bdb9b5394eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[dataset] blocks total=1774 | train=1596 | valid=178 | block_size=256\n",
            "[probe] tokenization lengths (expect 1): {'conmanes': 1, 'presounder': 1, 'codayor': 1, 'outdanceist': 1, 'coraines': 1, 'consongen': 1, 'destarment': 1, 'revoicely': 1, 'overwatering': 1, 'miswomaning': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pre train snap shot"
      ],
      "metadata": {
        "id": "wkpy6AxEc_2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding_snapshot(words, model, tokenizer, name=\"snapshot\"):\n",
        "    model.eval()\n",
        "    emb_matrix = model.get_input_embeddings().weight.data\n",
        "    emb_norm = emb_matrix / emb_matrix.norm(dim=1, keepdim=True)\n",
        "\n",
        "    snapshot = {\"name\": name, \"vocab_size\": len(tokenizer), \"words\": {}}\n",
        "\n",
        "    for word_item in words[:50]:\n",
        "        word = word_item['word']\n",
        "        tid = tokenizer.convert_tokens_to_ids(word)\n",
        "        if tid == tokenizer.unk_token_id:\n",
        "            continue\n",
        "\n",
        "        word_emb_norm = emb_norm[tid]\n",
        "        sims = torch.matmul(word_emb_norm.unsqueeze(0), emb_norm.T)[0]\n",
        "        top_k = torch.topk(sims, 11)\n",
        "\n",
        "        neighbors = []\n",
        "        for idx, sim in zip(top_k.indices[1:], top_k.values[1:]):\n",
        "            neighbors.append({\n",
        "                \"token\": tokenizer.convert_ids_to_tokens(idx.item()),\n",
        "                \"sim\": round(sim.item(), 4)\n",
        "            })\n",
        "\n",
        "        snapshot[\"words\"][word] = {\n",
        "            \"token_id\": tid,\n",
        "            \"composition\": f\"{word_item['prefix'] or 'Ø'}+{word_item['root']}+{word_item['suffix'] or 'Ø'}\",\n",
        "            \"embedding_norm\": round(emb_matrix[tid].norm().item(), 4),\n",
        "            \"top_neighbors\": neighbors[:10]\n",
        "        }\n",
        "\n",
        "    return snapshot\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PRE-TRAINING SNAPSHOT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "pre_snapshot = get_embedding_snapshot(synthetic_words, model, tok, \"pre_morpheme\")\n",
        "with open(OUTDIR / \"results\" / \"pre_morpheme_snapshot.json\", \"w\") as f:\n",
        "    json.dump(pre_snapshot, f, indent=2)\n",
        "\n",
        "print(f\"✓ Pre-training snapshot: {len(pre_snapshot['words'])} words\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDzkjKJAc89q",
        "outputId": "f6888b81-131d-44e7-ab39-2dfdc30d7c91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PRE-TRAINING SNAPSHOT\n",
            "============================================================\n",
            "✓ Pre-training snapshot: 49 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "training args"
      ],
      "metadata": {
        "id": "9L1My3SmsmV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === OOM-HARDENED TRAIN (FP32 activations, adamw_bnb_8bit optimizer) ===\n",
        "from pathlib import Path\n",
        "import os, random, json, torch, torch.nn.functional as F\n",
        "from transformers import (\n",
        "    TrainingArguments, Trainer, DataCollatorForLanguageModeling,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "import transformers\n",
        "\n",
        "# 0) deps + CUDA alloc hygiene\n",
        "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
        "try:\n",
        "    import bitsandbytes as bnb  # noqa: F401\n",
        "except Exception:\n",
        "    # Colab-friendly install\n",
        "    import subprocess, sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"bitsandbytes>=0.43.0\"])\n",
        "    import bitsandbytes as bnb  # noqa: F401\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 1) knobs (tune BATCH_SIZE/GRAD_ACCUM if you still see OOM)\n",
        "OUTDIR        = Path(globals().get(\"OUTDIR\", \"runs/wake2vec_run\"))\n",
        "BATCH_SIZE    = int(globals().get(\"BATCH_SIZE\", 8))   # try 4/2/1 if needed\n",
        "GRAD_ACCUM    = int(globals().get(\"GRAD_ACCUM\", 2))\n",
        "EPOCHS_FULL   = int(globals().get(\"EPOCHS_FULL\", 2))\n",
        "LR_FULL       = float(globals().get(\"LR_FULL\", 2e-5))\n",
        "WARMUP_FRAC   = float(globals().get(\"WARMUP_FRAC\", 0.03))\n",
        "SAVE_STEPS    = int(globals().get(\"SAVE_STEPS\", 200))\n",
        "EVAL_ENABLED  = len(valid) > 0\n",
        "\n",
        "# 2) reduce activation memory\n",
        "if hasattr(model, \"gradient_checkpointing_enable\"):\n",
        "    model.gradient_checkpointing_enable()\n",
        "if hasattr(model.config, \"use_cache\"):\n",
        "    model.config.use_cache = False  # avoid KV cache during training\n",
        "\n",
        "# 3) Trainer args — 8-bit AdamW via bitsandbytes\n",
        "args = TrainingArguments(\n",
        "    output_dir=str(OUTDIR / \"checkpoints\"),\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=min(BATCH_SIZE, 4),\n",
        "    gradient_accumulation_steps=GRAD_ACCUM,\n",
        "    learning_rate=LR_FULL,\n",
        "    num_train_epochs=EPOCHS_FULL,\n",
        "    warmup_ratio=WARMUP_FRAC,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=20,\n",
        "    save_steps=SAVE_STEPS,\n",
        "    save_strategy=\"steps\",\n",
        "    eval_strategy=\"steps\" if EVAL_ENABLED else \"no\",\n",
        "    eval_steps=SAVE_STEPS if EVAL_ENABLED else None,\n",
        "    do_eval=EVAL_ENABLED,\n",
        "    metric_for_best_model=\"loss\",\n",
        "    greater_is_better=False,\n",
        "    load_best_model_at_end=True if EVAL_ENABLED else False,\n",
        "    report_to=[\"none\"],\n",
        "    remove_unused_columns=False,\n",
        "    fp16=False, bf16=False,                # keep FP32 activations (stable)\n",
        "    optim=\"adamw_bnb_8bit\",                # <<< 8-bit AdamW\n",
        ")\n",
        "\n",
        "collator  = DataCollatorForLanguageModeling(tokenizer=tok, mlm=False)\n",
        "callbacks = [EarlyStoppingCallback(early_stopping_patience=2)] if EVAL_ENABLED else []\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    data_collator=collator,\n",
        "    train_dataset=train,\n",
        "    eval_dataset=valid if EVAL_ENABLED else None,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "print(f\"[train] transformers={transformers.__version__} | optim=adamw_bnb_8bit | \"\n",
        "      f\"bsz={BATCH_SIZE} x accum={GRAD_ACCUM} | eval={'on' if EVAL_ENABLED else 'off'}\")\n",
        "res = trainer.train()\n",
        "print(\"[train] done. train_loss:\", float(res.metrics.get(\"train_loss\", float('nan'))))\n",
        "\n",
        "# ---- quick neighbors for a few new tokens ----\n",
        "with torch.no_grad():\n",
        "    W = model.get_input_embeddings().weight.detach().float().cpu()\n",
        "    vocab = tok.get_vocab()\n",
        "    inv_vocab = {i: t for t, i in vocab.items()}\n",
        "\n",
        "    def neighbors(term, k=6):\n",
        "        ids = tok(term, add_special_tokens=False)[\"input_ids\"]\n",
        "        if len(ids) != 1: return []\n",
        "        tid = ids[0]\n",
        "        q = F.normalize(W[tid][None, :], dim=-1)\n",
        "        sims = (q @ F.normalize(W.T, dim=0)).squeeze(0)\n",
        "        vals, idxs = torch.topk(sims, k+1)\n",
        "        out = []\n",
        "        for v, i in zip(vals.tolist(), idxs.tolist()):\n",
        "            t = inv_vocab.get(i, f\"<{i}>\")\n",
        "            if t == term: continue\n",
        "            out.append((t, round(float(v), 4)))\n",
        "            if len(out) == k: break\n",
        "        return out\n",
        "\n",
        "sample_new = []\n",
        "try:\n",
        "    sample_new = random.sample(new_tokens, k=min(8, len(new_tokens)))\n",
        "except Exception:\n",
        "    if \"synthetic_words\" in globals():\n",
        "        cand = [w[\"word\"] for w in synthetic_words]\n",
        "        sample_new = [w for w in cand[:100] if len(tok(w, add_special_tokens=False)[\"input_ids\"]) == 1][:8]\n",
        "\n",
        "print(\"\\n[neighbors] sample new tokens:\")\n",
        "for s in sample_new:\n",
        "    print(f\"  {s:18s} -> {neighbors(s)}\")\n",
        "\n",
        "# ---- save final ----\n",
        "final_dir = OUTDIR / \"final\"\n",
        "final_dir.mkdir(parents=True, exist_ok=True)\n",
        "model.save_pretrained(final_dir)\n",
        "tok.save_pretrained(final_dir)\n",
        "\n",
        "meta = {\n",
        "    \"epochs\": EPOCHS_FULL, \"learning_rate\": LR_FULL, \"warmup_ratio\": WARMUP_FRAC,\n",
        "    \"batch_size\": BATCH_SIZE, \"grad_accum\": GRAD_ACCUM,\n",
        "    \"block_size\": int(globals().get(\"BLOCK_SIZE\", 256)),\n",
        "    \"train_blocks\": len(train), \"valid_blocks\": len(valid),\n",
        "    \"vocab_size\": len(tok),\n",
        "    \"optimizer\": \"adamw_bnb_8bit\",\n",
        "}\n",
        "(Path(final_dir / \"run_meta.json\")).write_text(json.dumps(meta, indent=2))\n",
        "print(\"\\n[save] wrote final model/tokenizer + metadata to:\", final_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "F-2cGO1vuEC-",
        "outputId": "7f8e1383-52b7-4399-cc0d-22b3141fa700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] transformers=4.57.1 | optim=adamw_bnb_8bit | bsz=2 x accum=4 | eval=on\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [400/400 53:23, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>5.398900</td>\n",
              "      <td>5.425949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>4.827800</td>\n",
              "      <td>5.230994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[train] done. train_loss: 5.492043323516846\n",
            "\n",
            "[neighbors] sample new tokens:\n",
            "  requeenment        -> [('queenment', 0.9816), ('requeen', 0.9801), ('requeens', 0.9791), ('queenation', 0.9639), ('enqueen', 0.9606), ('conqueen', 0.9606)]\n",
            "  pandayly           -> [('codayly', 0.9254), ('exdayly', 0.923), ('dayy', 0.9115), ('dayor', 0.9044), ('dayen', 0.9042), ('redays', 0.9039)]\n",
            "  rainual            -> [('rainly', 0.9537), ('raines', 0.9533), ('birain', 0.9474), ('exrain', 0.9471), ('trirain', 0.9418), ('conrainer', 0.9399)]\n",
            "  cothundered        -> [('cothunder', 0.9694), ('cothunderes', 0.9655), ('cothunderal', 0.9567), ('thundered', 0.9545), ('cothunderness', 0.943), ('rethunderly', 0.9213)]\n",
            "  enwatery           -> [('cowatery', 0.9573), ('wateren', 0.9402), ('inwaterly', 0.9378), ('waterment', 0.9357), ('cowaters', 0.9346), ('rewateres', 0.9344)]\n",
            "  exsonger           -> [('songer', 0.9731), ('exsongling', 0.9723), ('exsongity', 0.9667), ('exsongness', 0.9667), ('consonger', 0.9664), ('songed', 0.9545)]\n",
            "  thunders           -> [('thundered', 0.9221), ('dethunder', 0.9118), ('unthunder', 0.9075), ('cothunder', 0.9031), ('unthunderes', 0.9001), ('cothunderes', 0.8955)]\n",
            "  coqueenes          -> [('coqueens', 0.9869), ('coqueen', 0.9847), ('queenes', 0.9787), ('queeny', 0.9631), ('conqueener', 0.963), ('requeens', 0.9629)]\n",
            "\n",
            "[save] wrote final model/tokenizer + metadata to: runs/morpheme_wake_20251030_0017/final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "post training analysis"
      ],
      "metadata": {
        "id": "uZg-o1-uda7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === POST-TRAINING ANALYSIS CELL ===\n",
        "import json, math, time, os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "OUTDIR = Path(globals().get(\"OUTDIR\", \"runs/wake2vec_run\"))\n",
        "RESULTS_DIR = OUTDIR / \"results\"\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- helper: get top-k neighbors for a single token id using CPU-normalized embeddings ---\n",
        "def _topk_neighbors_for_id(tid, W_norm, inv_vocab, k=20):\n",
        "    # W_norm: (V, D) float32 CPU tensor already normalized\n",
        "    q = W_norm[tid : tid + 1]                 # (1, D)\n",
        "    sims = (q @ W_norm.T).squeeze(0)          # (V,)\n",
        "    # get top k+5 then filter out the same token etc.\n",
        "    vals, idxs = torch.topk(sims, k + 5)\n",
        "    out = []\n",
        "    for v, i in zip(vals.tolist(), idxs.tolist()):\n",
        "        token = inv_vocab.get(int(i), f\"<{i}>\")\n",
        "        out.append({\"token\": token, \"score\": float(v)})\n",
        "        if len(out) >= k:\n",
        "            break\n",
        "    return out\n",
        "\n",
        "# --- main snapshot function ---\n",
        "def get_embedding_snapshot(synth_words, model, tokenizer, tag=\"snapshot\", topk=12):\n",
        "    \"\"\"\n",
        "    synth_words: list of dicts with keys 'word','prefix','root','suffix' (as used previously)\n",
        "    returns a dict with \"meta\" and \"words\" map\n",
        "    \"\"\"\n",
        "    t0 = time.time()\n",
        "    emb = model.get_input_embeddings().weight.detach().float().cpu()   # (V, D)\n",
        "    V, D = emb.shape\n",
        "    # normalize once\n",
        "    W_norm = F.normalize(emb, dim=1)    # (V, D) normalized\n",
        "\n",
        "    vocab = tokenizer.get_vocab()\n",
        "    inv_vocab = {i: t for t, i in vocab.items()}\n",
        "\n",
        "    # helper to get id(s) for text\n",
        "    def ids_for_text(s):\n",
        "        return tokenizer(s, add_special_tokens=False)[\"input_ids\"]\n",
        "\n",
        "    result = {\n",
        "        \"meta\": {\n",
        "            \"tag\": tag,\n",
        "            \"vocab_size\": V,\n",
        "            \"emb_dim\": D,\n",
        "            \"time\": time.time(),\n",
        "        },\n",
        "        \"words\": {}\n",
        "    }\n",
        "\n",
        "    for item in (synth_words or []):\n",
        "        w = item.get(\"word\")\n",
        "        if not w:\n",
        "            continue\n",
        "        ids = ids_for_text(w)\n",
        "        # prefer words that are single-token, but if multi-token, average their token vectors\n",
        "        if len(ids) == 0:\n",
        "            continue\n",
        "        vecs = emb[torch.tensor(ids, dtype=torch.long)]\n",
        "        emb_mean = vecs.mean(dim=0)\n",
        "        emb_norm = float(torch.norm(emb_mean).item())\n",
        "\n",
        "        # pick top neighbors using the first token id if single-token; otherwise find nearest by projecting mean\n",
        "        if len(ids) == 1:\n",
        "            tid = ids[0]\n",
        "            neighbors = _topk_neighbors_for_id(tid, W_norm, inv_vocab, k=topk)\n",
        "        else:\n",
        "            # fallback: compute cosine of mean vector vs W_norm\n",
        "            q = F.normalize(emb_mean, dim=0).unsqueeze(0)    # (1, D)\n",
        "            sims = (q @ W_norm.T).squeeze(0)\n",
        "            vals, idxs = torch.topk(sims, topk + 5)\n",
        "            neighbors = []\n",
        "            for v, i in zip(vals.tolist(), idxs.tolist()):\n",
        "                token = inv_vocab.get(int(i), f\"<{i}>\")\n",
        "                neighbors.append({\"token\": token, \"score\": float(v)})\n",
        "                if len(neighbors) >= topk:\n",
        "                    break\n",
        "\n",
        "        # Compose metadata\n",
        "        composition = {\n",
        "            \"prefix\": item.get(\"prefix\"),\n",
        "            \"root\": item.get(\"root\"),\n",
        "            \"suffix\": item.get(\"suffix\"),\n",
        "        }\n",
        "\n",
        "        result[\"words\"][w] = {\n",
        "            \"composition\": composition,\n",
        "            \"embedding_norm\": emb_norm,\n",
        "            \"tokenized_ids\": ids,\n",
        "            \"top_neighbors\": neighbors\n",
        "        }\n",
        "\n",
        "    result[\"meta\"][\"elapsed_sec\"] = time.time() - t0\n",
        "    return result\n",
        "\n",
        "# --- run snapshot ---\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"POST-TRAINING ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# require synthetic_words (but can still run partial analysis if missing)\n",
        "if \"synthetic_words\" not in globals():\n",
        "    print(\"[warn] synthetic_words not found in globals(); nothing to snapshot.\")\n",
        "    synth = []\n",
        "else:\n",
        "    synth = synthetic_words\n",
        "\n",
        "post_snapshot = get_embedding_snapshot(synth, model, tok, tag=\"post_morpheme\")\n",
        "out_path = RESULTS_DIR / \"post_morpheme_snapshot.json\"\n",
        "out_path.write_text(json.dumps(post_snapshot, indent=2))\n",
        "print(f\"[saved] post snapshot -> {out_path}\")\n",
        "\n",
        "# --- if pre_snapshot exists, compare ---\n",
        "if \"pre_snapshot\" in globals() and pre_snapshot and \"words\" in pre_snapshot:\n",
        "    print(\"[compare] pre_snapshot detected — running comparison for sample words\")\n",
        "    comparison = {}\n",
        "    # pick up to 50 words to compare (or fewer if pre has less)\n",
        "    sample_words = list(pre_snapshot[\"words\"].keys())[:50]\n",
        "    for word in sample_words:\n",
        "        if word not in post_snapshot[\"words\"]:\n",
        "            continue\n",
        "        pre = pre_snapshot[\"words\"][word]\n",
        "        post = post_snapshot[\"words\"][word]\n",
        "\n",
        "        pre_neighbors = {n[\"token\"] for n in pre.get(\"top_neighbors\", [])[:5]}\n",
        "        post_neighbors = {n[\"token\"] for n in post.get(\"top_neighbors\", [])[:5]}\n",
        "        overlap = len(pre_neighbors & post_neighbors)\n",
        "\n",
        "        comparison[word] = {\n",
        "            \"composition\": pre.get(\"composition\"),\n",
        "            \"norm_change\": post.get(\"embedding_norm\", 0.0) - pre.get(\"embedding_norm\", 0.0),\n",
        "            \"neighbor_overlap\": overlap,\n",
        "            \"pre_top5\": [n[\"token\"] for n in pre.get(\"top_neighbors\", [])[:5]],\n",
        "            \"post_top5\": [n[\"token\"] for n in post.get(\"top_neighbors\", [])[:5]]\n",
        "        }\n",
        "\n",
        "        # pretty print first 10 comparisons\n",
        "        if len(comparison) <= 10:\n",
        "            print(f\"\\n{word} ({comparison[word]['composition']}):\")\n",
        "            print(f\"  Norm: {pre.get('embedding_norm',0):.4f} → {post.get('embedding_norm',0):.4f}\")\n",
        "            print(f\"  Overlap: {overlap}/5\")\n",
        "            print(f\"  Before: {', '.join(comparison[word]['pre_top5'])}\")\n",
        "            print(f\"  After:  {', '.join(comparison[word]['post_top5'])}\")\n",
        "\n",
        "    comp_path = RESULTS_DIR / \"morpheme_comparison.json\"\n",
        "    comp_path.write_text(json.dumps(comparison, indent=2))\n",
        "    print(f\"\\n[written] comparison -> {comp_path}\")\n",
        "\n",
        "else:\n",
        "    print(\"[note] pre_snapshot not found; saved only post_snapshot. If you have a pre_snapshot, load it into a var named `pre_snapshot` and re-run this cell to compare.\")\n",
        "\n",
        "# Save final model and tokenizer (tagged)\n",
        "final_dir = OUTDIR / \"final_morpheme_model\"\n",
        "final_dir.mkdir(parents=True, exist_ok=True)\n",
        "model.save_pretrained(final_dir)\n",
        "tok.save_pretrained(final_dir)\n",
        "\n",
        "print(f\"\\nModel saved: {final_dir}\")\n",
        "print(f\"Results folder: {RESULTS_DIR}\")\n",
        "print(\"\\nMaybe it learned a thing or two — inspect the JSONs for details.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sCGikLn47rt",
        "outputId": "647ab38c-4405-4f08-d59e-3629511e5611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "POST-TRAINING ANALYSIS\n",
            "============================================================\n",
            "[saved] post snapshot -> runs/morpheme_wake_20251030_0017/results/post_morpheme_snapshot.json\n",
            "[compare] pre_snapshot detected — running comparison for sample words\n",
            "\n",
            "conmanes (con-+man+-es):\n",
            "  Norm: 0.1911 → 0.1972\n",
            "  Overlap: 4/5\n",
            "  Before: manes, conmaning, enmanes, comanes, mans\n",
            "  After:  conmanes, manes, conmaning, enmanes, comanes\n",
            "\n",
            "presounder (pre-+sound+-er):\n",
            "  Norm: 0.2137 → 0.2209\n",
            "  Overlap: 4/5\n",
            "  Before: presounded, ensounder, resound, soundy, resoundly\n",
            "  After:  presounder, presounded, ensounder, resound, soundy\n",
            "\n",
            "soundity (Ø+sound+-ity):\n",
            "  Norm: 0.1989 → 0.2063\n",
            "  Overlap: 3/5\n",
            "  Before: soundy, ▁sound, soundal, soundation, soundes\n",
            "  After:  soundity, soundy, soundal, soundation, soundor\n",
            "\n",
            "codayor (co-+day+-or):\n",
            "  Norm: 0.1854 → 0.1925\n",
            "  Overlap: 4/5\n",
            "  Before: codayy, codayed, dayor, codayly, codayness\n",
            "  After:  codayor, codayy, codayed, dayor, codayly\n",
            "\n",
            "outdanceist (out-+dance+-ist):\n",
            "  Norm: 0.2437 → 0.2499\n",
            "  Overlap: 4/5\n",
            "  Before: dancely, danceed, danceor, danceen, condance\n",
            "  After:  outdanceist, danceed, dancely, danceor, danceen\n",
            "\n",
            "maned (Ø+man+-ed):\n",
            "  Norm: 0.1757 → 0.1816\n",
            "  Overlap: 3/5\n",
            "  Before: inmaned, ▁man, mans, manes, manen\n",
            "  After:  maned, inmaned, manes, manen, manal\n",
            "\n",
            "corunous (co-+run+-ous):\n",
            "  Norm: 0.1952 → 0.1999\n",
            "  Overlap: 4/5\n",
            "  Before: coruner, corunation, misrunous, runly, runer\n",
            "  After:  corunous, coruner, corunation, misrunous, runly\n",
            "\n",
            "coraines (co-+rain+-es):\n",
            "  Norm: 0.2462 → 0.2518\n",
            "  Overlap: 4/5\n",
            "  Before: raines, imraines, corainication, rerains, rainly\n",
            "  After:  coraines, raines, imraines, corainication, rerains\n",
            "\n",
            "consongen (con-+song+-en):\n",
            "  Norm: 0.2236 → 0.2306\n",
            "  Overlap: 4/5\n",
            "  Before: consonger, songy, songer, songal, songed\n",
            "  After:  consongen, consonger, songy, songer, songal\n",
            "\n",
            "destarment (de-+star+-ment):\n",
            "  Norm: 0.2021 → 0.2105\n",
            "  Overlap: 4/5\n",
            "  Before: destar, destares, destaring, prostarment, staration\n",
            "  After:  destarment, destar, destares, destaring, prostarment\n",
            "\n",
            "[written] comparison -> runs/morpheme_wake_20251030_0017/results/morpheme_comparison.json\n",
            "\n",
            "Model saved: runs/morpheme_wake_20251030_0017/final_morpheme_model\n",
            "Results folder: runs/morpheme_wake_20251030_0017/results\n",
            "\n",
            "Maybe it learned a thing or two — inspect the JSONs for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Summary stats + top movers ===\n",
        "import json, math, statistics\n",
        "from pathlib import Path\n",
        "\n",
        "OUTDIR = Path(\"runs/morpheme_wake_20251030_0017\")\n",
        "RESULTS = OUTDIR / \"results\"\n",
        "\n",
        "pre = globals().get(\"pre_snapshot\", None)\n",
        "post = globals().get(\"post_snapshot\", None)\n",
        "# if not in-memory, try to load saved\n",
        "if pre is None:\n",
        "    ppath = RESULTS / \"pre_morpheme_snapshot.json\"\n",
        "    if ppath.exists():\n",
        "        pre = json.loads(ppath.read_text(encoding=\"utf-8\"))\n",
        "if post is None:\n",
        "    ppath = RESULTS / \"post_morpheme_snapshot.json\"\n",
        "    if ppath.exists():\n",
        "        post = json.loads(ppath.read_text(encoding=\"utf-8\"))\n",
        "\n",
        "if not post:\n",
        "    raise RuntimeError(\"post_snapshot missing (need post_morpheme_snapshot.json or post_snapshot in memory).\")\n",
        "\n",
        "words = list(post[\"words\"].keys())\n",
        "# build arrays of stats where pre exists\n",
        "norm_changes = []\n",
        "overlaps = []\n",
        "records = {}\n",
        "for w in words:\n",
        "    post_w = post[\"words\"][w]\n",
        "    pre_w = (pre[\"words\"].get(w) if pre and \"words\" in pre else None)\n",
        "    if pre_w:\n",
        "        pre_norm = pre_w.get(\"embedding_norm\")\n",
        "        post_norm = post_w.get(\"embedding_norm\")\n",
        "        if pre_norm is not None and post_norm is not None:\n",
        "            nc = post_norm - pre_norm\n",
        "            norm_changes.append(nc)\n",
        "        # overlap top5\n",
        "        pre_top5 = {n[\"token\"] for n in pre_w.get(\"top_neighbors\", [])[:5]}\n",
        "        post_top5 = {n[\"token\"] for n in post_w.get(\"top_neighbors\", [])[:5]}\n",
        "        overlap = len(pre_top5 & post_top5)\n",
        "        overlaps.append(overlap)\n",
        "        records[w] = {\n",
        "            \"pre_norm\": pre_w.get(\"embedding_norm\"),\n",
        "            \"post_norm\": post_w.get(\"embedding_norm\"),\n",
        "            \"norm_change\": post_w.get(\"embedding_norm\") - pre_w.get(\"embedding_norm\"),\n",
        "            \"pre_top5\": [n[\"token\"] for n in pre_w.get(\"top_neighbors\",[])[:5]],\n",
        "            \"post_top5\": [n[\"token\"] for n in post_w.get(\"top_neighbors\",[])[:5]],\n",
        "            \"overlap_top5\": overlap\n",
        "        }\n",
        "\n",
        "print(\"N compared words:\", len(records))\n",
        "if norm_changes:\n",
        "    print(\"Norm change: mean=\", statistics.mean(norm_changes), \"median=\", statistics.median(norm_changes),\n",
        "          \"min=\", min(norm_changes), \"max=\", max(norm_changes))\n",
        "if overlaps:\n",
        "    print(\"Overlap top5: mean=\", statistics.mean(overlaps), \"median=\", statistics.median(overlaps))\n",
        "\n",
        "# Top movers by absolute norm change and by neighbor-change (1 - overlap)\n",
        "top_by_norm = sorted(records.items(), key=lambda x: abs(x[1]['norm_change'] or 0), reverse=True)[:30]\n",
        "top_by_overlap_loss = sorted(records.items(), key=lambda x: (5 - (x[1]['overlap_top5'] or 0)), reverse=True)[:30]\n",
        "\n",
        "# Save\n",
        "(Path(RESULTS / \"summary_stats.json\")).write_text(json.dumps({\n",
        "    \"n_compared\": len(records),\n",
        "    \"norm_change_stats\": {\n",
        "        \"mean\": statistics.mean(norm_changes) if norm_changes else None,\n",
        "        \"median\": statistics.median(norm_changes) if norm_changes else None,\n",
        "    },\n",
        "    \"overlap_mean\": statistics.mean(overlaps) if overlaps else None\n",
        "}, indent=2))\n",
        "\n",
        "print(\"\\nTop 10 by absolute norm change:\")\n",
        "for w,v in top_by_norm[:10]:\n",
        "    print(f\" {w:20s} norm Δ={v['norm_change']:.4f} overlap={v['overlap_top5']}  pre_top5={v['pre_top5'][:5]}\")\n",
        "\n",
        "print(\"\\nTop 10 by overlap loss (moved away):\")\n",
        "for w,v in top_by_overlap_loss[:10]:\n",
        "    print(f\" {w:20s} overlap={v['overlap_top5']} norm Δ={v['norm_change']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrdlQRBODclK",
        "outputId": "8a65aca1-9fb5-42ef-bd02-6d6e60d93780"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N compared words: 49\n",
            "Norm change: mean= 0.005135101273595071 median= 0.006620781826972955 min= -0.07503086223602295 max= 0.01022875852584837\n",
            "Overlap top5: mean= 3.7142857142857144 median= 4\n",
            "\n",
            "Top 10 by absolute norm change:\n",
            " sound                norm Δ=-0.0750 overlap=2  pre_top5=['▁sound', 'soundation', 'soundity', 'resound', 'soundy']\n",
            " cloud                norm Δ=0.0102 overlap=4  pre_top5=['Cloud', 'clouded', '▁cloud', 'cloudly', 'clouder']\n",
            " probook              norm Δ=0.0099 overlap=4  pre_top5=['▁book', 'bookor', 'booker', 'bookes', 'booking']\n",
            " enstone              norm Δ=0.0090 overlap=4  pre_top5=['enstoneer', '▁stone', 'stonees', 'stoneed', 'stoneer']\n",
            " thundered            norm Δ=0.0089 overlap=4  pre_top5=['thunders', 'cothundered', 'dethunder', 'unthunder', 'cothunder']\n",
            " revoicely            norm Δ=0.0085 overlap=4  pre_top5=['revoice', 'voicely', 'revoiceing', 'revoiceal', 'voiceed']\n",
            " destar               norm Δ=0.0085 overlap=4  pre_top5=['destares', 'destaring', 'destarment', '▁star', 'stary']\n",
            " destarment           norm Δ=0.0084 overlap=4  pre_top5=['destar', 'destares', 'destaring', 'prostarment', 'staration']\n",
            " restarable           norm Δ=0.0084 overlap=4  pre_top5=['restar', 'restares', 'restarness', 'unstared', 'restareous']\n",
            " prestoney            norm Δ=0.0083 overlap=4  pre_top5=['prestoneen', 'destoney', 'bistoney', 'stoneer', 'stoneed']\n",
            "\n",
            "Top 10 by overlap loss (moved away):\n",
            " word                 overlap=2 norm Δ=0.0030\n",
            " sound                overlap=2 norm Δ=-0.0750\n",
            " windes               overlap=2 norm Δ=0.0078\n",
            " soundity             overlap=3 norm Δ=0.0074\n",
            " maned                overlap=3 norm Δ=0.0059\n",
            " innightment          overlap=3 norm Δ=0.0062\n",
            " suning               overlap=3 norm Δ=0.0065\n",
            " cowordes             overlap=3 norm Δ=0.0071\n",
            " manly                overlap=3 norm Δ=0.0032\n",
            " triqueenious         overlap=3 norm Δ=0.0065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Plots: histograms + scatter ===\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "RESULTS.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# gather arrays\n",
        "norms = [r[\"norm_change\"] for r in records.values() if r[\"norm_change\"] is not None]\n",
        "ov = [r[\"overlap_top5\"] for r in records.values() if r[\"overlap_top5\"] is not None]\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(ov, bins=range(0,6), align='left')\n",
        "plt.title(\"Neighbor overlap (top5) distribution\")\n",
        "plt.xlabel(\"Overlap (0..5)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.savefig(RESULTS / \"hist_overlap_top5.png\")\n",
        "plt.close()\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(norms, bins=50)\n",
        "plt.title(\"Embedding norm change distribution (post - pre)\")\n",
        "plt.xlabel(\"Norm change\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.savefig(RESULTS / \"hist_norm_change.png\")\n",
        "plt.close()\n",
        "\n",
        "# scatter\n",
        "x = norms\n",
        "y = ov[:len(x)]\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.scatter(x, y, alpha=0.6)\n",
        "plt.title(\"Norm change vs overlap (top5)\")\n",
        "plt.xlabel(\"Norm change\")\n",
        "plt.ylabel(\"Overlap (top5)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(RESULTS / \"scatter_norm_vs_overlap.png\")\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved plots to\", RESULTS)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYW3vxNPDjrk",
        "outputId": "e102cd11-fca3-4774-d68f-cd14404c9aac"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved plots to runs/morpheme_wake_20251030_0017/results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# t-SNE / UMAP visualization\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "# optional: from umap import UMAP   # if you prefer UMAP and it's installed\n",
        "\n",
        "# pick sample set (all new tokens in records)\n",
        "tokens = list(records.keys())\n",
        "# build vectors: use post embeddings from model\n",
        "import torch\n",
        "post_emb = model.get_input_embeddings().weight.detach().cpu()\n",
        "\n",
        "def avg_vec_for_token(t):\n",
        "    ids = tok(t, add_special_tokens=False)[\"input_ids\"]\n",
        "    if not ids:\n",
        "        return None\n",
        "    return post_emb[torch.tensor(ids)].mean(dim=0).numpy()\n",
        "\n",
        "vecs = []\n",
        "labels = []\n",
        "for t in tokens:\n",
        "    v = avg_vec_for_token(t)\n",
        "    if v is None: continue\n",
        "    vecs.append(v)\n",
        "    labels.append(t)\n",
        "\n",
        "# also compute centroids of pre_top5 neighbours (if available) using post-emb to compare positions\n",
        "centroids = []\n",
        "cent_labels = []\n",
        "for t in tokens:\n",
        "    pre_top5 = records[t].get(\"pre_top5\", [])\n",
        "    neigh_vecs = []\n",
        "    for nt in pre_top5:\n",
        "        v = avg_vec_for_token(nt)\n",
        "        if v is not None:\n",
        "            neigh_vecs.append(v)\n",
        "    if neigh_vecs:\n",
        "        centroids.append(np.mean(neigh_vecs, axis=0))\n",
        "        cent_labels.append(t + \"_precentroid\")\n",
        "\n",
        "# stack and run t-SNE\n",
        "all_vecs = np.vstack(vecs + centroids) if centroids else np.vstack(vecs)\n",
        "ts = TSNE(n_components=2, perplexity=30, init='random', random_state=42, n_iter=1000)\n",
        "proj = ts.fit_transform(all_vecs)\n",
        "\n",
        "n_tok = len(vecs)\n",
        "proj_tokens = proj[:n_tok]\n",
        "proj_cents = proj[n_tok:] if centroids else []\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.scatter(proj_tokens[:,0], proj_tokens[:,1], s=25, c='C0', label='new_tokens')\n",
        "if len(proj_cents):\n",
        "    plt.scatter(proj_cents[:,0], proj_cents[:,1], s=60, marker='x', c='C1', label='pre_top5_centroids')\n",
        "# annotate top extreme movers for quick inspection\n",
        "for i, t in enumerate(labels):\n",
        "    if abs(records[t][\"norm_change\"]) > np.percentile(np.abs(norms), 90) or records[t][\"overlap_top5\"] <= 2:\n",
        "        plt.text(proj_tokens[i,0], proj_tokens[i,1], t, fontsize=8)\n",
        "plt.legend()\n",
        "plt.title(\"t-SNE: new tokens (post) and pre-top5 centroids\")\n",
        "plt.savefig(RESULTS / \"tsne_newtokens_vs_precentroids.png\", dpi=150)\n",
        "plt.close()\n",
        "print(\"Saved t-SNE plot:\", RESULTS / \"tsne_newtokens_vs_precentroids.png\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sUV_4xtDzZ8",
        "outputId": "07cb3081-64e2-4814-8edd-858ba0e6eec5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/manifold/_t_sne.py:1164: FutureWarning: 'n_iter' was renamed to 'max_iter' in version 1.5 and will be removed in 1.7.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved t-SNE plot: runs/morpheme_wake_20251030_0017/results/tsne_newtokens_vs_precentroids.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math, torch\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "if 'valid' not in globals() or len(valid) == 0:\n",
        "    print(\"No valid dataset found (valid variable missing or empty). Skipping perplexity.\")\n",
        "else:\n",
        "    # make a lightweight evaluation loop using Trainer\n",
        "    args_eval = TrainingArguments(output_dir=str(OUTDIR / \"tmp_eval\"), per_device_eval_batch_size=4, report_to=[\"none\"])\n",
        "    trainer_eval = Trainer(model=model, args=args_eval)\n",
        "    res = trainer_eval.evaluate(eval_dataset=valid)\n",
        "    eval_loss = res.get(\"eval_loss\", res.get(\"loss\", None))\n",
        "    if eval_loss is not None:\n",
        "        perp = math.exp(eval_loss)\n",
        "        print(f\"Validation loss: {eval_loss:.4f} -> Perplexity: {perp:.2f}\")\n",
        "    else:\n",
        "        print(\"Could not find eval_loss in Trainer output:\", res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "Sdb6YpJGD8kK",
        "outputId": "2cab0fbc-1ca9-467c-ad39-fe4a332e1b6d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [45/45 00:32]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 5.2310 -> Perplexity: 186.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generation samples for selected tokens\n",
        "import random, torch\n",
        "def gen_seed(token, max_new=40):\n",
        "    prompt = token + \" \"\n",
        "    ids = tok(prompt, return_tensors=\"pt\").to(next(model.parameters()).device)\n",
        "    out = model.generate(**ids, max_new_tokens=max_new, do_sample=True, top_p=0.92, temperature=0.9)\n",
        "    return tok.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "# pick tokens\n",
        "top_movers = [w for w,_ in top_by_norm[:10]]\n",
        "low_movers = [w for w,_ in top_by_norm[-10:]]\n",
        "sample_set = (top_movers[:5] + low_movers[:5])[:10]\n",
        "print(\"Generating for sample tokens:\", sample_set)\n",
        "for t in sample_set:\n",
        "    try:\n",
        "        print(\"\\n----\", t)\n",
        "        print(gen_seed(t, max_new=40))\n",
        "    except Exception as e:\n",
        "        print(\"Generation failed for\", t, e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfTof3d2EDOo",
        "outputId": "964ec94b-8929-4b72-c35a-bc451ce062c5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating for sample tokens: ['sound', 'cloud', 'probook', 'enstone', 'thundered', 'danceed', 'cowordes', 'codayor', 'consongen', 'rewalkum']\n",
            "\n",
            "---- sound\n",
            "sound . Douth! It's as it is, the wold. Tip. Oclinate.\n",
            "\n",
            "[1] A covenity of ballybills and b\n",
            "\n",
            "---- cloud\n",
            "cloud   O'morn\n",
            "is the hodle! Ogone!\n",
            "\n",
            "  Mick\n",
            "\n",
            "  Jute.— A jute of pantry is a jacper.\n",
            "\n",
            "\n",
            "---- probook\n",
            "probook  2683), the pigeon's pudding for an man's\n",
            "                man; he was a young man's man (I am a rede) and\n",
            "\n",
            "---- enstone\n",
            "enstone   Higd.\n",
            "\n",
            "[1] My huntswoman, my boys, my hubbings, my tilt on my tinkle.\n",
            "\n",
            "[2\n",
            "\n",
            "---- thundered\n",
            "thundered   hunt!\n",
            "dill and ove. And all the fungos, the lamus, the flamim, the\n",
            "chillons, the lordies, the\n",
            "\n",
            "---- danceed\n",
            "danceed 3822. Tailu!\n",
            "\n",
            "—Peggiery, sir, he was aloft as I looked to it, as I thought,\n",
            "when he is the\n",
            "\n",
            "---- cowordes\n",
            "cowordes 31. Netty Bawls, the binnies, we to'll say. The old\n",
            "telltown, the first of the jews, the one of\n",
            "\n",
            "---- codayor\n",
            "codayor              Ondt?\n",
            "tip and hug! Tip. From the tumbum's hym. Ken a tham.\n",
            "\n",
            "—I can have\n",
            "\n",
            "---- consongen\n",
            "consongen \n",
            "                                                                   [279]\n",
            "_Salloes of a Tumbler_ or _The Finse to the Spick_, _Frupper's\n",
            "\n",
            "\n",
            "---- rewalkum\n",
            "rewalkum     T. C. O. H.\n",
            "                with this staple of the hundh. To the\n",
            "                lamb's chump. And how it was in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity\n",
        "import torch\n",
        "emb = model.get_input_embeddings().weight.detach()\n",
        "print(\"Embedding shape:\", emb.shape, \"mean:\", float(emb.mean()), \"std:\", float(emb.std()))\n",
        "if hasattr(model, \"lm_head\"):\n",
        "    tied = (model.lm_head.weight.data_ptr() == emb.data_ptr())\n",
        "    print(\"lm_head tied to embeddings?\", tied)\n",
        "else:\n",
        "    print(\"No lm_head attribute on model object.\")\n",
        "# token frequency check: how often new tokens occur in dataset (rough estimate)\n",
        "def token_freq_estimate(token, dataset, tokenizer):\n",
        "    # sample some blocks and count occurrences\n",
        "    import random\n",
        "    sample_idxs = random.sample(range(len(dataset)), min(200, len(dataset)))\n",
        "    cnt = 0\n",
        "    for i in sample_idxs:\n",
        "        toks = dataset[i][\"input_ids\"]\n",
        "        # approximate: decode block and count token string occurrences\n",
        "        s = tokenizer.decode(toks, skip_special_tokens=True)\n",
        "        cnt += s.count(token)\n",
        "    return cnt / len(sample_idxs)\n",
        "print(\"Estimated freq of a few tokens in train (sampled blocks):\")\n",
        "for t in sample_set[:6]:\n",
        "    print(\" \", t, token_freq_estimate(t, train, tok) if 'train' in globals() else \"no train ds\")\n"
      ],
      "metadata": {
        "id": "LVl-pmU3EOOT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}